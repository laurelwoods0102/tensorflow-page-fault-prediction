{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598422306876",
   "display_name": "Python 3.7.6 64-bit ('ProgramData': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import kerastuner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'20200826-201949'"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "'''\n",
    "log_dir = \"logs/fit/\" + timestamp\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "'''\n",
    "version_dir = \"version/\" + timestamp \n",
    "\n",
    "os.makedirs(version_dir)\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"SEG_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0., 0., 0., ..., 1., 3., 1.], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "dataset = np.genfromtxt(\"data/{}_train_set.csv\".format(dataset_name), delimiter=\"\\n\", dtype=np.float32) #np.int64\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "14882"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "word_index = np.genfromtxt(\"data/word_index.csv\", delimiter=\"\\n\", dtype=np.int64)\n",
    "vocab_size = len(word_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = dict()\n",
    "\n",
    "param_list[\"PAST_HISTORY\"] = 16\n",
    "param_list[\"FUTURE_TARGET\"] = 8\n",
    "param_list[\"BATCH_SIZE\"] = 128\n",
    "param_list[\"EPOCHS\"] = 100\n",
    "param_list[\"BUFFER_SIZE\"] = 200000\n",
    "param_list[\"VOCAB_SIZE\"] = vocab_size\n",
    "param_list[\"LEARNING_RATE\"] = 0.01\n",
    "param_list[\"NUM_1_NEURONS\"] = 177\n",
    "param_list[\"NUM_2_NEURONS\"] = 177\n",
    "param_list[\"DROPOUT_1\"] = 0.1\n",
    "param_list[\"DROPOUT_2\"] = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timeseries(dataset, start_index, end_index, history_size, target_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i)\n",
    "        # Reshape data from (history_size,) to (history_size, n_feature)\n",
    "        data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
    "        #data.append(dataset[indices])\n",
    "        labels.append(np.reshape(dataset[i:i+target_size], (target_size, 1)))\n",
    "        #labels.append(dataset[i:i+target_size])\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((14858, 16, 1), (14858, 8, 1))"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "x_train, y_train = generate_timeseries(dataset, 0, None, param_list[\"PAST_HISTORY\"], param_list[\"FUTURE_TARGET\"])\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [933.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]], dtype=float32),\n array([[ 0.],\n        [ 0.],\n        [48.],\n        [ 0.],\n        [ 0.],\n        [ 0.],\n        [ 0.],\n        [ 0.]], dtype=float32))"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "x_train[10], y_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Bidirectional(tf.keras.layers.LSTM(param_list[\"NUM_1_NEURONS\"])))\n",
    "model.add(keras.layers.Dropout(param_list[\"DROPOUT_1\"]))\n",
    "model.add(keras.layers.RepeatVector(param_list[\"FUTURE_TARGET\"]))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(param_list[\"NUM_2_NEURONS\"], return_sequences=True)))\n",
    "model.add(keras.layers.Dropout(param_list[\"DROPOUT_2\"]))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Dense(param_list[\"VOCAB_SIZE\"], activation='softmax')))\n",
    "model.compile(optimizer=keras.optimizers.Adam(param_list[\"LEARNING_RATE\"]), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0s - loss: 0.3129 - accuracy: 0.9087/93 [===========================>..] - ETA: 0s - loss: 0.3136 - accuracy: 0.9089/93 [===========================>..] - ETA: 0s - loss: 0.3133 - accuracy: 0.9091/93 [============================>.] - ETA: 0s - loss: 0.3123 - accuracy: 0.9093/93 [==============================] - ETA: 0s - loss: 0.3125 - accuracy: 0.9093/93 [==============================] - 3s 37ms/step - loss: 0.3125 - accuracy: 0.9027 - val_loss: 0.4606 - val_accuracy: 0.8432\nEpoch 96/100\n 1/93 [..............................] - ETA: 0s - loss: 0.3400 - accuracy: 0.88 3/93 [..............................] - ETA: 1s - loss: 0.3215 - accuracy: 0.89 5/93 [>.............................] - ETA: 2s - loss: 0.3083 - accuracy: 0.90 7/93 [=>............................] - ETA: 2s - loss: 0.3038 - accuracy: 0.90 9/93 [=>............................] - ETA: 2s - loss: 0.3110 - accuracy: 0.9011/93 [==>...........................] - ETA: 2s - loss: 0.3231 - accuracy: 0.8913/93 [===>..........................] - ETA: 2s - loss: 0.3148 - accuracy: 0.9015/93 [===>..........................] - ETA: 2s - loss: 0.3060 - accuracy: 0.9017/93 [====>.........................] - ETA: 2s - loss: 0.3056 - accuracy: 0.9019/93 [=====>........................] - ETA: 2s - loss: 0.3009 - accuracy: 0.9021/93 [=====>........................] - ETA: 2s - loss: 0.3094 - accuracy: 0.9023/93 [======>.......................] - ETA: 2s - loss: 0.3125 - accuracy: 0.9025/93 [=======>......................] - ETA: 2s - loss: 0.3082 - accuracy: 0.9027/93 [=======>......................] - ETA: 2s - loss: 0.3078 - accuracy: 0.9029/93 [========>.....................] - ETA: 2s - loss: 0.3059 - accuracy: 0.9031/93 [=========>....................] - ETA: 1s - loss: 0.3094 - accuracy: 0.9033/93 [=========>....................] - ETA: 1s - loss: 0.3116 - accuracy: 0.9035/93 [==========>...................] - ETA: 1s - loss: 0.3181 - accuracy: 0.9037/93 [==========>...................] - ETA: 1s - loss: 0.3183 - accuracy: 0.9039/93 [===========>..................] - ETA: 1s - loss: 0.3186 - accuracy: 0.9041/93 [============>.................] - ETA: 1s - loss: 0.3175 - accuracy: 0.9043/93 [============>.................] - ETA: 1s - loss: 0.3174 - accuracy: 0.9045/93 [=============>................] - ETA: 1s - loss: 0.3168 - accuracy: 0.9047/93 [==============>...............] - ETA: 1s - loss: 0.3155 - accuracy: 0.9049/93 [==============>...............] - ETA: 1s - loss: 0.3200 - accuracy: 0.9051/93 [===============>..............] - ETA: 1s - loss: 0.3169 - accuracy: 0.9053/93 [================>.............] - ETA: 1s - loss: 0.3187 - accuracy: 0.9055/93 [================>.............] - ETA: 1s - loss: 0.3181 - accuracy: 0.9057/93 [=================>............] - ETA: 1s - loss: 0.3159 - accuracy: 0.9059/93 [==================>...........] - ETA: 1s - loss: 0.3160 - accuracy: 0.9061/93 [==================>...........] - ETA: 1s - loss: 0.3154 - accuracy: 0.9063/93 [===================>..........] - ETA: 0s - loss: 0.3182 - accuracy: 0.9065/93 [===================>..........] - ETA: 0s - loss: 0.3176 - accuracy: 0.9067/93 [====================>.........] - ETA: 0s - loss: 0.3180 - accuracy: 0.9069/93 [=====================>........] - ETA: 0s - loss: 0.3183 - accuracy: 0.9071/93 [=====================>........] - ETA: 0s - loss: 0.3184 - accuracy: 0.9073/93 [======================>.......] - ETA: 0s - loss: 0.3185 - accuracy: 0.9075/93 [=======================>......] - ETA: 0s - loss: 0.3187 - accuracy: 0.9077/93 [=======================>......] - ETA: 0s - loss: 0.3185 - accuracy: 0.9079/93 [========================>.....] - ETA: 0s - loss: 0.3179 - accuracy: 0.9081/93 [=========================>....] - ETA: 0s - loss: 0.3168 - accuracy: 0.9083/93 [=========================>....] - ETA: 0s - loss: 0.3163 - accuracy: 0.9085/93 [==========================>...] - ETA: 0s - loss: 0.3167 - accuracy: 0.9087/93 [===========================>..] - ETA: 0s - loss: 0.3148 - accuracy: 0.9089/93 [===========================>..] - ETA: 0s - loss: 0.3132 - accuracy: 0.9091/93 [============================>.] - ETA: 0s - loss: 0.3141 - accuracy: 0.9093/93 [==============================] - ETA: 0s - loss: 0.3148 - accuracy: 0.9093/93 [==============================] - 3s 37ms/step - loss: 0.3148 - accuracy: 0.9039 - val_loss: 0.4646 - val_accuracy: 0.8369\nEpoch 97/100\n 1/93 [..............................] - ETA: 0s - loss: 0.3083 - accuracy: 0.90 3/93 [..............................] - ETA: 1s - loss: 0.4151 - accuracy: 0.88 5/93 [>.............................] - ETA: 2s - loss: 0.3532 - accuracy: 0.89 7/93 [=>............................] - ETA: 2s - loss: 0.3464 - accuracy: 0.89 9/93 [=>............................] - ETA: 2s - loss: 0.3484 - accuracy: 0.8911/93 [==>...........................] - ETA: 2s - loss: 0.3398 - accuracy: 0.8913/93 [===>..........................] - ETA: 2s - loss: 0.3296 - accuracy: 0.9015/93 [===>..........................] - ETA: 2s - loss: 0.3309 - accuracy: 0.9017/93 [====>.........................] - ETA: 2s - loss: 0.3326 - accuracy: 0.9019/93 [=====>........................] - ETA: 2s - loss: 0.3323 - accuracy: 0.8921/93 [=====>........................] - ETA: 2s - loss: 0.3257 - accuracy: 0.9023/93 [======>.......................] - ETA: 2s - loss: 0.3225 - accuracy: 0.9025/93 [=======>......................] - ETA: 2s - loss: 0.3215 - accuracy: 0.9027/93 [=======>......................] - ETA: 2s - loss: 0.3196 - accuracy: 0.9029/93 [========>.....................] - ETA: 1s - loss: 0.3168 - accuracy: 0.9031/93 [=========>....................] - ETA: 1s - loss: 0.3219 - accuracy: 0.9033/93 [=========>....................] - ETA: 1s - loss: 0.3198 - accuracy: 0.9035/93 [==========>...................] - ETA: 1s - loss: 0.3200 - accuracy: 0.9037/93 [==========>...................] - ETA: 1s - loss: 0.3178 - accuracy: 0.9039/93 [===========>..................] - ETA: 1s - loss: 0.3166 - accuracy: 0.9041/93 [============>.................] - ETA: 1s - loss: 0.3183 - accuracy: 0.9043/93 [============>.................] - ETA: 1s - loss: 0.3136 - accuracy: 0.9045/93 [=============>................] - ETA: 1s - loss: 0.3166 - accuracy: 0.9047/93 [==============>...............] - ETA: 1s - loss: 0.3133 - accuracy: 0.9049/93 [==============>...............] - ETA: 1s - loss: 0.3138 - accuracy: 0.9051/93 [===============>..............] - ETA: 1s - loss: 0.3124 - accuracy: 0.9053/93 [================>.............] - ETA: 1s - loss: 0.3132 - accuracy: 0.9055/93 [================>.............] - ETA: 1s - loss: 0.3106 - accuracy: 0.9057/93 [=================>............] - ETA: 1s - loss: 0.3099 - accuracy: 0.9059/93 [==================>...........] - ETA: 1s - loss: 0.3095 - accuracy: 0.9061/93 [==================>...........] - ETA: 1s - loss: 0.3088 - accuracy: 0.9063/93 [===================>..........] - ETA: 0s - loss: 0.3079 - accuracy: 0.9065/93 [===================>..........] - ETA: 0s - loss: 0.3085 - accuracy: 0.9067/93 [====================>.........] - ETA: 0s - loss: 0.3093 - accuracy: 0.9069/93 [=====================>........] - ETA: 0s - loss: 0.3114 - accuracy: 0.9071/93 [=====================>........] - ETA: 0s - loss: 0.3117 - accuracy: 0.9073/93 [======================>.......] - ETA: 0s - loss: 0.3124 - accuracy: 0.9075/93 [=======================>......] - ETA: 0s - loss: 0.3144 - accuracy: 0.9077/93 [=======================>......] - ETA: 0s - loss: 0.3148 - accuracy: 0.9079/93 [========================>.....] - ETA: 0s - loss: 0.3137 - accuracy: 0.9081/93 [=========================>....] - ETA: 0s - loss: 0.3130 - accuracy: 0.9083/93 [=========================>....] - ETA: 0s - loss: 0.3137 - accuracy: 0.9085/93 [==========================>...] - ETA: 0s - loss: 0.3133 - accuracy: 0.9087/93 [===========================>..] - ETA: 0s - loss: 0.3122 - accuracy: 0.9089/93 [===========================>..] - ETA: 0s - loss: 0.3101 - accuracy: 0.9091/93 [============================>.] - ETA: 0s - loss: 0.3105 - accuracy: 0.9093/93 [==============================] - ETA: 0s - loss: 0.3108 - accuracy: 0.9093/93 [==============================] - 3s 37ms/step - loss: 0.3108 - accuracy: 0.9038 - val_loss: 0.4916 - val_accuracy: 0.8226\nEpoch 98/100\n 1/93 [..............................] - ETA: 0s - loss: 0.2953 - accuracy: 0.89 3/93 [..............................] - ETA: 1s - loss: 0.3458 - accuracy: 0.88 5/93 [>.............................] - ETA: 2s - loss: 0.3351 - accuracy: 0.89 7/93 [=>............................] - ETA: 2s - loss: 0.3174 - accuracy: 0.89 9/93 [=>............................] - ETA: 2s - loss: 0.3167 - accuracy: 0.8911/93 [==>...........................] - ETA: 2s - loss: 0.3195 - accuracy: 0.8913/93 [===>..........................] - ETA: 2s - loss: 0.3328 - accuracy: 0.8915/93 [===>..........................] - ETA: 2s - loss: 0.3276 - accuracy: 0.8917/93 [====>.........................] - ETA: 2s - loss: 0.3317 - accuracy: 0.8919/93 [=====>........................] - ETA: 2s - loss: 0.3214 - accuracy: 0.8921/93 [=====>........................] - ETA: 2s - loss: 0.3214 - accuracy: 0.8923/93 [======>.......................] - ETA: 2s - loss: 0.3218 - accuracy: 0.8925/93 [=======>......................] - ETA: 2s - loss: 0.3164 - accuracy: 0.8927/93 [=======>......................] - ETA: 2s - loss: 0.3129 - accuracy: 0.9029/93 [========>.....................] - ETA: 1s - loss: 0.3153 - accuracy: 0.8931/93 [=========>....................] - ETA: 1s - loss: 0.3130 - accuracy: 0.9033/93 [=========>....................] - ETA: 1s - loss: 0.3148 - accuracy: 0.8935/93 [==========>...................] - ETA: 1s - loss: 0.3123 - accuracy: 0.9037/93 [==========>...................] - ETA: 1s - loss: 0.3113 - accuracy: 0.9039/93 [===========>..................] - ETA: 1s - loss: 0.3105 - accuracy: 0.9041/93 [============>.................] - ETA: 1s - loss: 0.3095 - accuracy: 0.9043/93 [============>.................] - ETA: 1s - loss: 0.3134 - accuracy: 0.8945/93 [=============>................] - ETA: 1s - loss: 0.3146 - accuracy: 0.8947/93 [==============>...............] - ETA: 1s - loss: 0.3171 - accuracy: 0.8949/93 [==============>...............] - ETA: 1s - loss: 0.3149 - accuracy: 0.8951/93 [===============>..............] - ETA: 1s - loss: 0.3156 - accuracy: 0.8953/93 [================>.............] - ETA: 1s - loss: 0.3162 - accuracy: 0.8955/93 [================>.............] - ETA: 1s - loss: 0.3151 - accuracy: 0.8957/93 [=================>............] - ETA: 1s - loss: 0.3155 - accuracy: 0.8959/93 [==================>...........] - ETA: 1s - loss: 0.3134 - accuracy: 0.9061/93 [==================>...........] - ETA: 1s - loss: 0.3160 - accuracy: 0.8963/93 [===================>..........] - ETA: 0s - loss: 0.3158 - accuracy: 0.8965/93 [===================>..........] - ETA: 0s - loss: 0.3152 - accuracy: 0.8967/93 [====================>.........] - ETA: 0s - loss: 0.3169 - accuracy: 0.8969/93 [=====================>........] - ETA: 0s - loss: 0.3170 - accuracy: 0.8971/93 [=====================>........] - ETA: 0s - loss: 0.3180 - accuracy: 0.8973/93 [======================>.......] - ETA: 0s - loss: 0.3174 - accuracy: 0.8975/93 [=======================>......] - ETA: 0s - loss: 0.3164 - accuracy: 0.9077/93 [=======================>......] - ETA: 0s - loss: 0.3140 - accuracy: 0.9079/93 [========================>.....] - ETA: 0s - loss: 0.3139 - accuracy: 0.9081/93 [=========================>....] - ETA: 0s - loss: 0.3134 - accuracy: 0.9083/93 [=========================>....] - ETA: 0s - loss: 0.3128 - accuracy: 0.9085/93 [==========================>...] - ETA: 0s - loss: 0.3140 - accuracy: 0.9087/93 [===========================>..] - ETA: 0s - loss: 0.3147 - accuracy: 0.9089/93 [===========================>..] - ETA: 0s - loss: 0.3142 - accuracy: 0.9091/93 [============================>.] - ETA: 0s - loss: 0.3130 - accuracy: 0.9093/93 [==============================] - ETA: 0s - loss: 0.3134 - accuracy: 0.9093/93 [==============================] - 3s 36ms/step - loss: 0.3134 - accuracy: 0.9019 - val_loss: 0.4583 - val_accuracy: 0.8398\nEpoch 99/100\n 1/93 [..............................] - ETA: 0s - loss: 0.2247 - accuracy: 0.93 3/93 [..............................] - ETA: 1s - loss: 0.2291 - accuracy: 0.92 5/93 [>.............................] - ETA: 2s - loss: 0.2479 - accuracy: 0.91 7/93 [=>............................] - ETA: 2s - loss: 0.2567 - accuracy: 0.91 9/93 [=>............................] - ETA: 2s - loss: 0.2711 - accuracy: 0.9111/93 [==>...........................] - ETA: 2s - loss: 0.2795 - accuracy: 0.9113/93 [===>..........................] - ETA: 2s - loss: 0.2862 - accuracy: 0.9015/93 [===>..........................] - ETA: 2s - loss: 0.2909 - accuracy: 0.9017/93 [====>.........................] - ETA: 2s - loss: 0.3002 - accuracy: 0.9019/93 [=====>........................] - ETA: 2s - loss: 0.3051 - accuracy: 0.9021/93 [=====>........................] - ETA: 2s - loss: 0.3058 - accuracy: 0.9023/93 [======>.......................] - ETA: 2s - loss: 0.3093 - accuracy: 0.9025/93 [=======>......................] - ETA: 2s - loss: 0.3106 - accuracy: 0.9027/93 [=======>......................] - ETA: 2s - loss: 0.3069 - accuracy: 0.9029/93 [========>.....................] - ETA: 1s - loss: 0.3022 - accuracy: 0.9031/93 [=========>....................] - ETA: 1s - loss: 0.3042 - accuracy: 0.9033/93 [=========>....................] - ETA: 1s - loss: 0.3077 - accuracy: 0.9035/93 [==========>...................] - ETA: 1s - loss: 0.3076 - accuracy: 0.9037/93 [==========>...................] - ETA: 1s - loss: 0.3108 - accuracy: 0.9039/93 [===========>..................] - ETA: 1s - loss: 0.3110 - accuracy: 0.9041/93 [============>.................] - ETA: 1s - loss: 0.3157 - accuracy: 0.9043/93 [============>.................] - ETA: 1s - loss: 0.3168 - accuracy: 0.9045/93 [=============>................] - ETA: 1s - loss: 0.3184 - accuracy: 0.8947/93 [==============>...............] - ETA: 1s - loss: 0.3158 - accuracy: 0.9049/93 [==============>...............] - ETA: 1s - loss: 0.3145 - accuracy: 0.9051/93 [===============>..............] - ETA: 1s - loss: 0.3130 - accuracy: 0.9053/93 [================>.............] - ETA: 1s - loss: 0.3128 - accuracy: 0.9055/93 [================>.............] - ETA: 1s - loss: 0.3144 - accuracy: 0.9057/93 [=================>............] - ETA: 1s - loss: 0.3117 - accuracy: 0.9059/93 [==================>...........] - ETA: 1s - loss: 0.3123 - accuracy: 0.9061/93 [==================>...........] - ETA: 0s - loss: 0.3141 - accuracy: 0.9063/93 [===================>..........] - ETA: 0s - loss: 0.3158 - accuracy: 0.9065/93 [===================>..........] - ETA: 0s - loss: 0.3134 - accuracy: 0.9067/93 [====================>.........] - ETA: 0s - loss: 0.3115 - accuracy: 0.9069/93 [=====================>........] - ETA: 0s - loss: 0.3121 - accuracy: 0.9071/93 [=====================>........] - ETA: 0s - loss: 0.3124 - accuracy: 0.9073/93 [======================>.......] - ETA: 0s - loss: 0.3110 - accuracy: 0.9075/93 [=======================>......] - ETA: 0s - loss: 0.3134 - accuracy: 0.9077/93 [=======================>......] - ETA: 0s - loss: 0.3136 - accuracy: 0.9079/93 [========================>.....] - ETA: 0s - loss: 0.3128 - accuracy: 0.9081/93 [=========================>....] - ETA: 0s - loss: 0.3093 - accuracy: 0.9083/93 [=========================>....] - ETA: 0s - loss: 0.3086 - accuracy: 0.9085/93 [==========================>...] - ETA: 0s - loss: 0.3086 - accuracy: 0.9087/93 [===========================>..] - ETA: 0s - loss: 0.3103 - accuracy: 0.9089/93 [===========================>..] - ETA: 0s - loss: 0.3100 - accuracy: 0.9091/93 [============================>.] - ETA: 0s - loss: 0.3104 - accuracy: 0.9093/93 [==============================] - ETA: 0s - loss: 0.3092 - accuracy: 0.9093/93 [==============================] - 3s 36ms/step - loss: 0.3092 - accuracy: 0.9032 - val_loss: 0.4571 - val_accuracy: 0.8385\nEpoch 100/100\n 1/93 [..............................] - ETA: 0s - loss: 0.2512 - accuracy: 0.92 3/93 [..............................] - ETA: 1s - loss: 0.3126 - accuracy: 0.89 5/93 [>.............................] - ETA: 2s - loss: 0.2882 - accuracy: 0.90 7/93 [=>............................] - ETA: 2s - loss: 0.2878 - accuracy: 0.91 9/93 [=>............................] - ETA: 2s - loss: 0.2821 - accuracy: 0.9111/93 [==>...........................] - ETA: 2s - loss: 0.2744 - accuracy: 0.9113/93 [===>..........................] - ETA: 2s - loss: 0.2800 - accuracy: 0.9115/93 [===>..........................] - ETA: 2s - loss: 0.2728 - accuracy: 0.9117/93 [====>.........................] - ETA: 2s - loss: 0.2809 - accuracy: 0.9119/93 [=====>........................] - ETA: 2s - loss: 0.2836 - accuracy: 0.9121/93 [=====>........................] - ETA: 2s - loss: 0.2849 - accuracy: 0.9123/93 [======>.......................] - ETA: 2s - loss: 0.2876 - accuracy: 0.9125/93 [=======>......................] - ETA: 2s - loss: 0.2807 - accuracy: 0.9127/93 [=======>......................] - ETA: 1s - loss: 0.2869 - accuracy: 0.9129/93 [========>.....................] - ETA: 1s - loss: 0.2839 - accuracy: 0.9131/93 [=========>....................] - ETA: 1s - loss: 0.2877 - accuracy: 0.9033/93 [=========>....................] - ETA: 1s - loss: 0.2850 - accuracy: 0.9135/93 [==========>...................] - ETA: 1s - loss: 0.2850 - accuracy: 0.9037/93 [==========>...................] - ETA: 1s - loss: 0.2855 - accuracy: 0.9039/93 [===========>..................] - ETA: 1s - loss: 0.2894 - accuracy: 0.9041/93 [============>.................] - ETA: 1s - loss: 0.2916 - accuracy: 0.9043/93 [============>.................] - ETA: 1s - loss: 0.2939 - accuracy: 0.9045/93 [=============>................] - ETA: 1s - loss: 0.2939 - accuracy: 0.9047/93 [==============>...............] - ETA: 1s - loss: 0.2957 - accuracy: 0.9049/93 [==============>...............] - ETA: 1s - loss: 0.2950 - accuracy: 0.9051/93 [===============>..............] - ETA: 1s - loss: 0.2964 - accuracy: 0.9053/93 [================>.............] - ETA: 1s - loss: 0.2965 - accuracy: 0.9055/93 [================>.............] - ETA: 1s - loss: 0.2939 - accuracy: 0.9057/93 [=================>............] - ETA: 1s - loss: 0.2954 - accuracy: 0.9059/93 [==================>...........] - ETA: 1s - loss: 0.2966 - accuracy: 0.9061/93 [==================>...........] - ETA: 0s - loss: 0.2968 - accuracy: 0.9063/93 [===================>..........] - ETA: 0s - loss: 0.2961 - accuracy: 0.9065/93 [===================>..........] - ETA: 0s - loss: 0.2940 - accuracy: 0.9067/93 [====================>.........] - ETA: 0s - loss: 0.2959 - accuracy: 0.9069/93 [=====================>........] - ETA: 0s - loss: 0.2948 - accuracy: 0.9071/93 [=====================>........] - ETA: 0s - loss: 0.2949 - accuracy: 0.9073/93 [======================>.......] - ETA: 0s - loss: 0.2988 - accuracy: 0.9075/93 [=======================>......] - ETA: 0s - loss: 0.3001 - accuracy: 0.9077/93 [=======================>......] - ETA: 0s - loss: 0.3005 - accuracy: 0.9079/93 [========================>.....] - ETA: 0s - loss: 0.3022 - accuracy: 0.9081/93 [=========================>....] - ETA: 0s - loss: 0.3031 - accuracy: 0.9083/93 [=========================>....] - ETA: 0s - loss: 0.3037 - accuracy: 0.9085/93 [==========================>...] - ETA: 0s - loss: 0.3028 - accuracy: 0.9087/93 [===========================>..] - ETA: 0s - loss: 0.3044 - accuracy: 0.9089/93 [===========================>..] - ETA: 0s - loss: 0.3052 - accuracy: 0.9091/93 [============================>.] - ETA: 0s - loss: 0.3059 - accuracy: 0.9093/93 [==============================] - ETA: 0s - loss: 0.3067 - accuracy: 0.9093/93 [==============================] - 3s 36ms/step - loss: 0.3067 - accuracy: 0.9037 - val_loss: 0.4551 - val_accuracy: 0.8415\n"
    }
   ],
   "source": [
    "model_history = model.fit(x_train, y_train, batch_size=param_list[\"BATCH_SIZE\"], validation_split=0.2, epochs=param_list[\"EPOCHS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([[[6.1038168e-05, 9.8713338e-01, 6.2270291e-09, ...,\n          6.7727048e-21, 2.3094301e-11, 2.6334306e-11],\n         [8.0672351e-07, 2.2673817e-02, 8.1424520e-12, ...,\n          4.0316848e-22, 1.2918821e-14, 1.5611544e-14],\n         [2.5613365e-06, 7.0023197e-01, 9.7059321e-09, ...,\n          5.1029115e-18, 2.8300067e-13, 3.4164991e-13],\n         ...,\n         [1.6759045e-06, 4.8838500e-02, 2.2756441e-10, ...,\n          2.6029939e-18, 4.0208989e-14, 4.7051952e-14],\n         [5.7494722e-06, 6.5169364e-01, 1.1887892e-08, ...,\n          2.3820406e-16, 8.6826640e-13, 1.0649063e-12],\n         [2.2729300e-06, 5.4909896e-02, 7.6255331e-09, ...,\n          1.0153624e-17, 2.8463692e-12, 3.1653406e-12]]], dtype=float32),\n (1, 8, 14882))"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "result = model.predict(x_train[10000].reshape(1, -1, 1))\n",
    "result, result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"version/{}/model.h5\".format(timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597676927149",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'20200818-002519'"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = \"logs/fit/\" + timestamp\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "version_dir = \"version/\" + timestamp \n",
    "\n",
    "os.makedirs(version_dir)\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"SEG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "             t          t+1  delta  tokenized_data\n0  93220738952  93220738952      0               0\n1  93220738952  93220738952      0               0\n2  93220738952  93220738952      0               0\n3  93220738952  93220738952      0               0\n4  93220738952  93220738952      0               0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t</th>\n      <th>t+1</th>\n      <th>delta</th>\n      <th>tokenized_data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>93220738952</td>\n      <td>93220738952</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>93220738952</td>\n      <td>93220738952</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>93220738952</td>\n      <td>93220738952</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>93220738952</td>\n      <td>93220738952</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>93220738952</td>\n      <td>93220738952</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"data/{}_train_set.csv\".format(dataset_name))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = dict()\n",
    "\n",
    "param_list[\"PAST_HISTORY\"] = 16\n",
    "param_list[\"FUTURE_TARGET\"] = 8\n",
    "param_list[\"BATCH_SIZE\"] = 1024\n",
    "param_list[\"EPOCHS\"] = 500\n",
    "param_list[\"BUFFER_SIZE\"] = 200000\n",
    "param_list[\"NUM_1_NEURONS\"] = 128\n",
    "param_list[\"NUM_2_NEURONS\"] = 64\n",
    "\n",
    "with open(\"version/{}/params.json\".format(timestamp), \"w\") as p:\n",
    "    json.dump(param_list, p, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timeseries(dataset, start_index, end_index, history_size, target_size, n_features):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i)\n",
    "        # Reshape data from (history_size,) to (history_size, n_feature)\n",
    "        data.append(np.reshape(dataset[indices], (history_size, n_features)))\n",
    "        labels.append(dataset[i:i+target_size])\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(<1x87 sparse matrix of type '<class 'numpy.float32'>'\n \twith 1 stored elements in Compressed Sparse Row format>,\n [array([-909517620, -515913384,    -192512,     -61440,     -32768,\n             -20480,     -16384,     -12288,      -8304,      -8192,\n              -5888,      -4096,      -4040,      -2884,      -2744,\n               -432,       -240,        -48,        -24,        -16,\n                -12,         -8,         -4,         -1,          0,\n                  2,          4,          6,          8,         16,\n                 24,         28,         32,         36,         44,\n                 48,         56,         64,         76,        240,\n                256,        432,       2416,       3072,       3520,\n               3856,       3904,       3936,       4080,       4092,\n               4096,       4104,       4112,       4128,       5280,\n               6144,       8192,      11776,      12288,      16384,\n              17664,      20480,      24576,      28672,      32768,\n              36864,      40960,      53248,      61440,      69632,\n              77824,      81920,      90112,      94208,      98304,\n             106496,     118784,     126976,     131072,     135168,\n             172032,     184320,     241664,     274432,     376832,\n          515913384,  909517620], dtype=int64)])"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(dtype=np.float32)\n",
    "encoded_data = encoder.fit_transform(dataset[\"tokenized_data\"].values.reshape(-1, 1))\n",
    "encoded_data[0], encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((176109, 16, 87), (176109, 8, 87))"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "x_train, y_train = generate_timeseries(encoded_data.toarray(), 0, None, param_list[\"PAST_HISTORY\"], param_list[\"FUTURE_TARGET\"], len(encoder.categories_[0]))\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(param_list[\"NUM_1_NEURONS\"])))\n",
    "model.add(tf.keras.layers.Dropout(0.1))\n",
    "model.add(tf.keras.layers.RepeatVector(param_list[\"FUTURE_TARGET\"]))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(param_list[\"NUM_2_NEURONS\"], return_sequences=True)))\n",
    "model.add(tf.keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.TimeDistributed(tf.keras.layers.Dense(len(encoder.categories_[0]), activation=\"softmax\")))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "och 364/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2635 - accuracy: 0.9346 - val_loss: 0.8090 - val_accuracy: 0.8704\nEpoch 365/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2633 - accuracy: 0.9345 - val_loss: 0.8140 - val_accuracy: 0.8699\nEpoch 366/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2637 - accuracy: 0.9346 - val_loss: 0.8015 - val_accuracy: 0.8699\nEpoch 367/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2632 - accuracy: 0.9345 - val_loss: 0.8095 - val_accuracy: 0.8695\nEpoch 368/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2630 - accuracy: 0.9346 - val_loss: 0.7983 - val_accuracy: 0.8691\nEpoch 369/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2625 - accuracy: 0.9346 - val_loss: 0.8063 - val_accuracy: 0.8702\nEpoch 370/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2630 - accuracy: 0.9346 - val_loss: 0.8038 - val_accuracy: 0.8693\nEpoch 371/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2628 - accuracy: 0.9347 - val_loss: 0.7964 - val_accuracy: 0.8697\nEpoch 372/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2624 - accuracy: 0.9349 - val_loss: 0.8127 - val_accuracy: 0.8707\nEpoch 373/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2626 - accuracy: 0.9348 - val_loss: 0.8003 - val_accuracy: 0.8707\nEpoch 374/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2621 - accuracy: 0.9351 - val_loss: 0.8170 - val_accuracy: 0.8693\nEpoch 375/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2620 - accuracy: 0.9349 - val_loss: 0.7997 - val_accuracy: 0.8701\nEpoch 376/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2618 - accuracy: 0.9351 - val_loss: 0.8036 - val_accuracy: 0.8700\nEpoch 377/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2626 - accuracy: 0.9347 - val_loss: 0.8076 - val_accuracy: 0.8698\nEpoch 378/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2618 - accuracy: 0.9351 - val_loss: 0.7953 - val_accuracy: 0.8704\nEpoch 379/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2617 - accuracy: 0.9352 - val_loss: 0.8031 - val_accuracy: 0.8703\nEpoch 380/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2619 - accuracy: 0.9351 - val_loss: 0.8022 - val_accuracy: 0.8699\nEpoch 381/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2616 - accuracy: 0.9352 - val_loss: 0.8106 - val_accuracy: 0.8687\nEpoch 382/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2614 - accuracy: 0.9352 - val_loss: 0.8034 - val_accuracy: 0.8702\nEpoch 383/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2616 - accuracy: 0.9351 - val_loss: 0.8068 - val_accuracy: 0.8698\nEpoch 384/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2610 - accuracy: 0.9353 - val_loss: 0.8034 - val_accuracy: 0.8697\nEpoch 385/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2614 - accuracy: 0.9352 - val_loss: 0.8072 - val_accuracy: 0.8703\nEpoch 386/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2613 - accuracy: 0.9351 - val_loss: 0.8073 - val_accuracy: 0.8700\nEpoch 387/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2619 - accuracy: 0.9350 - val_loss: 0.8070 - val_accuracy: 0.8698\nEpoch 388/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2616 - accuracy: 0.9352 - val_loss: 0.8034 - val_accuracy: 0.8692\nEpoch 389/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2611 - accuracy: 0.9354 - val_loss: 0.8128 - val_accuracy: 0.8688\nEpoch 390/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2616 - accuracy: 0.9353 - val_loss: 0.8067 - val_accuracy: 0.8698\nEpoch 391/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2609 - accuracy: 0.9354 - val_loss: 0.8023 - val_accuracy: 0.8694\nEpoch 392/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2601 - accuracy: 0.9355 - val_loss: 0.7985 - val_accuracy: 0.8704\nEpoch 393/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2607 - accuracy: 0.9356 - val_loss: 0.8117 - val_accuracy: 0.8693\nEpoch 394/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2607 - accuracy: 0.9355 - val_loss: 0.8055 - val_accuracy: 0.8705\nEpoch 395/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2613 - accuracy: 0.9354 - val_loss: 0.8164 - val_accuracy: 0.8690\nEpoch 396/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2612 - accuracy: 0.9355 - val_loss: 0.8095 - val_accuracy: 0.8692\nEpoch 397/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2603 - accuracy: 0.9357 - val_loss: 0.8216 - val_accuracy: 0.8699\nEpoch 398/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2604 - accuracy: 0.9356 - val_loss: 0.8070 - val_accuracy: 0.8697\nEpoch 399/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2603 - accuracy: 0.9356 - val_loss: 0.8190 - val_accuracy: 0.8700\nEpoch 400/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2601 - accuracy: 0.9358 - val_loss: 0.8207 - val_accuracy: 0.8695\nEpoch 401/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2597 - accuracy: 0.9358 - val_loss: 0.8142 - val_accuracy: 0.8694\nEpoch 402/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2607 - accuracy: 0.9356 - val_loss: 0.8117 - val_accuracy: 0.8694\nEpoch 403/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2603 - accuracy: 0.9356 - val_loss: 0.8090 - val_accuracy: 0.8689\nEpoch 404/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2596 - accuracy: 0.9360 - val_loss: 0.8223 - val_accuracy: 0.8698\nEpoch 405/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2598 - accuracy: 0.9358 - val_loss: 0.8109 - val_accuracy: 0.8702\nEpoch 406/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2599 - accuracy: 0.9359 - val_loss: 0.8040 - val_accuracy: 0.8705\nEpoch 407/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2593 - accuracy: 0.9359 - val_loss: 0.8090 - val_accuracy: 0.8708\nEpoch 408/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2602 - accuracy: 0.9355 - val_loss: 0.8149 - val_accuracy: 0.8713\nEpoch 409/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2601 - accuracy: 0.9357 - val_loss: 0.8153 - val_accuracy: 0.8688\nEpoch 410/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2593 - accuracy: 0.9361 - val_loss: 0.8140 - val_accuracy: 0.8699\nEpoch 411/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2591 - accuracy: 0.9360 - val_loss: 0.8128 - val_accuracy: 0.8715\nEpoch 412/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2596 - accuracy: 0.9359 - val_loss: 0.8174 - val_accuracy: 0.8699\nEpoch 413/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2591 - accuracy: 0.9362 - val_loss: 0.8220 - val_accuracy: 0.8695\nEpoch 414/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2589 - accuracy: 0.9360 - val_loss: 0.8249 - val_accuracy: 0.8692\nEpoch 415/500\n138/138 [==============================] - 3s 21ms/step - loss: 0.2587 - accuracy: 0.9361 - val_loss: 0.8173 - val_accuracy: 0.8682\nEpoch 416/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2584 - accuracy: 0.9363 - val_loss: 0.8219 - val_accuracy: 0.8686\nEpoch 417/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2587 - accuracy: 0.9363 - val_loss: 0.8173 - val_accuracy: 0.8695\nEpoch 418/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2584 - accuracy: 0.9364 - val_loss: 0.8196 - val_accuracy: 0.8697\nEpoch 419/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2589 - accuracy: 0.9360 - val_loss: 0.8259 - val_accuracy: 0.8696\nEpoch 420/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2588 - accuracy: 0.9364 - val_loss: 0.8181 - val_accuracy: 0.8695\nEpoch 421/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2588 - accuracy: 0.9361 - val_loss: 0.8174 - val_accuracy: 0.8686\nEpoch 422/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2592 - accuracy: 0.9361 - val_loss: 0.8138 - val_accuracy: 0.8702\nEpoch 423/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2587 - accuracy: 0.9362 - val_loss: 0.8161 - val_accuracy: 0.8694\nEpoch 424/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2581 - accuracy: 0.9364 - val_loss: 0.8253 - val_accuracy: 0.8684\nEpoch 425/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2587 - accuracy: 0.9363 - val_loss: 0.8251 - val_accuracy: 0.8689\nEpoch 426/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2582 - accuracy: 0.9363 - val_loss: 0.8239 - val_accuracy: 0.8691\nEpoch 427/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2582 - accuracy: 0.9363 - val_loss: 0.8158 - val_accuracy: 0.8701\nEpoch 428/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2581 - accuracy: 0.9364 - val_loss: 0.8241 - val_accuracy: 0.8695\nEpoch 429/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2579 - accuracy: 0.9363 - val_loss: 0.8285 - val_accuracy: 0.8694\nEpoch 430/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2574 - accuracy: 0.9366 - val_loss: 0.8313 - val_accuracy: 0.8696\nEpoch 431/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2577 - accuracy: 0.9365 - val_loss: 0.8309 - val_accuracy: 0.8688\nEpoch 432/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2575 - accuracy: 0.9366 - val_loss: 0.8204 - val_accuracy: 0.8685\nEpoch 433/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2575 - accuracy: 0.9366 - val_loss: 0.8238 - val_accuracy: 0.8700\nEpoch 434/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2574 - accuracy: 0.9367 - val_loss: 0.8073 - val_accuracy: 0.8710\nEpoch 435/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2576 - accuracy: 0.9365 - val_loss: 0.8211 - val_accuracy: 0.8690\nEpoch 436/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2583 - accuracy: 0.9363 - val_loss: 0.8215 - val_accuracy: 0.8694\nEpoch 437/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2575 - accuracy: 0.9366 - val_loss: 0.8272 - val_accuracy: 0.8698\nEpoch 438/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2574 - accuracy: 0.9366 - val_loss: 0.8285 - val_accuracy: 0.8702\nEpoch 439/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2571 - accuracy: 0.9366 - val_loss: 0.8245 - val_accuracy: 0.8699\nEpoch 440/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2568 - accuracy: 0.9368 - val_loss: 0.8291 - val_accuracy: 0.8688\nEpoch 441/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2572 - accuracy: 0.9369 - val_loss: 0.8258 - val_accuracy: 0.8696\nEpoch 442/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2571 - accuracy: 0.9368 - val_loss: 0.8346 - val_accuracy: 0.8702\nEpoch 443/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2576 - accuracy: 0.9366 - val_loss: 0.8415 - val_accuracy: 0.8686\nEpoch 444/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2574 - accuracy: 0.9368 - val_loss: 0.8312 - val_accuracy: 0.8697\nEpoch 445/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2572 - accuracy: 0.9368 - val_loss: 0.8290 - val_accuracy: 0.8681\nEpoch 446/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2566 - accuracy: 0.9369 - val_loss: 0.8285 - val_accuracy: 0.8696\nEpoch 447/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2562 - accuracy: 0.9370 - val_loss: 0.8338 - val_accuracy: 0.8689\nEpoch 448/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2566 - accuracy: 0.9368 - val_loss: 0.8274 - val_accuracy: 0.8697\nEpoch 449/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2565 - accuracy: 0.9370 - val_loss: 0.8335 - val_accuracy: 0.8694\nEpoch 450/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2560 - accuracy: 0.9371 - val_loss: 0.8298 - val_accuracy: 0.8704\nEpoch 451/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2563 - accuracy: 0.9370 - val_loss: 0.8273 - val_accuracy: 0.8696\nEpoch 452/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2560 - accuracy: 0.9372 - val_loss: 0.8331 - val_accuracy: 0.8699\nEpoch 453/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2567 - accuracy: 0.9368 - val_loss: 0.8363 - val_accuracy: 0.8689\nEpoch 454/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2564 - accuracy: 0.9370 - val_loss: 0.8216 - val_accuracy: 0.8703\nEpoch 455/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2562 - accuracy: 0.9372 - val_loss: 0.8364 - val_accuracy: 0.8694\nEpoch 456/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2569 - accuracy: 0.9368 - val_loss: 0.8290 - val_accuracy: 0.8691\nEpoch 457/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2561 - accuracy: 0.9372 - val_loss: 0.8326 - val_accuracy: 0.8693\nEpoch 458/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2559 - accuracy: 0.9372 - val_loss: 0.8346 - val_accuracy: 0.8697\nEpoch 459/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2551 - accuracy: 0.9374 - val_loss: 0.8253 - val_accuracy: 0.8684\nEpoch 460/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2553 - accuracy: 0.9375 - val_loss: 0.8282 - val_accuracy: 0.8690\nEpoch 461/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2551 - accuracy: 0.9375 - val_loss: 0.8318 - val_accuracy: 0.8692\nEpoch 462/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2557 - accuracy: 0.9373 - val_loss: 0.8294 - val_accuracy: 0.8689\nEpoch 463/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2552 - accuracy: 0.9374 - val_loss: 0.8384 - val_accuracy: 0.8690\nEpoch 464/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2557 - accuracy: 0.9373 - val_loss: 0.8329 - val_accuracy: 0.8694\nEpoch 465/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2555 - accuracy: 0.9372 - val_loss: 0.8290 - val_accuracy: 0.8687\nEpoch 466/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2558 - accuracy: 0.9373 - val_loss: 0.8297 - val_accuracy: 0.8691\nEpoch 467/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2552 - accuracy: 0.9374 - val_loss: 0.8282 - val_accuracy: 0.8683\nEpoch 468/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2550 - accuracy: 0.9375 - val_loss: 0.8342 - val_accuracy: 0.8689\nEpoch 469/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2554 - accuracy: 0.9372 - val_loss: 0.8485 - val_accuracy: 0.8679\nEpoch 470/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2559 - accuracy: 0.9372 - val_loss: 0.8340 - val_accuracy: 0.8679\nEpoch 471/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2550 - accuracy: 0.9375 - val_loss: 0.8547 - val_accuracy: 0.8677\nEpoch 472/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2552 - accuracy: 0.9373 - val_loss: 0.8455 - val_accuracy: 0.8688\nEpoch 473/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2555 - accuracy: 0.9373 - val_loss: 0.8355 - val_accuracy: 0.8695\nEpoch 474/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2543 - accuracy: 0.9377 - val_loss: 0.8358 - val_accuracy: 0.8691\nEpoch 475/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2546 - accuracy: 0.9378 - val_loss: 0.8353 - val_accuracy: 0.8690\nEpoch 476/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2543 - accuracy: 0.9378 - val_loss: 0.8313 - val_accuracy: 0.8689\nEpoch 477/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2547 - accuracy: 0.9377 - val_loss: 0.8450 - val_accuracy: 0.8688\nEpoch 478/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2555 - accuracy: 0.9374 - val_loss: 0.8480 - val_accuracy: 0.8679\nEpoch 479/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2549 - accuracy: 0.9377 - val_loss: 0.8331 - val_accuracy: 0.8692\nEpoch 480/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2547 - accuracy: 0.9376 - val_loss: 0.8312 - val_accuracy: 0.8685\nEpoch 481/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2541 - accuracy: 0.9379 - val_loss: 0.8314 - val_accuracy: 0.8692\nEpoch 482/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2548 - accuracy: 0.9376 - val_loss: 0.8254 - val_accuracy: 0.8702\nEpoch 483/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2552 - accuracy: 0.9376 - val_loss: 0.8421 - val_accuracy: 0.8690\nEpoch 484/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2543 - accuracy: 0.9378 - val_loss: 0.8463 - val_accuracy: 0.8689\nEpoch 485/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2538 - accuracy: 0.9381 - val_loss: 0.8367 - val_accuracy: 0.8694\nEpoch 486/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2535 - accuracy: 0.9380 - val_loss: 0.8552 - val_accuracy: 0.8668\nEpoch 487/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2538 - accuracy: 0.9379 - val_loss: 0.8452 - val_accuracy: 0.8681\nEpoch 488/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2541 - accuracy: 0.9379 - val_loss: 0.8423 - val_accuracy: 0.8694\nEpoch 489/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2538 - accuracy: 0.9381 - val_loss: 0.8400 - val_accuracy: 0.8691\nEpoch 490/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2540 - accuracy: 0.9379 - val_loss: 0.8490 - val_accuracy: 0.8698\nEpoch 491/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2539 - accuracy: 0.9379 - val_loss: 0.8474 - val_accuracy: 0.8684\nEpoch 492/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2536 - accuracy: 0.9379 - val_loss: 0.8447 - val_accuracy: 0.8685\nEpoch 493/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2537 - accuracy: 0.9378 - val_loss: 0.8596 - val_accuracy: 0.8676\nEpoch 494/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2542 - accuracy: 0.9379 - val_loss: 0.8494 - val_accuracy: 0.8679\nEpoch 495/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2538 - accuracy: 0.9379 - val_loss: 0.8481 - val_accuracy: 0.8688\nEpoch 496/500\n138/138 [==============================] - 3s 20ms/step - loss: 0.2531 - accuracy: 0.9381 - val_loss: 0.8451 - val_accuracy: 0.8699\nEpoch 497/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2539 - accuracy: 0.9379 - val_loss: 0.8520 - val_accuracy: 0.8690\nEpoch 498/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2533 - accuracy: 0.9381 - val_loss: 0.8437 - val_accuracy: 0.8692\nEpoch 499/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2535 - accuracy: 0.9379 - val_loss: 0.8395 - val_accuracy: 0.8697\nEpoch 500/500\n138/138 [==============================] - 3s 19ms/step - loss: 0.2538 - accuracy: 0.9379 - val_loss: 0.8446 - val_accuracy: 0.8689\n"
    }
   ],
   "source": [
    "model_history = model.fit(x_train, y_train, batch_size=param_list[\"BATCH_SIZE\"], validation_split=0.2, epochs=param_list[\"EPOCHS\"])\n",
    "model.save(\"version/{}/model.h5\".format(timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "             t          t+1     delta  tokenized_data\n0  92892336072  92805776480 -86559592              -1\n1  92805776480  92805776656       176              -1\n2  92805776656  92806873264   1096608              -1\n3  92806873264  92806868361     -4903              -1\n4  92806868361  92806801536    -66825              -1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t</th>\n      <th>t+1</th>\n      <th>delta</th>\n      <th>tokenized_data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>92892336072</td>\n      <td>92805776480</td>\n      <td>-86559592</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>92805776480</td>\n      <td>92805776656</td>\n      <td>176</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>92805776656</td>\n      <td>92806873264</td>\n      <td>1096608</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>92806873264</td>\n      <td>92806868361</td>\n      <td>-4903</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>92806868361</td>\n      <td>92806801536</td>\n      <td>-66825</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "test_dataset = pd.read_csv(\"data/{}_test_set.csv\".format(dataset_name))\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(<1x87 sparse matrix of type '<class 'numpy.float32'>'\n \twith 1 stored elements in Compressed Sparse Row format>,\n [array([-909517620, -515913384,    -192512,     -61440,     -32768,\n             -20480,     -16384,     -12288,      -8304,      -8192,\n              -5888,      -4096,      -4040,      -2884,      -2744,\n               -432,       -240,        -48,        -24,        -16,\n                -12,         -8,         -4,         -1,          0,\n                  2,          4,          6,          8,         16,\n                 24,         28,         32,         36,         44,\n                 48,         56,         64,         76,        240,\n                256,        432,       2416,       3072,       3520,\n               3856,       3904,       3936,       4080,       4092,\n               4096,       4104,       4112,       4128,       5280,\n               6144,       8192,      11776,      12288,      16384,\n              17664,      20480,      24576,      28672,      32768,\n              36864,      40960,      53248,      61440,      69632,\n              77824,      81920,      90112,      94208,      98304,\n             106496,     118784,     126976,     131072,     135168,\n             172032,     184320,     241664,     274432,     376832,\n          515913384,  909517620], dtype=int64)])"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "test_encoder = OneHotEncoder(dtype=np.float32)\n",
    "encoded_test_data = encoder.transform(test_dataset[\"tokenized_data\"].values.reshape(-1, 1))\n",
    "encoded_test_data[0], encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = generate_timeseries(encoded_test_data.toarray(), 0, None, 16, 8, len(encoder.categories_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(16, 87)"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "x_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "for i in range(y_test.shape[0]):\n",
    "    y_true.extend(np.argmax(y_test[i], axis=1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in range(x_test.shape[0]):\n",
    "    y_pred.extend(np.argmax(model.predict(x_test[i].reshape(1, 16, len(encoder.categories_[0])))[0], axis=1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9018202497997853"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "with open(\"version/{}/accuracy.txt\".format(timestamp), \"w\") as t:\n",
    "    t.write(str(accuracy.tolist()))\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score       support\n0              0.000000  0.000000  0.000000       0.00000\n2              0.964912  0.859375  0.909091     128.00000\n3              0.969697  0.857143  0.909953     112.00000\n4              0.817460  0.715278  0.762963     144.00000\n5              1.000000  0.750000  0.857143     128.00000\n...                 ...       ...       ...           ...\n83             0.750000  0.573529  0.650000     136.00000\n84             0.880597  0.460938  0.605128     128.00000\naccuracy       0.901820  0.901820  0.901820       0.90182\nmacro avg      0.539198  0.362106  0.416084  469496.00000\nweighted avg   0.877072  0.901820  0.884304  469496.00000\n\n[87 rows x 4 columns]\n"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = pd.DataFrame(classification_report(y_true, y_pred, output_dict=True)).transpose()\n",
    "report.to_csv(\"version/{}/report.csv\".format(timestamp))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
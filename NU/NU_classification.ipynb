{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597475101354",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'20200815-170315'"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = \"logs/fit/\" + timestamp\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "version_dir = \"version/\" + timestamp \n",
    "\n",
    "os.makedirs(version_dir)\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              t           t+1    delta  tokenized_data\n0  104289271808  104282980352 -6291456        -6291456\n1  104282980352  104282984448     4096            4096\n2  104282984448  104282988544     4096            4096\n3  104282988544  104282992640     4096            4096\n4  104282992640  104282996736     4096            4096",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t</th>\n      <th>t+1</th>\n      <th>delta</th>\n      <th>tokenized_data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>104289271808</td>\n      <td>104282980352</td>\n      <td>-6291456</td>\n      <td>-6291456</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>104282980352</td>\n      <td>104282984448</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>104282984448</td>\n      <td>104282988544</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>104282988544</td>\n      <td>104282992640</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>104282992640</td>\n      <td>104282996736</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"data/NU_train_set.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = dict()\n",
    "\n",
    "param_list[\"PAST_HISTORY\"] = 16\n",
    "param_list[\"FUTURE_TARGET\"] = 8\n",
    "param_list[\"BATCH_SIZE\"] = 1024\n",
    "param_list[\"EPOCHS\"] = 250\n",
    "param_list[\"BUFFER_SIZE\"] = 200000\n",
    "\n",
    "with open(\"version/{}/params.json\".format(timestamp), \"w\") as p:\n",
    "    json.dump(param_list, p, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timeseries(dataset, start_index, end_index, history_size, target_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i)\n",
    "        # Reshape data from (history_size,) to (history_size, n_feature)\n",
    "        data.append(np.reshape(dataset[indices], (history_size, 5)))\n",
    "        labels.append(dataset[i:i+target_size])\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(<1x5 sparse matrix of type '<class 'numpy.float32'>'\n \twith 1 stored elements in Compressed Sparse Row format>,\n [array([-6291456,       -1,        0,     4096,  2097152], dtype=int64)])"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(dtype=np.float32)   #dtype=np.int64\n",
    "encoded_data = encoder.fit_transform(dataset[\"tokenized_data\"].values.reshape(-1, 1))\n",
    "encoded_data[0], encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(encoder, \"data/encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = generate_timeseries(encoded_data.toarray(), 0, None, param_list[\"PAST_HISTORY\"], param_list[\"FUTURE_TARGET\"])\n",
    "\n",
    "#train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "#train_data = train_data.cache().shuffle(param_list[\"BUFFER_SIZE\"]).batch(param_list[\"BATCH_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(47165, 16, 5)"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(47165, 8, 5)"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(5))  #x_train.shape[-2:] , input_shape=[16, 5] , return_sequences=True\n",
    "#model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.RepeatVector(8))\n",
    "model.add(keras.layers.TimeDistributed(tf.keras.layers.Dense(5, activation=\"softmax\")))\n",
    "#model.add(tf.keras.layers.Flatten())\n",
    "#model.add(tf.keras.layers.Dense(5, activation=\"softmax\"))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(5)))  #x_train.shape[-2:] , input_shape=[16, 5] , return_sequences=True\n",
    "model.add(tf.keras.layers.RepeatVector(8))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(5, return_sequences=True)))\n",
    "model.add(keras.layers.TimeDistributed(tf.keras.layers.Dense(5, activation=\"softmax\")))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "l_loss: 0.0197 - val_accuracy: 0.9966\nEpoch 113/250\n37/37 [==============================] - 1s 25ms/step - loss: 0.0365 - accuracy: 0.9909 - val_loss: 0.0197 - val_accuracy: 0.9966\nEpoch 114/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0365 - accuracy: 0.9910 - val_loss: 0.0197 - val_accuracy: 0.9968\nEpoch 115/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0366 - accuracy: 0.9911 - val_loss: 0.0196 - val_accuracy: 0.9967\nEpoch 116/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0365 - accuracy: 0.9910 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 117/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0365 - accuracy: 0.9910 - val_loss: 0.0196 - val_accuracy: 0.9967\nEpoch 118/250\n37/37 [==============================] - 1s 37ms/step - loss: 0.0365 - accuracy: 0.9910 - val_loss: 0.0197 - val_accuracy: 0.9966\nEpoch 119/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0364 - accuracy: 0.9910 - val_loss: 0.0199 - val_accuracy: 0.9967\nEpoch 120/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0364 - accuracy: 0.9910 - val_loss: 0.0196 - val_accuracy: 0.9966\nEpoch 121/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0364 - accuracy: 0.9910 - val_loss: 0.0196 - val_accuracy: 0.9966\nEpoch 122/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0365 - accuracy: 0.9910 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 123/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0364 - accuracy: 0.9910 - val_loss: 0.0195 - val_accuracy: 0.9966\nEpoch 124/250\n37/37 [==============================] - 3s 90ms/step - loss: 0.0364 - accuracy: 0.9910 - val_loss: 0.0196 - val_accuracy: 0.9966\nEpoch 125/250\n37/37 [==============================] - 2s 46ms/step - loss: 0.0365 - accuracy: 0.9910 - val_loss: 0.0194 - val_accuracy: 0.9968\nEpoch 126/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0364 - accuracy: 0.9910 - val_loss: 0.0199 - val_accuracy: 0.9966\nEpoch 127/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0364 - accuracy: 0.9910 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 128/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0364 - accuracy: 0.9910 - val_loss: 0.0196 - val_accuracy: 0.9966\nEpoch 129/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0364 - accuracy: 0.9911 - val_loss: 0.0196 - val_accuracy: 0.9967\nEpoch 130/250\n37/37 [==============================] - 1s 23ms/step - loss: 0.0363 - accuracy: 0.9910 - val_loss: 0.0196 - val_accuracy: 0.9966\nEpoch 131/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0363 - accuracy: 0.9911 - val_loss: 0.0198 - val_accuracy: 0.9966\nEpoch 132/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0363 - accuracy: 0.9911 - val_loss: 0.0200 - val_accuracy: 0.9966\nEpoch 133/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0364 - accuracy: 0.9911 - val_loss: 0.0198 - val_accuracy: 0.9966\nEpoch 134/250\n37/37 [==============================] - 1s 26ms/step - loss: 0.0363 - accuracy: 0.9911 - val_loss: 0.0202 - val_accuracy: 0.9967\nEpoch 135/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0363 - accuracy: 0.9911 - val_loss: 0.0196 - val_accuracy: 0.9966\nEpoch 136/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0363 - accuracy: 0.9911 - val_loss: 0.0199 - val_accuracy: 0.9966\nEpoch 137/250\n37/37 [==============================] - 2s 43ms/step - loss: 0.0363 - accuracy: 0.9911 - val_loss: 0.0194 - val_accuracy: 0.9968\nEpoch 138/250\n37/37 [==============================] - 4s 117ms/step - loss: 0.0362 - accuracy: 0.9911 - val_loss: 0.0200 - val_accuracy: 0.9967\nEpoch 139/250\n37/37 [==============================] - 3s 93ms/step - loss: 0.0363 - accuracy: 0.9911 - val_loss: 0.0198 - val_accuracy: 0.9966\nEpoch 140/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0363 - accuracy: 0.9911 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 141/250\n37/37 [==============================] - 1s 20ms/step - loss: 0.0362 - accuracy: 0.9911 - val_loss: 0.0196 - val_accuracy: 0.9967\nEpoch 142/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0362 - accuracy: 0.9911 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 143/250\n37/37 [==============================] - 1s 23ms/step - loss: 0.0362 - accuracy: 0.9911 - val_loss: 0.0195 - val_accuracy: 0.9968\nEpoch 144/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0362 - accuracy: 0.9911 - val_loss: 0.0198 - val_accuracy: 0.9966\nEpoch 145/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0362 - accuracy: 0.9911 - val_loss: 0.0197 - val_accuracy: 0.9967\nEpoch 146/250\n37/37 [==============================] - 5s 132ms/step - loss: 0.0361 - accuracy: 0.9911 - val_loss: 0.0197 - val_accuracy: 0.9967\nEpoch 147/250\n37/37 [==============================] - 1s 20ms/step - loss: 0.0361 - accuracy: 0.9912 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 148/250\n37/37 [==============================] - 1s 37ms/step - loss: 0.0361 - accuracy: 0.9911 - val_loss: 0.0197 - val_accuracy: 0.9967\nEpoch 149/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0361 - accuracy: 0.9911 - val_loss: 0.0197 - val_accuracy: 0.9967\nEpoch 150/250\n37/37 [==============================] - 2s 52ms/step - loss: 0.0361 - accuracy: 0.9911 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 151/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0361 - accuracy: 0.9911 - val_loss: 0.0197 - val_accuracy: 0.9967\nEpoch 152/250\n37/37 [==============================] - 1s 40ms/step - loss: 0.0360 - accuracy: 0.9911 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 153/250\n37/37 [==============================] - 3s 78ms/step - loss: 0.0361 - accuracy: 0.9911 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 154/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0360 - accuracy: 0.9911 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 155/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0360 - accuracy: 0.9911 - val_loss: 0.0197 - val_accuracy: 0.9967\nEpoch 156/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0361 - accuracy: 0.9911 - val_loss: 0.0197 - val_accuracy: 0.9966\nEpoch 157/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0360 - accuracy: 0.9911 - val_loss: 0.0198 - val_accuracy: 0.9967\nEpoch 158/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0359 - accuracy: 0.9911 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 159/250\n37/37 [==============================] - 1s 29ms/step - loss: 0.0360 - accuracy: 0.9911 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 160/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0360 - accuracy: 0.9912 - val_loss: 0.0194 - val_accuracy: 0.9968\nEpoch 161/250\n37/37 [==============================] - 1s 20ms/step - loss: 0.0359 - accuracy: 0.9911 - val_loss: 0.0194 - val_accuracy: 0.9966\nEpoch 162/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0360 - accuracy: 0.9911 - val_loss: 0.0194 - val_accuracy: 0.9966\nEpoch 163/250\n37/37 [==============================] - 4s 97ms/step - loss: 0.0360 - accuracy: 0.9911 - val_loss: 0.0196 - val_accuracy: 0.9967\nEpoch 164/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0359 - accuracy: 0.9911 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 165/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0360 - accuracy: 0.9911 - val_loss: 0.0194 - val_accuracy: 0.9966\nEpoch 166/250\n37/37 [==============================] - 3s 69ms/step - loss: 0.0359 - accuracy: 0.9911 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 167/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0358 - accuracy: 0.9911 - val_loss: 0.0195 - val_accuracy: 0.9966\nEpoch 168/250\n37/37 [==============================] - 1s 26ms/step - loss: 0.0359 - accuracy: 0.9912 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 169/250\n37/37 [==============================] - 13s 339ms/step - loss: 0.0359 - accuracy: 0.9912 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 170/250\n37/37 [==============================] - 1s 23ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 0.0194 - val_accuracy: 0.9966\nEpoch 171/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 172/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 173/250\n37/37 [==============================] - 1s 20ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 0.0197 - val_accuracy: 0.9966\nEpoch 174/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 0.0199 - val_accuracy: 0.9966\nEpoch 175/250\n37/37 [==============================] - 7s 180ms/step - loss: 0.0359 - accuracy: 0.9912 - val_loss: 0.0196 - val_accuracy: 0.9966\nEpoch 176/250\n37/37 [==============================] - 1s 23ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.0194 - val_accuracy: 0.9966\nEpoch 177/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 0.0194 - val_accuracy: 0.9966\nEpoch 178/250\n37/37 [==============================] - 1s 23ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 179/250\n37/37 [==============================] - 1s 20ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.0195 - val_accuracy: 0.9966\nEpoch 180/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.0198 - val_accuracy: 0.9966\nEpoch 181/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0359 - accuracy: 0.9912 - val_loss: 0.0198 - val_accuracy: 0.9967\nEpoch 182/250\n37/37 [==============================] - 1s 23ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 183/250\n37/37 [==============================] - 1s 37ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 0.0197 - val_accuracy: 0.9967\nEpoch 184/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.0194 - val_accuracy: 0.9968\nEpoch 185/250\n37/37 [==============================] - 1s 23ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 186/250\n37/37 [==============================] - 1s 20ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 187/250\n37/37 [==============================] - 1s 23ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 188/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.0203 - val_accuracy: 0.9965\nEpoch 189/250\n37/37 [==============================] - 1s 35ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.0196 - val_accuracy: 0.9967\nEpoch 190/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0356 - accuracy: 0.9913 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 191/250\n37/37 [==============================] - 2s 46ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 192/250\n37/37 [==============================] - 2s 53ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.0199 - val_accuracy: 0.9966\nEpoch 193/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.0199 - val_accuracy: 0.9965\nEpoch 194/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0356 - accuracy: 0.9913 - val_loss: 0.0192 - val_accuracy: 0.9967\nEpoch 195/250\n37/37 [==============================] - 1s 37ms/step - loss: 0.0357 - accuracy: 0.9913 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 196/250\n36/37 [============================>.] - ETA: 0s - loss: 0.0353 - accuracy: 0.9937/37 [==============================] - 1s 34ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.0194 - val_accuracy: 0.9966\nEpoch 197/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.0199 - val_accuracy: 0.9966\nEpoch 198/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0356 - accuracy: 0.9913 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 199/250\n37/37 [==============================] - 3s 68ms/step - loss: 0.0356 - accuracy: 0.9913 - val_loss: 0.0197 - val_accuracy: 0.9966\nEpoch 200/250\n37/37 [==============================] - 1s 25ms/step - loss: 0.0355 - accuracy: 0.9913 - val_loss: 0.0194 - val_accuracy: 0.9968\nEpoch 201/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0355 - accuracy: 0.9913 - val_loss: 0.0195 - val_accuracy: 0.9966\nEpoch 202/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0354 - accuracy: 0.9913 - val_loss: 0.0193 - val_accuracy: 0.9968\nEpoch 203/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0355 - accuracy: 0.9913 - val_loss: 0.0192 - val_accuracy: 0.9967\nEpoch 204/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0356 - accuracy: 0.9914 - val_loss: 0.0194 - val_accuracy: 0.9966\nEpoch 205/250\n37/37 [==============================] - 1s 23ms/step - loss: 0.0355 - accuracy: 0.9913 - val_loss: 0.0195 - val_accuracy: 0.9965\nEpoch 206/250\n37/37 [==============================] - 2s 57ms/step - loss: 0.0355 - accuracy: 0.9913 - val_loss: 0.0196 - val_accuracy: 0.9967\nEpoch 207/250\n37/37 [==============================] - 1s 20ms/step - loss: 0.0354 - accuracy: 0.9914 - val_loss: 0.0197 - val_accuracy: 0.9965\nEpoch 208/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0354 - accuracy: 0.9914 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 209/250\n37/37 [==============================] - 2s 49ms/step - loss: 0.0354 - accuracy: 0.9914 - val_loss: 0.0195 - val_accuracy: 0.9966\nEpoch 210/250\n37/37 [==============================] - 1s 23ms/step - loss: 0.0354 - accuracy: 0.9913 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 211/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0354 - accuracy: 0.9913 - val_loss: 0.0196 - val_accuracy: 0.9965\nEpoch 212/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0354 - accuracy: 0.9914 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 213/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0354 - accuracy: 0.9914 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 214/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0355 - accuracy: 0.9913 - val_loss: 0.0193 - val_accuracy: 0.9968\nEpoch 215/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0354 - accuracy: 0.9914 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 216/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0353 - accuracy: 0.9915 - val_loss: 0.0199 - val_accuracy: 0.9966\nEpoch 217/250\n37/37 [==============================] - 3s 86ms/step - loss: 0.0354 - accuracy: 0.9914 - val_loss: 0.0196 - val_accuracy: 0.9966\nEpoch 218/250\n37/37 [==============================] - 6s 166ms/step - loss: 0.0354 - accuracy: 0.9914 - val_loss: 0.0194 - val_accuracy: 0.9966\nEpoch 219/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0353 - accuracy: 0.9914 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 220/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0354 - accuracy: 0.9914 - val_loss: 0.0193 - val_accuracy: 0.9966\nEpoch 221/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0353 - accuracy: 0.9914 - val_loss: 0.0193 - val_accuracy: 0.9968\nEpoch 222/250\n37/37 [==============================] - 2s 43ms/step - loss: 0.0354 - accuracy: 0.9914 - val_loss: 0.0191 - val_accuracy: 0.9968\nEpoch 223/250\n37/37 [==============================] - 1s 35ms/step - loss: 0.0353 - accuracy: 0.9914 - val_loss: 0.0196 - val_accuracy: 0.9967\nEpoch 224/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0354 - accuracy: 0.9914 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 225/250\n37/37 [==============================] - 1s 27ms/step - loss: 0.0353 - accuracy: 0.9914 - val_loss: 0.0195 - val_accuracy: 0.9965\nEpoch 226/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0354 - accuracy: 0.9914 - val_loss: 0.0193 - val_accuracy: 0.9968\nEpoch 227/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0352 - accuracy: 0.9915 - val_loss: 0.0196 - val_accuracy: 0.9967\nEpoch 228/250\n37/37 [==============================] - 15s 396ms/step - loss: 0.0352 - accuracy: 0.9915 - val_loss: 0.0195 - val_accuracy: 0.9965\nEpoch 229/250\n37/37 [==============================] - 3s 71ms/step - loss: 0.0353 - accuracy: 0.9915 - val_loss: 0.0193 - val_accuracy: 0.9968\nEpoch 230/250\n37/37 [==============================] - 3s 75ms/step - loss: 0.0352 - accuracy: 0.9914 - val_loss: 0.0194 - val_accuracy: 0.9966\nEpoch 231/250\n37/37 [==============================] - 1s 35ms/step - loss: 0.0352 - accuracy: 0.9915 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 232/250\n37/37 [==============================] - 1s 25ms/step - loss: 0.0352 - accuracy: 0.9915 - val_loss: 0.0193 - val_accuracy: 0.9968\nEpoch 233/250\n37/37 [==============================] - 1s 26ms/step - loss: 0.0352 - accuracy: 0.9915 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 234/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0352 - accuracy: 0.9915 - val_loss: 0.0197 - val_accuracy: 0.9964\nEpoch 235/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0352 - accuracy: 0.9915 - val_loss: 0.0197 - val_accuracy: 0.9966\nEpoch 236/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0352 - accuracy: 0.9914 - val_loss: 0.0196 - val_accuracy: 0.9968\nEpoch 237/250\n37/37 [==============================] - 3s 88ms/step - loss: 0.0353 - accuracy: 0.9915 - val_loss: 0.0193 - val_accuracy: 0.9969\nEpoch 238/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0352 - accuracy: 0.9915 - val_loss: 0.0192 - val_accuracy: 0.9968\nEpoch 239/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0351 - accuracy: 0.9915 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 240/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0351 - accuracy: 0.9915 - val_loss: 0.0196 - val_accuracy: 0.9966\nEpoch 241/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0351 - accuracy: 0.9915 - val_loss: 0.0196 - val_accuracy: 0.9966\nEpoch 242/250\n37/37 [==============================] - 1s 25ms/step - loss: 0.0351 - accuracy: 0.9915 - val_loss: 0.0191 - val_accuracy: 0.9968\nEpoch 243/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0350 - accuracy: 0.9916 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 244/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0351 - accuracy: 0.9915 - val_loss: 0.0194 - val_accuracy: 0.9966\nEpoch 245/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0352 - accuracy: 0.9915 - val_loss: 0.0195 - val_accuracy: 0.9964\nEpoch 246/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0351 - accuracy: 0.9915 - val_loss: 0.0193 - val_accuracy: 0.9969\nEpoch 247/250\n37/37 [==============================] - 1s 21ms/step - loss: 0.0351 - accuracy: 0.9915 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 248/250\n37/37 [==============================] - 4s 113ms/step - loss: 0.0351 - accuracy: 0.9915 - val_loss: 0.0195 - val_accuracy: 0.9966\nEpoch 249/250\n37/37 [==============================] - 4s 115ms/step - loss: 0.0353 - accuracy: 0.9915 - val_loss: 0.0199 - val_accuracy: 0.9964\nEpoch 250/250\n37/37 [==============================] - 2s 67ms/step - loss: 0.0351 - accuracy: 0.9916 - val_loss: 0.0197 - val_accuracy: 0.9964\n"
    }
   ],
   "source": [
    "model_history = model.fit(x_train, y_train, batch_size=param_list[\"BATCH_SIZE\"], validation_split=0.2, epochs=param_list[\"EPOCHS\"])\n",
    "model.save(\"version/{}/model.h5\".format(timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"SEG_CNNLSTM_2_retrain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'20201123-091640'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "version_dir = \"version/\" + timestamp \n",
    "\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "16293"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "vocabulary = np.genfromtxt(\"static/vocabulary.csv\", delimiter=\"\\n\", dtype=np.int64)\n",
    "vocab_size = vocabulary.shape[0]\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = dict()\n",
    "\n",
    "param_list[\"PAST_HISTORY\"] = 16\n",
    "param_list[\"FUTURE_TARGET\"] = 8\n",
    "param_list[\"BATCH_SIZE\"] = 128\n",
    "param_list[\"EPOCHS\"] = 1000\n",
    "param_list[\"BUFFER_SIZE\"] = 200000\n",
    "param_list[\"VOCAB_SIZE\"] = vocab_size\n",
    "param_list[\"LEARNING_RATE\"] = 0.01\n",
    "param_list[\"NUM_1_NEURONS\"] = 64\n",
    "param_list[\"NUM_2_NEURONS\"] = 64\n",
    "param_list[\"DROPOUT_1\"] = 0.1\n",
    "param_list[\"DROPOUT_2\"] = 0.2\n",
    "param_list[\"FILTERS\"] = 64\n",
    "param_list[\"KERNEL_SIZE\"] = 9\n",
    "param_list[\"POOL_SIZE\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.genfromtxt(\"data/{}_train_set.csv\".format(dataset_name), delimiter=\"\\n\", dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.data.Dataset.from_tensor_slices(train_set[:-param_list[\"FUTURE_TARGET\"]]).window(param_list[\"PAST_HISTORY\"], 1, 1, True)\n",
    "# As dataset.window() returns \"dataset\", not \"tensor\", need to flat_map() it with sequence length\n",
    "x_train = x_train.flat_map(lambda x: x.batch(param_list[\"PAST_HISTORY\"])) \n",
    "x_train = x_train.map(lambda x: tf.one_hot(x, param_list[\"VOCAB_SIZE\"], axis=-1))\n",
    "x_train = x_train.batch(param_list[\"BATCH_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.data.Dataset.from_tensor_slices(train_set[param_list[\"PAST_HISTORY\"]:]).window(param_list[\"FUTURE_TARGET\"], 1, 1, True)\n",
    "y_train = y_train.flat_map(lambda y: y.batch(param_list[\"FUTURE_TARGET\"]))\n",
    "y_train = y_train.map(lambda y: tf.one_hot(y, param_list[\"VOCAB_SIZE\"], axis=-1))\n",
    "y_train = y_train.batch(param_list[\"BATCH_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.zip((x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = np.genfromtxt(\"data/{}_val_set.csv\".format(dataset_name), delimiter=\"\\n\", dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = tf.data.Dataset.from_tensor_slices(val_set[:-param_list[\"FUTURE_TARGET\"]]).window(param_list[\"PAST_HISTORY\"], 1, 1, True)\n",
    "x_val = x_val.flat_map(lambda x: x.batch(param_list[\"PAST_HISTORY\"]))\n",
    "x_val = x_val.map(lambda x: tf.one_hot(x, param_list[\"VOCAB_SIZE\"], axis=-1))\n",
    "x_val = x_val.batch(param_list[\"BATCH_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = tf.data.Dataset.from_tensor_slices(val_set[param_list[\"PAST_HISTORY\"]:]).window(param_list[\"FUTURE_TARGET\"], 1, 1, True)\n",
    "y_val = y_val.flat_map(lambda y: y.batch(param_list[\"FUTURE_TARGET\"]))\n",
    "y_val = y_val.map(lambda y: tf.one_hot(y, param_list[\"VOCAB_SIZE\"], axis=-1))\n",
    "y_val = y_val.batch(param_list[\"BATCH_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = tf.data.Dataset.zip((x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv1D(filters=param_list[\"FILTERS\"], kernel_size=param_list[\"KERNEL_SIZE\"], padding=\"causal\", activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(pool_size=param_list[\"POOL_SIZE\"]))\n",
    "model.add(keras.layers.LSTM(param_list[\"NUM_1_NEURONS\"], return_sequences=True))\n",
    "model.add(keras.layers.Dropout(param_list[\"DROPOUT_1\"]))\n",
    "model.add(keras.layers.LSTM(param_list[\"NUM_2_NEURONS\"], return_sequences=True))\n",
    "model.add(keras.layers.Dropout(param_list[\"DROPOUT_2\"]))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Dense(param_list[\"VOCAB_SIZE\"], activation=\"softmax\")))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Nadam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1260/1260 [==============================] - 120s 96ms/step - loss: 6.6710 - accuracy: 0.3608 - val_loss: 7.6434 - val_accuracy: 0.1942\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(train_data, batch_size=param_list[\"BATCH_SIZE\"], epochs=param_list[\"EPOCHS\"], validation_data=val_data, callbacks=[keras.callbacks.EarlyStopping('val_accuracy', patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: version/20201123-091640\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(version_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
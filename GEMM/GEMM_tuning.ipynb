{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597610788518",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'20200817-092343'"
     },
     "metadata": {},
     "execution_count": 215
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = \"logs/fit/\" + timestamp\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "version_dir = \"version/\" + timestamp \n",
    "\n",
    "os.makedirs(version_dir)\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"StreamBench_1G1P\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              t           t+1  delta  tokenized_data\n0  104291368960  104291373056   4096            4096\n1  104291373056  104291377152   4096            4096\n2  104291377152  104291381248   4096            4096\n3  104291381248  104291385344   4096            4096\n4  104291385344  104291389440   4096            4096",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t</th>\n      <th>t+1</th>\n      <th>delta</th>\n      <th>tokenized_data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>104291368960</td>\n      <td>104291373056</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>104291373056</td>\n      <td>104291377152</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>104291377152</td>\n      <td>104291381248</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>104291381248</td>\n      <td>104291385344</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>104291385344</td>\n      <td>104291389440</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 217
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"data/{}_train_set.csv\".format(dataset_name))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = dict()\n",
    "\n",
    "param_list[\"PAST_HISTORY\"] = 16\n",
    "param_list[\"FUTURE_TARGET\"] = 8\n",
    "param_list[\"BATCH_SIZE\"] = 1024\n",
    "param_list[\"EPOCHS\"] = 1000\n",
    "param_list[\"BUFFER_SIZE\"] = 200000\n",
    "param_list[\"NUM_1_NEURONS\"] = 128\n",
    "param_list[\"NUM_2_NEURONS\"] = 64\n",
    "\n",
    "with open(\"version/{}/params.json\".format(timestamp), \"w\") as p:\n",
    "    json.dump(param_list, p, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timeseries(dataset, start_index, end_index, history_size, target_size, n_features):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i)\n",
    "        # Reshape data from (history_size,) to (history_size, n_feature)\n",
    "        data.append(np.reshape(dataset[indices], (history_size, n_features)))\n",
    "        labels.append(dataset[i:i+target_size])\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(<1x5 sparse matrix of type '<class 'numpy.float32'>'\n \twith 1 stored elements in Compressed Sparse Row format>,\n [array([-6291456,       -1,        0,     4096,  2097152], dtype=int64)])"
     },
     "metadata": {},
     "execution_count": 220
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(dtype=np.float32)\n",
    "encoded_data = encoder.fit_transform(dataset[\"tokenized_data\"].values.reshape(-1, 1))\n",
    "encoded_data[0], encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((33634, 16, 5), (33634, 8, 5))"
     },
     "metadata": {},
     "execution_count": 221
    }
   ],
   "source": [
    "x_train, y_train = generate_timeseries(encoded_data.toarray(), 0, None, param_list[\"PAST_HISTORY\"], param_list[\"FUTURE_TARGET\"], len(encoder.categories_[0]))\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(param_list[\"NUM_1_NEURONS\"])))\n",
    "model.add(tf.keras.layers.Dropout(0.1))\n",
    "model.add(tf.keras.layers.RepeatVector(param_list[\"FUTURE_TARGET\"]))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(param_list[\"NUM_2_NEURONS\"], return_sequences=True)))\n",
    "model.add(tf.keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.TimeDistributed(tf.keras.layers.Dense(len(encoder.categories_[0]), activation=\"softmax\")))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0303 - accuracy: 0.9950 - val_loss: 0.0533 - val_accuracy: 0.9913\nEpoch 864/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0536 - val_accuracy: 0.9914\nEpoch 865/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0537 - val_accuracy: 0.9914\nEpoch 866/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9949 - val_loss: 0.0538 - val_accuracy: 0.9913\nEpoch 867/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0301 - accuracy: 0.9949 - val_loss: 0.0540 - val_accuracy: 0.9915\nEpoch 868/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0538 - val_accuracy: 0.9915\nEpoch 869/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0302 - accuracy: 0.9951 - val_loss: 0.0538 - val_accuracy: 0.9914\nEpoch 870/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0540 - val_accuracy: 0.9914\nEpoch 871/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.0542 - val_accuracy: 0.9914\nEpoch 872/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0545 - val_accuracy: 0.9913\nEpoch 873/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0556 - val_accuracy: 0.9911\nEpoch 874/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0554 - val_accuracy: 0.9912\nEpoch 875/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0549 - val_accuracy: 0.9913\nEpoch 876/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0304 - accuracy: 0.9949 - val_loss: 0.0545 - val_accuracy: 0.9913\nEpoch 877/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0304 - accuracy: 0.9949 - val_loss: 0.0545 - val_accuracy: 0.9912\nEpoch 878/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0304 - accuracy: 0.9949 - val_loss: 0.0535 - val_accuracy: 0.9914\nEpoch 879/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0305 - accuracy: 0.9948 - val_loss: 0.0542 - val_accuracy: 0.9912\nEpoch 880/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0303 - accuracy: 0.9950 - val_loss: 0.0540 - val_accuracy: 0.9914\nEpoch 881/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0306 - accuracy: 0.9948 - val_loss: 0.0533 - val_accuracy: 0.9915\nEpoch 882/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0330 - accuracy: 0.9943 - val_loss: 0.0521 - val_accuracy: 0.9915\nEpoch 883/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0322 - accuracy: 0.9944 - val_loss: 0.0518 - val_accuracy: 0.9915\nEpoch 884/1000\n27/27 [==============================] - 0s 15ms/step - loss: 0.0311 - accuracy: 0.9947 - val_loss: 0.0527 - val_accuracy: 0.9913\nEpoch 885/1000\n27/27 [==============================] - 0s 15ms/step - loss: 0.0312 - accuracy: 0.9946 - val_loss: 0.0524 - val_accuracy: 0.9913\nEpoch 886/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0312 - accuracy: 0.9946 - val_loss: 0.0526 - val_accuracy: 0.9914\nEpoch 887/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0304 - accuracy: 0.9949 - val_loss: 0.0526 - val_accuracy: 0.9914\nEpoch 888/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.0529 - val_accuracy: 0.9914\nEpoch 889/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0303 - accuracy: 0.9949 - val_loss: 0.0540 - val_accuracy: 0.9914\nEpoch 890/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0543 - val_accuracy: 0.9914\nEpoch 891/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.0539 - val_accuracy: 0.9913\nEpoch 892/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0543 - val_accuracy: 0.9912\nEpoch 893/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0544 - val_accuracy: 0.9914\nEpoch 894/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0303 - accuracy: 0.9950 - val_loss: 0.0548 - val_accuracy: 0.9912\nEpoch 895/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0546 - val_accuracy: 0.9913\nEpoch 896/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0541 - val_accuracy: 0.9914\nEpoch 897/1000\n27/27 [==============================] - 0s 15ms/step - loss: 0.0301 - accuracy: 0.9951 - val_loss: 0.0546 - val_accuracy: 0.9914\nEpoch 898/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.0552 - val_accuracy: 0.9913\nEpoch 899/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0547 - val_accuracy: 0.9914\nEpoch 900/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.0549 - val_accuracy: 0.9913\nEpoch 901/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0550 - val_accuracy: 0.9913\nEpoch 902/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.0550 - val_accuracy: 0.9913\nEpoch 903/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0552 - val_accuracy: 0.9913\nEpoch 904/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0554 - val_accuracy: 0.9913\nEpoch 905/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0300 - accuracy: 0.9950 - val_loss: 0.0554 - val_accuracy: 0.9913\nEpoch 906/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0548 - val_accuracy: 0.9915\nEpoch 907/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0548 - val_accuracy: 0.9915\nEpoch 908/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9951 - val_loss: 0.0551 - val_accuracy: 0.9914\nEpoch 909/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0555 - val_accuracy: 0.9913\nEpoch 910/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0300 - accuracy: 0.9950 - val_loss: 0.0556 - val_accuracy: 0.9914\nEpoch 911/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0559 - val_accuracy: 0.9914\nEpoch 912/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0300 - accuracy: 0.9951 - val_loss: 0.0561 - val_accuracy: 0.9915\nEpoch 913/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0559 - val_accuracy: 0.9914\nEpoch 914/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0558 - val_accuracy: 0.9912\nEpoch 915/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.0555 - val_accuracy: 0.9914\nEpoch 916/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0300 - accuracy: 0.9950 - val_loss: 0.0554 - val_accuracy: 0.9914\nEpoch 917/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0556 - val_accuracy: 0.9913\nEpoch 918/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0548 - val_accuracy: 0.9913\nEpoch 919/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0563 - val_accuracy: 0.9913\nEpoch 920/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.0542 - val_accuracy: 0.9914\nEpoch 921/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9949 - val_loss: 0.0544 - val_accuracy: 0.9913\nEpoch 922/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.0548 - val_accuracy: 0.9913\nEpoch 923/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0553 - val_accuracy: 0.9914\nEpoch 924/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0555 - val_accuracy: 0.9914\nEpoch 925/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0552 - val_accuracy: 0.9913\nEpoch 926/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0554 - val_accuracy: 0.9913\nEpoch 927/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0553 - val_accuracy: 0.9913\nEpoch 928/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0554 - val_accuracy: 0.9913\nEpoch 929/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0550 - val_accuracy: 0.9914\nEpoch 930/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0548 - val_accuracy: 0.9915\nEpoch 931/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0300 - accuracy: 0.9950 - val_loss: 0.0550 - val_accuracy: 0.9915\nEpoch 932/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0552 - val_accuracy: 0.9915\nEpoch 933/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.0561 - val_accuracy: 0.9913\nEpoch 934/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0565 - val_accuracy: 0.9912\nEpoch 935/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0561 - val_accuracy: 0.9914\nEpoch 936/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0561 - val_accuracy: 0.9914\nEpoch 937/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0301 - accuracy: 0.9949 - val_loss: 0.0564 - val_accuracy: 0.9913\nEpoch 938/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0562 - val_accuracy: 0.9914\nEpoch 939/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0564 - val_accuracy: 0.9913\nEpoch 940/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0567 - val_accuracy: 0.9914\nEpoch 941/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0564 - val_accuracy: 0.9914\nEpoch 942/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0560 - val_accuracy: 0.9913\nEpoch 943/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.0560 - val_accuracy: 0.9913\nEpoch 944/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0561 - val_accuracy: 0.9914\nEpoch 945/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.0557 - val_accuracy: 0.9914\nEpoch 946/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.0555 - val_accuracy: 0.9913\nEpoch 947/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.0557 - val_accuracy: 0.9913\nEpoch 948/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0560 - val_accuracy: 0.9915\nEpoch 949/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0300 - accuracy: 0.9950 - val_loss: 0.0562 - val_accuracy: 0.9913\nEpoch 950/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0558 - val_accuracy: 0.9914\nEpoch 951/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.0560 - val_accuracy: 0.9913\nEpoch 952/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0300 - accuracy: 0.9950 - val_loss: 0.0563 - val_accuracy: 0.9912\nEpoch 953/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0568 - val_accuracy: 0.9912\nEpoch 954/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0570 - val_accuracy: 0.9911\nEpoch 955/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0566 - val_accuracy: 0.9913\nEpoch 956/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0564 - val_accuracy: 0.9912\nEpoch 957/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0562 - val_accuracy: 0.9912\nEpoch 958/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0301 - accuracy: 0.9949 - val_loss: 0.0545 - val_accuracy: 0.9913\nEpoch 959/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9949 - val_loss: 0.0547 - val_accuracy: 0.9913\nEpoch 960/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0557 - val_accuracy: 0.9912\nEpoch 961/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0545 - val_accuracy: 0.9912\nEpoch 962/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0548 - val_accuracy: 0.9913\nEpoch 963/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0553 - val_accuracy: 0.9913\nEpoch 964/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0550 - val_accuracy: 0.9914\nEpoch 965/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0545 - val_accuracy: 0.9913\nEpoch 966/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0550 - val_accuracy: 0.9914\nEpoch 967/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0553 - val_accuracy: 0.9913\nEpoch 968/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0300 - accuracy: 0.9950 - val_loss: 0.0549 - val_accuracy: 0.9913\nEpoch 969/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9951 - val_loss: 0.0555 - val_accuracy: 0.9913\nEpoch 970/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0300 - accuracy: 0.9951 - val_loss: 0.0557 - val_accuracy: 0.9914\nEpoch 971/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0563 - val_accuracy: 0.9914\nEpoch 972/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0300 - accuracy: 0.9950 - val_loss: 0.0561 - val_accuracy: 0.9914\nEpoch 973/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.0561 - val_accuracy: 0.9913\nEpoch 974/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9951 - val_loss: 0.0556 - val_accuracy: 0.9913\nEpoch 975/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9949 - val_loss: 0.0560 - val_accuracy: 0.9913\nEpoch 976/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0560 - val_accuracy: 0.9914\nEpoch 977/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0561 - val_accuracy: 0.9914\nEpoch 978/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0558 - val_accuracy: 0.9914\nEpoch 979/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0553 - val_accuracy: 0.9914\nEpoch 980/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9949 - val_loss: 0.0557 - val_accuracy: 0.9913\nEpoch 981/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0300 - accuracy: 0.9951 - val_loss: 0.0558 - val_accuracy: 0.9914\nEpoch 982/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0300 - accuracy: 0.9950 - val_loss: 0.0558 - val_accuracy: 0.9913\nEpoch 983/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0561 - val_accuracy: 0.9914\nEpoch 984/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0563 - val_accuracy: 0.9913\nEpoch 985/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0563 - val_accuracy: 0.9913\nEpoch 986/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0567 - val_accuracy: 0.9914\nEpoch 987/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0300 - accuracy: 0.9950 - val_loss: 0.0569 - val_accuracy: 0.9915\nEpoch 988/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0567 - val_accuracy: 0.9914\nEpoch 989/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0300 - accuracy: 0.9949 - val_loss: 0.0560 - val_accuracy: 0.9914\nEpoch 990/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0565 - val_accuracy: 0.9915\nEpoch 991/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0567 - val_accuracy: 0.9913\nEpoch 992/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0561 - val_accuracy: 0.9914\nEpoch 993/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9949 - val_loss: 0.0566 - val_accuracy: 0.9914\nEpoch 994/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0552 - val_accuracy: 0.9915\nEpoch 995/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0569 - val_accuracy: 0.9913\nEpoch 996/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.0570 - val_accuracy: 0.9914\nEpoch 997/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0301 - accuracy: 0.9949 - val_loss: 0.0566 - val_accuracy: 0.9914\nEpoch 998/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0300 - accuracy: 0.9951 - val_loss: 0.0562 - val_accuracy: 0.9914\nEpoch 999/1000\n27/27 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0558 - val_accuracy: 0.9914\nEpoch 1000/1000\n27/27 [==============================] - 0s 13ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0556 - val_accuracy: 0.9915\n"
    }
   ],
   "source": [
    "model_history = model.fit(x_train, y_train, batch_size=param_list[\"BATCH_SIZE\"], validation_split=0.2, epochs=param_list[\"EPOCHS\"])\n",
    "model.save(\"version/{}/model.h5\".format(timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              t           t+1    delta  tokenized_data\n0  103653834752  103655931904  2097152         2097152\n1  103655931904  103655931904        0               0\n2  103655931904  103649640448 -6291456        -6291456\n3  103649640448  103649640448        0               0\n4  103649640448  103651737600  2097152         2097152",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t</th>\n      <th>t+1</th>\n      <th>delta</th>\n      <th>tokenized_data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>103653834752</td>\n      <td>103655931904</td>\n      <td>2097152</td>\n      <td>2097152</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>103655931904</td>\n      <td>103655931904</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>103655931904</td>\n      <td>103649640448</td>\n      <td>-6291456</td>\n      <td>-6291456</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>103649640448</td>\n      <td>103649640448</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>103649640448</td>\n      <td>103651737600</td>\n      <td>2097152</td>\n      <td>2097152</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 224
    }
   ],
   "source": [
    "test_dataset = pd.read_csv(\"data/{}_test_set.csv\".format(dataset_name))\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(<1x5 sparse matrix of type '<class 'numpy.float32'>'\n \twith 1 stored elements in Compressed Sparse Row format>,\n [array([-6291456,       -1,        0,     4096,  2097152], dtype=int64)])"
     },
     "metadata": {},
     "execution_count": 225
    }
   ],
   "source": [
    "test_encoder = OneHotEncoder(dtype=np.float32)\n",
    "encoded_test_data = test_encoder.fit_transform(test_dataset[\"tokenized_data\"].values.reshape(-1, 1))\n",
    "encoded_test_data[0], test_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = generate_timeseries(encoded_test_data.toarray(), 0, None, 16, 8, len(test_encoder.categories_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "for i in range(y_test.shape[0]):\n",
    "    y_true.extend(np.argmax(y_test[i], axis=1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in range(x_test.shape[0]):\n",
    "    y_pred.extend(np.argmax(model.predict(x_test[i].reshape(1, 16, 5))[0], axis=1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[[1.6143678e-05, 1.1879786e-05, 1.1160756e-04, 9.9985051e-01,\n         9.8830214e-06],\n        [5.2995347e-06, 4.7371395e-06, 1.0321221e-05, 9.9993849e-01,\n         4.1070514e-05],\n        [1.5543282e-06, 2.1834480e-06, 1.1994189e-05, 9.9996161e-01,\n         2.2663262e-05],\n        [5.7104393e-07, 6.1036695e-07, 3.0910587e-06, 9.9999094e-01,\n         4.7377498e-06],\n        [6.4900462e-07, 6.7179059e-07, 3.2362925e-06, 9.9998915e-01,\n         6.3334351e-06],\n        [5.4870782e-07, 5.1940106e-07, 2.2633951e-06, 9.9999356e-01,\n         3.0409103e-06],\n        [5.7147599e-07, 4.2658905e-07, 3.0220210e-06, 9.9999380e-01,\n         2.2642050e-06],\n        [7.1840248e-07, 5.1157451e-07, 3.3709866e-06, 9.9999285e-01,\n         2.5908096e-06]]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 229
    }
   ],
   "source": [
    "model.predict(x_test[0].reshape(1, 16, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([3, 3, 3, 3, 3, 3, 3, 3], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 230
    }
   ],
   "source": [
    "np.argmax(model.predict(x_test[0].reshape(1, 16, 5))[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9576634512325831"
     },
     "metadata": {},
     "execution_count": 231
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "with open(\"version/{}/accuracy.txt\".format(timestamp), \"w\") as t:\n",
    "    t.write(str(accuracy.tolist()))\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score       support\n0              0.136571  0.703125  0.228717    128.000000\n1              0.000000  0.000000  0.000000     80.000000\n2              0.177722  0.169048  0.173276   1680.000000\n3              0.983073  0.974338  0.978686  87560.000000\n4              0.189765  0.741667  0.302207    120.000000\naccuracy       0.957663  0.957663  0.957663      0.957663\nmacro avg      0.297426  0.517635  0.336577  89568.000000\nweighted avg   0.964816  0.957663  0.960727  89568.000000\n"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = pd.DataFrame(classification_report(y_true, y_pred, output_dict=True)).transpose()\n",
    "report.to_csv(\"version/{}/report.csv\".format(timestamp))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import dill         # 0.3.2\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Global/Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"GEMM_EX\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset/Static Param List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   extra             time address_type          gpa  \\\n",
       "0       [601757.292075]   06:00:51:525554           PF  14190604288   \n",
       "1       [601757.297013]   06:00:51:530492           PF  14352732392   \n",
       "2       [601757.337978]   06:00:51:571456           PF  14121463808   \n",
       "3       [601757.368684]   06:00:51:602162           PF  14120734720   \n",
       "4       [601757.376568]   06:00:51:610048           PF  14120828928   \n",
       "...                  ...              ...          ...          ...   \n",
       "400591   [ 1946.373117]   07:24:00:468967          GPA   8620549134   \n",
       "400592   [ 1946.373123]   07:24:00:468972          GPA  22541025656   \n",
       "400593   [ 1946.373157]   07:24:00:469006          GPA   8620549134   \n",
       "400594   [ 1946.373422]   07:24:00:469266          GPA   8620548801   \n",
       "400595   [ 1946.373454]   07:24:00:469301          GPA  22638145536   \n",
       "\n",
       "                         rip  vmid  \n",
       "0                   15410752  3214  \n",
       "1            140316942991300  3214  \n",
       "2                   15410776  3214  \n",
       "3                   15410764  3214  \n",
       "4                   15410764  3214  \n",
       "...                      ...   ...  \n",
       "400591  18446744071888380942  3214  \n",
       "400592  18446744071888380942  3214  \n",
       "400593  18446744071888380942  3214  \n",
       "400594  18446744071888380609  3214  \n",
       "400595  18446744071888380609  3214  \n",
       "\n",
       "[2332979 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>extra</th>\n      <th>time</th>\n      <th>address_type</th>\n      <th>gpa</th>\n      <th>rip</th>\n      <th>vmid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[601757.292075]</td>\n      <td>06:00:51:525554</td>\n      <td>PF</td>\n      <td>14190604288</td>\n      <td>15410752</td>\n      <td>3214</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[601757.297013]</td>\n      <td>06:00:51:530492</td>\n      <td>PF</td>\n      <td>14352732392</td>\n      <td>140316942991300</td>\n      <td>3214</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[601757.337978]</td>\n      <td>06:00:51:571456</td>\n      <td>PF</td>\n      <td>14121463808</td>\n      <td>15410776</td>\n      <td>3214</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[601757.368684]</td>\n      <td>06:00:51:602162</td>\n      <td>PF</td>\n      <td>14120734720</td>\n      <td>15410764</td>\n      <td>3214</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[601757.376568]</td>\n      <td>06:00:51:610048</td>\n      <td>PF</td>\n      <td>14120828928</td>\n      <td>15410764</td>\n      <td>3214</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>400591</th>\n      <td>[ 1946.373117]</td>\n      <td>07:24:00:468967</td>\n      <td>GPA</td>\n      <td>8620549134</td>\n      <td>18446744071888380942</td>\n      <td>3214</td>\n    </tr>\n    <tr>\n      <th>400592</th>\n      <td>[ 1946.373123]</td>\n      <td>07:24:00:468972</td>\n      <td>GPA</td>\n      <td>22541025656</td>\n      <td>18446744071888380942</td>\n      <td>3214</td>\n    </tr>\n    <tr>\n      <th>400593</th>\n      <td>[ 1946.373157]</td>\n      <td>07:24:00:469006</td>\n      <td>GPA</td>\n      <td>8620549134</td>\n      <td>18446744071888380942</td>\n      <td>3214</td>\n    </tr>\n    <tr>\n      <th>400594</th>\n      <td>[ 1946.373422]</td>\n      <td>07:24:00:469266</td>\n      <td>GPA</td>\n      <td>8620548801</td>\n      <td>18446744071888380609</td>\n      <td>3214</td>\n    </tr>\n    <tr>\n      <th>400595</th>\n      <td>[ 1946.373454]</td>\n      <td>07:24:00:469301</td>\n      <td>GPA</td>\n      <td>22638145536</td>\n      <td>18446744071888380609</td>\n      <td>3214</td>\n    </tr>\n  </tbody>\n</table>\n<p>2332979 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "original_dataset = pd.concat([pd.read_csv(\"../로그 데이터/GEMM/gem_3214_generic_{}.csv\".format(i), dtype=np.object) for i in reversed(range(1, 11))], axis=0)\n",
    "original_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                gpa                   rip\n",
       "0       14190604288              15410752\n",
       "1       14352732392       140316942991300\n",
       "2       14121463808              15410776\n",
       "3       14120734720              15410764\n",
       "4       14120828928              15410764\n",
       "...             ...                   ...\n",
       "400591   8620549134  18446744071888380942\n",
       "400592  22541025656  18446744071888380942\n",
       "400593   8620549134  18446744071888380942\n",
       "400594   8620548801  18446744071888380609\n",
       "400595  22638145536  18446744071888380609\n",
       "\n",
       "[2332869 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gpa</th>\n      <th>rip</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14190604288</td>\n      <td>15410752</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14352732392</td>\n      <td>140316942991300</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14121463808</td>\n      <td>15410776</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14120734720</td>\n      <td>15410764</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14120828928</td>\n      <td>15410764</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>400591</th>\n      <td>8620549134</td>\n      <td>18446744071888380942</td>\n    </tr>\n    <tr>\n      <th>400592</th>\n      <td>22541025656</td>\n      <td>18446744071888380942</td>\n    </tr>\n    <tr>\n      <th>400593</th>\n      <td>8620549134</td>\n      <td>18446744071888380942</td>\n    </tr>\n    <tr>\n      <th>400594</th>\n      <td>8620548801</td>\n      <td>18446744071888380609</td>\n    </tr>\n    <tr>\n      <th>400595</th>\n      <td>22638145536</td>\n      <td>18446744071888380609</td>\n    </tr>\n  </tbody>\n</table>\n<p>2332869 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "original_dataset = original_dataset[[\"gpa\", \"rip\"]].dropna()       # rip for PCs\n",
    "original_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalculateDelta(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X[:-1] - X[1:]\n",
    "\n",
    "    def inverse_transform(self, X, y=None):     # Just for test_pipeline.inverse_transform()\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseTokenizer(TransformerMixin):\n",
    "    def __init__(self, minimum_category_occurence=2, oov_token=-1):        \n",
    "        self.minimum_category_occurence = minimum_category_occurence\n",
    "        self.oov_token = oov_token\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        ## NOTE : If X is unsigned type, change the value of {oov_token} to maximum value of its type.\n",
    "        self.dtype = X.dtype\n",
    "        if self.dtype in [np.uint8, np.uint16, np.uint32, np.uint64]:\n",
    "            self.oov_token = str(self.oov_token)\n",
    "            X.astype(np.string_)\n",
    "\n",
    "        mask = (pd.Series(X).value_counts() <= self.minimum_category_occurence)\n",
    "        noise_index = np.where(np.isin(X, mask.index[mask == True]))[0]\n",
    "    \n",
    "        X[noise_index] = self.oov_token    ## NOTE : Due to Unknown Bug, move this part to transform()\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if X.dtype in [np.uint8, np.uint16, np.uint32, np.uint64]:\n",
    "            X.astype(np.string_)\n",
    "        return X\n",
    "\n",
    "    def inverse_transform(self, X, y=None):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseCategoryEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, oov_token=-1):\n",
    "        self.oov_token = oov_token\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_counts = pd.Series(X).value_counts()\n",
    "        self.vocab_size = len(X_counts)\n",
    "        self.word_index = X_counts.index\n",
    "        if self.word_index.dtype == np.string_:     # As np.string_ type is byte type, not str(), need to be decoded.\n",
    "            self.vocabulary = {X_counts.index[i].decode():i for i in range(self.vocab_size)}\n",
    "            self.oov_token = str(self.oov_token)\n",
    "        else:\n",
    "            self.vocabulary = {X_counts.index[i]:i for i in range(self.vocab_size)}\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for i in range(len(X)):\n",
    "            if X[i] in self.word_index:\n",
    "                X_transformed.append(self.vocabulary[X[i]])\n",
    "            else:\n",
    "                X_transformed.append(self.vocabulary[self.oov_token])\n",
    "\n",
    "        return np.array(X_transformed)\n",
    "\n",
    "    def inverse_transform(self, X, y=None):\n",
    "        return np.array([self.word_index[X[i]] for i in range(len(X))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Train/Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Val / Test Ratio : 70% / 15% / 15%\n",
    "train_val_set, test_set = train_test_split(original_dataset, test_size=0.15, shuffle=False)\n",
    "#train_set, val_set = train_test_split(train_val_set, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_gpa = train_val_set[\"gpa\"].values.astype(np.float64)\n",
    "train_val_rip = train_val_set[\"rip\"].values.astype(np.uint64)      # As uint64 not exists in pandas\n",
    "\n",
    "test_gpa = test_set[\"gpa\"].values.astype(np.float64)\n",
    "test_rip = test_set[\"rip\"].values.astype(np.uint64)      # As uint64 not exists in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMM_EX_gpa_train_pipeline = Pipeline([\n",
    "    ('calculate_delta', CalculateDelta()),\n",
    "    ('noise_tokenizer', NoiseTokenizer()),\n",
    "    ('sparse_category_encoder', SparseCategoryEncoder())\n",
    "])\n",
    "\n",
    "GEMM_EX_rip_train_pipeline = Pipeline([\n",
    "    ('calculate_delta', CalculateDelta()),\n",
    "    ('noise_tokenizer', NoiseTokenizer()),\n",
    "    ('sparse_category_encoder', SparseCategoryEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  1,   1, 545, ...,   0,   0,   0])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "processed_train_val_gpa = GEMM_EX_gpa_train_pipeline.fit_transform(train_val_gpa.copy())\n",
    "processed_train_val_gpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([13, 13,  4, ...,  0,  0,  0])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "processed_train_val_rip = GEMM_EX_rip_train_pipeline.fit_transform(train_val_rip)\n",
    "processed_train_val_rip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       1189566\n",
       "1         99667\n",
       "2         54664\n",
       "3         48114\n",
       "4         34376\n",
       "         ...   \n",
       "1559          3\n",
       "1763          3\n",
       "1671          3\n",
       "1762          3\n",
       "1615          3\n",
       "Length: 1883, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "pd.Series(processed_train_val_rip).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_gpa, processed_val_gpa = train_test_split(processed_train_val_gpa, test_size=0.2, shuffle=False)\n",
    "processed_train_rip, processed_val_rip = train_test_split(processed_train_val_rip, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1586349,), (396588,), (1586349,), (396588,))"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "processed_train_gpa.shape, processed_val_gpa.shape, processed_train_rip.shape, processed_val_rip.shape  # check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gpa = train_val_gpa[:processed_train_gpa.shape[0]+1]\n",
    "val_gpa = train_val_gpa[processed_train_gpa.shape[0]:]\n",
    "\n",
    "train_rip = train_val_rip[:processed_train_rip.shape[0]+1]\n",
    "val_rip = train_val_rip[processed_train_rip.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1586350,), (396589,), (1586350,), (396589,))"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "train_gpa.shape, val_gpa.shape, train_rip.shape, val_rip.shape"
   ]
  },
  {
   "source": [
    "## Process Test Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 0,  1,  1, ..., 13, 14,  1])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "processed_test_gpa = GEMM_EX_gpa_train_pipeline.transform(test_gpa)\n",
    "processed_test_gpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "-1",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-580d74655437>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprocessed_test_rip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGEMM_EX_rip_train_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_rip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprocessed_test_rip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-1bdeab310598>\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[0mX_transformed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                 \u001b[0mX_transformed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moov_token\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_transformed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: -1"
     ]
    }
   ],
   "source": [
    "processed_test_rip = GEMM_EX_rip_train_pipeline.transform(test_rip)\n",
    "processed_test_rip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 18446744073709551604: 1,\n",
       " 18446744073709551605: 2,\n",
       " 35: 3,\n",
       " 12: 4,\n",
       " 11: 5,\n",
       " 18446744073709551592: 6,\n",
       " 23: 7,\n",
       " 24: 8,\n",
       " 18446744073709551593: 9}"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "dict(list(GEMM_EX_rip_train_pipeline[\"sparse_category_encoder\"].vocabulary.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "numpy.str_"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "a = np.array([str(-1)])\n",
    "a.astype(np.string_)\n",
    "type(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'-1'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-c624ee830814>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mGEMM_EX_rip_train_pipeline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sparse_category_encoder\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: '-1'"
     ]
    }
   ],
   "source": [
    "GEMM_EX_rip_train_pipeline[\"sparse_category_encoder\"].vocabulary[a[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(processed_test_rip).value_counts()"
   ]
  },
  {
   "source": [
    "## Check Dataset/Processed Dataset Shape  \n",
    "Note that original train/val set have size of {processed train/val set + 1}, due to Delta calculation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((161292,), (40324,), (161291,), (40323,))"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "train_set.shape, val_set.shape, processed_train_set.shape, processed_val_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((35580,), (35579,))"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "test_set.shape, processed_test_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Processed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original \n",
    "np.savetxt(\"data/{}_train_set_original.csv\".format(model_name), train_set, fmt=\"%d\", delimiter=\"\\n\")\n",
    "np.savetxt(\"data/{}_val_set_original.csv\".format(model_name), val_set, fmt=\"%d\", delimiter=\"\\n\")\n",
    "np.savetxt(\"data/{}_test_set_original.csv\".format(model_name), test_set, fmt=\"%d\", delimiter=\"\\n\")\n",
    "\n",
    "# Processed \n",
    "np.savetxt(\"data/{}_train_set.csv\".format(model_name), processed_train_set, fmt=\"%d\", delimiter=\"\\n\")\n",
    "np.savetxt(\"data/{}_val_set.csv\".format(model_name), processed_val_set, fmt=\"%d\", delimiter=\"\\n\")\n",
    "np.savetxt(\"data/{}_test_set.csv\".format(model_name), processed_test_set, fmt=\"%d\", delimiter=\"\\n\")"
   ]
  },
  {
   "source": [
    "## Save Pipeline/Statics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "with open(\"static/pipeline.pkl\", 'wb') as f:\n",
    "    dill.dump(SEG_train_pipeline, f)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 20,
   "outputs": []
  },
  {
   "source": [
    "np.savetxt(\"static/vocabulary.csv\", np.array(list(SEG_train_pipeline[\"sparse_category_encoder\"].vocabulary.keys())), fmt=\"%d\", delimiter=\"\\n\")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{-1: 0,\n",
       " 0: 1,\n",
       " -4096: 2,\n",
       " -909517620: 3,\n",
       " 909517620: 4,\n",
       " -8192: 5,\n",
       " 8: 6,\n",
       " 4096: 7,\n",
       " -8: 8,\n",
       " -12288: 9,\n",
       " -2416: 10,\n",
       " -16384: 11,\n",
       " -24: 12,\n",
       " -3520: 13,\n",
       " 12: 14,\n",
       " 2744: 15,\n",
       " -6: 16,\n",
       " -64: 17,\n",
       " -32: 18,\n",
       " -20480: 19}"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "dict(list(SEG_train_pipeline[\"sparse_category_encoder\"].vocabulary.items())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "16293"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "SEG_train_pipeline[\"sparse_category_encoder\"].vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598329605360",
   "display_name": "Python 3.7.6 64-bit ('ProgramData': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'20200825-150332'"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "'''\n",
    "log_dir = \"logs/fit/\" + timestamp\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "version_dir = \"version/\" + timestamp \n",
    "\n",
    "os.makedirs(version_dir)\n",
    "'''\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"SEG_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([90096539952,      528712,       73032, ...,  5992956672,\n        -753929088,   639534672], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 266
    }
   ],
   "source": [
    "dataset = np.genfromtxt(\"data/{}_train_set.csv\".format(dataset_name), delimiter=\"\\n\", dtype=np.int64)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "225"
     },
     "metadata": {},
     "execution_count": 267
    }
   ],
   "source": [
    "word_index = np.genfromtxt(\"data/word_index.csv\", delimiter=\"\\n\", dtype=np.int64)\n",
    "vocab_size = len(word_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = dict()\n",
    "\n",
    "param_list[\"PAST_HISTORY\"] = 16\n",
    "param_list[\"FUTURE_TARGET\"] = 8\n",
    "param_list[\"BATCH_SIZE\"] = 128\n",
    "param_list[\"EPOCHS\"] = 1\n",
    "param_list[\"BUFFER_SIZE\"] = 200000\n",
    "param_list[\"VOCAB_SIZE\"] = vocab_size\n",
    "param_list[\"EMBEDDING_DIM\"] = 128\n",
    "param_list[\"NUM_1_NEURONS\"] = 64\n",
    "param_list[\"NUM_2_NEURONS\"] = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timeseries(dataset, start_index, end_index, history_size, target_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i)\n",
    "        # Reshape data from (history_size,) to (history_size, n_feature)\n",
    "        #data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
    "        data.append(dataset[indices])\n",
    "        labels.append(np.reshape(dataset[i:i+target_size], (target_size, 1)))\n",
    "        #labels.append(dataset[i:i+target_size])\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((14858, 16), (14858, 8, 1))"
     },
     "metadata": {},
     "execution_count": 199
    }
   ],
   "source": [
    "x_train, y_train = generate_timeseries(dataset, 0, None, param_list[\"PAST_HISTORY\"], param_list[\"FUTURE_TARGET\"])\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64),\n array([[  0],\n        [  0],\n        [  0],\n        [  0],\n        [  0],\n        [933],\n        [  0],\n        [  0]], dtype=int64))"
     },
     "metadata": {},
     "execution_count": 200
    }
   ],
   "source": [
    "x_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = keras.models.Sequential()\n",
    "model_1.add(keras.layers.Embedding(param_list[\"VOCAB_SIZE\"], param_list[\"EMBEDDING_DIM\"]))\n",
    "'''\n",
    "model.add(keras.layers.Bidirectional(tf.keras.layers.LSTM(param_list[\"NUM_1_NEURONS\"])))\n",
    "model.add(keras.layers.RepeatVector(param_list[\"FUTURE_TARGET\"]))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(param_list[\"NUM_2_NEURONS\"], return_sequences=True)))\n",
    "model.add(keras.layers.TimeDistributed(tf.keras.layers.Dense(param_list[\"EMBEDDING_DIM\"], activation=\"relu\")))\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"relu\"))\n",
    "'''\n",
    "model_1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([[[ 0.03348713, -0.0321422 , -0.0002039 , ..., -0.01538205,\n          -0.00037723, -0.04587115],\n         [ 0.03348713, -0.0321422 , -0.0002039 , ..., -0.01538205,\n          -0.00037723, -0.04587115],\n         [ 0.03348713, -0.0321422 , -0.0002039 , ..., -0.01538205,\n          -0.00037723, -0.04587115],\n         ...,\n         [ 0.03348713, -0.0321422 , -0.0002039 , ..., -0.01538205,\n          -0.00037723, -0.04587115],\n         [ 0.03348713, -0.0321422 , -0.0002039 , ..., -0.01538205,\n          -0.00037723, -0.04587115],\n         [ 0.03348713, -0.0321422 , -0.0002039 , ..., -0.01538205,\n          -0.00037723, -0.04587115]]], dtype=float32),\n (1, 16, 128))"
     },
     "metadata": {},
     "execution_count": 180
    }
   ],
   "source": [
    "result_1 = model_1.predict(x_train[0].reshape(1, -1))\n",
    "result_1, result_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = keras.models.Sequential()\n",
    "model_2.add(keras.layers.Embedding(param_list[\"VOCAB_SIZE\"], param_list[\"EMBEDDING_DIM\"]))\n",
    "model_2.add(keras.layers.Bidirectional(tf.keras.layers.LSTM(param_list[\"NUM_1_NEURONS\"])))\n",
    "'''\n",
    "model.add(keras.layers.RepeatVector(param_list[\"FUTURE_TARGET\"]))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(param_list[\"NUM_2_NEURONS\"], return_sequences=True)))\n",
    "model.add(keras.layers.TimeDistributed(tf.keras.layers.Dense(param_list[\"EMBEDDING_DIM\"], activation=\"relu\")))\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"relu\"))\n",
    "'''\n",
    "model_2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([[-0.0323175 ,  0.01080733, -0.02124918, -0.03182497,  0.0005349 ,\n          0.03013883,  0.00514005, -0.00704384,  0.00064479, -0.02233502,\n         -0.03173504,  0.03177533,  0.02380591, -0.04436284, -0.0002885 ,\n          0.03022791, -0.00095697,  0.00453   ,  0.0079164 , -0.01633008,\n         -0.01089192, -0.0180753 ,  0.02040696, -0.02448608,  0.04001582,\n          0.01959519,  0.0419482 ,  0.03068886, -0.05885827, -0.01642068,\n         -0.01179666,  0.02060026,  0.00935058, -0.00333466, -0.03220222,\n         -0.00065259,  0.03831847, -0.00028345, -0.02940718,  0.05537249,\n          0.0318084 ,  0.03244494,  0.03810416,  0.01265741,  0.03713877,\n         -0.0210963 , -0.01847055, -0.03113708,  0.00825988,  0.0211153 ,\n          0.02339498, -0.01074204, -0.0211601 ,  0.03770156, -0.03256163,\n          0.00466607, -0.02375534, -0.00655294, -0.02509974,  0.00518663,\n          0.06740782, -0.01615395,  0.01820631, -0.05055143,  0.01211054,\n         -0.0065441 , -0.03464903, -0.00733286, -0.05058663, -0.05690792,\n          0.01282805, -0.02661924, -0.03212349,  0.02971894, -0.00961798,\n         -0.02505342,  0.00246317, -0.00838401,  0.04465366, -0.00592322,\n          0.07201745,  0.00063334,  0.00707612, -0.0026803 , -0.02010919,\n          0.0117284 , -0.01399643,  0.02773403,  0.01851057, -0.01170032,\n         -0.01192531,  0.01524584, -0.01441398,  0.01349083, -0.05734517,\n         -0.03289086, -0.00224119,  0.00450695, -0.03233581,  0.00196819,\n          0.0709364 ,  0.02110091, -0.04234285,  0.03541804,  0.01771425,\n         -0.01942714,  0.00365604, -0.01081364,  0.04393675,  0.00988113,\n          0.06204972,  0.00447942,  0.05004923,  0.02202465,  0.02617297,\n         -0.0763275 ,  0.0441745 ,  0.00833984,  0.01256598,  0.05959178,\n         -0.01470987,  0.02041423, -0.01191399,  0.01863432,  0.00713943,\n         -0.02145493, -0.0112627 ,  0.04430768]], dtype=float32),\n (1, 128))"
     },
     "metadata": {},
     "execution_count": 184
    }
   ],
   "source": [
    "result_2 = model_2.predict(x_train[0].reshape(1, -1))\n",
    "result_2, result_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = keras.models.Sequential()\n",
    "model_3.add(keras.layers.Embedding(param_list[\"VOCAB_SIZE\"], param_list[\"EMBEDDING_DIM\"]))\n",
    "model_3.add(keras.layers.Bidirectional(tf.keras.layers.LSTM(param_list[\"NUM_1_NEURONS\"])))\n",
    "model_3.add(keras.layers.RepeatVector(param_list[\"FUTURE_TARGET\"]))\n",
    "'''\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(param_list[\"NUM_2_NEURONS\"], return_sequences=True)))\n",
    "model.add(keras.layers.TimeDistributed(tf.keras.layers.Dense(param_list[\"EMBEDDING_DIM\"], activation=\"relu\")))\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"relu\"))\n",
    "'''\n",
    "model_3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([[[-0.01109056,  0.0153303 ,  0.03808117, ...,  0.01914384,\n          -0.00045225,  0.02542185],\n         [-0.01109056,  0.0153303 ,  0.03808117, ...,  0.01914384,\n          -0.00045225,  0.02542185],\n         [-0.01109056,  0.0153303 ,  0.03808117, ...,  0.01914384,\n          -0.00045225,  0.02542185],\n         ...,\n         [-0.01109056,  0.0153303 ,  0.03808117, ...,  0.01914384,\n          -0.00045225,  0.02542185],\n         [-0.01109056,  0.0153303 ,  0.03808117, ...,  0.01914384,\n          -0.00045225,  0.02542185],\n         [-0.01109056,  0.0153303 ,  0.03808117, ...,  0.01914384,\n          -0.00045225,  0.02542185]]], dtype=float32),\n (1, 8, 128))"
     },
     "metadata": {},
     "execution_count": 186
    }
   ],
   "source": [
    "result_3 = model_3.predict(x_train[0].reshape(1, -1))\n",
    "result_3, result_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Embedding(param_list[\"VOCAB_SIZE\"], param_list[\"EMBEDDING_DIM\"]))\n",
    "model.add(keras.layers.Bidirectional(tf.keras.layers.LSTM(param_list[\"NUM_1_NEURONS\"])))\n",
    "model.add(keras.layers.RepeatVector(param_list[\"FUTURE_TARGET\"]))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(param_list[\"NUM_2_NEURONS\"], return_sequences=True)))\n",
    "model.add(keras.layers.TimeDistributed(tf.keras.layers.Dense(param_list[\"EMBEDDING_DIM\"])))\n",
    "#model.add(tf.keras.layers.Dense(1))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "93/93 [==============================] - 3s 33ms/step - loss: nan - accuracy: 0.0313 - val_loss: 4.8520 - val_accuracy: 0.0000e+00\n"
    }
   ],
   "source": [
    "model_history = model.fit(x_train, y_train, batch_size=param_list[\"BATCH_SIZE\"], validation_split=0.2, epochs=param_list[\"EPOCHS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([[[0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.]]], dtype=float32),\n (1, 8, 1))"
     },
     "metadata": {},
     "execution_count": 203
    }
   ],
   "source": [
    "result = model.predict(x_train[0].reshape(1, -1))\n",
    "result, result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = keras.models.Sequential()\n",
    "model_4.add(keras.layers.Embedding(param_list[\"VOCAB_SIZE\"], param_list[\"EMBEDDING_DIM\"]))\n",
    "model_4.add(tf.keras.layers.Dense(param_list[\"EMBEDDING_DIM\"]))\n",
    "#model_4.add(tf.keras.layers.Dense(1))\n",
    "model_4.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "93/93 [==============================] - 2s 20ms/step - loss: nan - accuracy: 0.0323 - val_loss: 4.8520 - val_accuracy: 0.0000e+00\n"
    }
   ],
   "source": [
    "model_4_history = model_4.fit(x_train, x_train, batch_size=param_list[\"BATCH_SIZE\"], validation_split=0.2, epochs=param_list[\"EPOCHS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([[[nan, nan, nan, ..., nan, nan, nan]],\n \n        [[nan, nan, nan, ..., nan, nan, nan]],\n \n        [[nan, nan, nan, ..., nan, nan, nan]],\n \n        ...,\n \n        [[nan, nan, nan, ..., nan, nan, nan]],\n \n        [[nan, nan, nan, ..., nan, nan, nan]],\n \n        [[nan, nan, nan, ..., nan, nan, nan]]], dtype=float32),\n (16, 1, 128))"
     },
     "metadata": {},
     "execution_count": 263
    }
   ],
   "source": [
    "result_4 = model_4.predict(x_train[30].reshape(1, -1))\n",
    "result_4, result_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
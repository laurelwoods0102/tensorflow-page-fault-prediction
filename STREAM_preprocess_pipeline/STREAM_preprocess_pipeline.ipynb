{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import dill         # 0.3.2\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Global/Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"STREAM\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset/Static Param List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   extra             time address_type         gpa  \\\n",
       "0       [336633.698810]   04:01:00:854206           PF   251797631   \n",
       "1       [336633.739463]   04:01:00:894857           PF  1007005696   \n",
       "2       [336633.867033]   04:01:01:022428           PF   906555392   \n",
       "3       [336633.901503]   04:01:01:056898           PF  1914261504   \n",
       "4       [336633.904886]   04:01:01:060282           PF   259330048   \n",
       "...                  ...              ...          ...         ...   \n",
       "180309   [ 1806.225725]   07:00:33:381360           PF   602140104   \n",
       "180310   [ 1806.225827]   07:00:33:381465           PF   597469140   \n",
       "180311   [ 1806.240176]   07:00:33:395810           PF   596315344   \n",
       "180312   [ 1806.240198]   07:00:33:395836           PF   597544452   \n",
       "180313   [ 1806.401068]   07:00:33:556702           PF   603197568   \n",
       "\n",
       "                         rip  vmid  \n",
       "0       18446744072449302655  4034  \n",
       "1       18446744072452043863  4034  \n",
       "2       18446744072452043863  4034  \n",
       "3       18446744072452043863  4034  \n",
       "4       18446744072452043863  4034  \n",
       "...                      ...   ...  \n",
       "180309       139790387006578  4034  \n",
       "180310  18446744072443263295  4034  \n",
       "180311  18446744072442219334  4034  \n",
       "180312  18446744072441579461  4034  \n",
       "180313       139675253067982  4034  \n",
       "\n",
       "[4157042 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>extra</th>\n      <th>time</th>\n      <th>address_type</th>\n      <th>gpa</th>\n      <th>rip</th>\n      <th>vmid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[336633.698810]</td>\n      <td>04:01:00:854206</td>\n      <td>PF</td>\n      <td>251797631</td>\n      <td>18446744072449302655</td>\n      <td>4034</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[336633.739463]</td>\n      <td>04:01:00:894857</td>\n      <td>PF</td>\n      <td>1007005696</td>\n      <td>18446744072452043863</td>\n      <td>4034</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[336633.867033]</td>\n      <td>04:01:01:022428</td>\n      <td>PF</td>\n      <td>906555392</td>\n      <td>18446744072452043863</td>\n      <td>4034</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[336633.901503]</td>\n      <td>04:01:01:056898</td>\n      <td>PF</td>\n      <td>1914261504</td>\n      <td>18446744072452043863</td>\n      <td>4034</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[336633.904886]</td>\n      <td>04:01:01:060282</td>\n      <td>PF</td>\n      <td>259330048</td>\n      <td>18446744072452043863</td>\n      <td>4034</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>180309</th>\n      <td>[ 1806.225725]</td>\n      <td>07:00:33:381360</td>\n      <td>PF</td>\n      <td>602140104</td>\n      <td>139790387006578</td>\n      <td>4034</td>\n    </tr>\n    <tr>\n      <th>180310</th>\n      <td>[ 1806.225827]</td>\n      <td>07:00:33:381465</td>\n      <td>PF</td>\n      <td>597469140</td>\n      <td>18446744072443263295</td>\n      <td>4034</td>\n    </tr>\n    <tr>\n      <th>180311</th>\n      <td>[ 1806.240176]</td>\n      <td>07:00:33:395810</td>\n      <td>PF</td>\n      <td>596315344</td>\n      <td>18446744072442219334</td>\n      <td>4034</td>\n    </tr>\n    <tr>\n      <th>180312</th>\n      <td>[ 1806.240198]</td>\n      <td>07:00:33:395836</td>\n      <td>PF</td>\n      <td>597544452</td>\n      <td>18446744072441579461</td>\n      <td>4034</td>\n    </tr>\n    <tr>\n      <th>180313</th>\n      <td>[ 1806.401068]</td>\n      <td>07:00:33:556702</td>\n      <td>PF</td>\n      <td>603197568</td>\n      <td>139675253067982</td>\n      <td>4034</td>\n    </tr>\n  </tbody>\n</table>\n<p>4157042 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "original_dataset = pd.concat([pd.read_csv(\"../로그 데이터/STREAM/STREAM/stream_4034_generic2_{}.csv\".format(i), dtype=np.object) for i in reversed(range(1, 11))], axis=0)\n",
    "original_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               gpa                   rip\n",
       "0        251797631  18446744072449302655\n",
       "1       1007005696  18446744072452043863\n",
       "2        906555392  18446744072452043863\n",
       "3       1914261504  18446744072452043863\n",
       "4        259330048  18446744072452043863\n",
       "...            ...                   ...\n",
       "180309   602140104       139790387006578\n",
       "180310   597469140  18446744072443263295\n",
       "180311   596315344  18446744072442219334\n",
       "180312   597544452  18446744072441579461\n",
       "180313   603197568       139675253067982\n",
       "\n",
       "[4156988 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gpa</th>\n      <th>rip</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>251797631</td>\n      <td>18446744072449302655</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1007005696</td>\n      <td>18446744072452043863</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>906555392</td>\n      <td>18446744072452043863</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1914261504</td>\n      <td>18446744072452043863</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>259330048</td>\n      <td>18446744072452043863</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>180309</th>\n      <td>602140104</td>\n      <td>139790387006578</td>\n    </tr>\n    <tr>\n      <th>180310</th>\n      <td>597469140</td>\n      <td>18446744072443263295</td>\n    </tr>\n    <tr>\n      <th>180311</th>\n      <td>596315344</td>\n      <td>18446744072442219334</td>\n    </tr>\n    <tr>\n      <th>180312</th>\n      <td>597544452</td>\n      <td>18446744072441579461</td>\n    </tr>\n    <tr>\n      <th>180313</th>\n      <td>603197568</td>\n      <td>139675253067982</td>\n    </tr>\n  </tbody>\n</table>\n<p>4156988 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "original_dataset = original_dataset[[\"gpa\", \"rip\"]].dropna()       # rip for PCs\n",
    "original_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalculateDelta(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = X[:-1] - X[1:]\n",
    "        # In case of unsigned types, change its type to string type\n",
    "        if X_transformed.dtype in [np.uint8, np.uint16, np.uint32, np.uint64]:\n",
    "            X_transformed = X_transformed.astype(np.string_)\n",
    "        return X_transformed\n",
    "\n",
    "    def inverse_transform(self, X, y=None):     # Just for test_pipeline.inverse_transform()\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseTokenizer(TransformerMixin):\n",
    "    def __init__(self, minimum_category_occurence=2, oov_token=-1):        \n",
    "        self.minimum_category_occurence = minimum_category_occurence\n",
    "        self.oov_token = oov_token\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        if X.dtype == np.string_:\n",
    "            self.oov_token = str(self.oov_token)\n",
    "\n",
    "        mask = (pd.Series(X).value_counts() <= self.minimum_category_occurence)\n",
    "        noise_index = np.where(np.isin(X, mask.index[mask == True]))[0]\n",
    "    \n",
    "        X[noise_index] = self.oov_token\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X\n",
    "\n",
    "    def inverse_transform(self, X, y=None):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseCategoryEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, oov_token=-1):\n",
    "        self.oov_token = oov_token\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_counts = pd.Series(X).value_counts()\n",
    "        self.vocab_size = len(X_counts)\n",
    "        self.word_index = X_counts.index\n",
    "        \n",
    "        if X.dtype in [np.dtype(\"S\" + str(i)) for i in range(24)]:  # X.dtype == |S{0~24}\n",
    "            # As np.string_ type is byte type, not str(), need to be decoded.\n",
    "            self.vocabulary = {X_counts.index[i].decode():i for i in range(self.vocab_size)}\n",
    "        else:\n",
    "            self.vocabulary = {X_counts.index[i]:i for i in range(self.vocab_size)}\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        if X.dtype in [np.dtype(\"S\" + str(i)) for i in range(24)]:\n",
    "            self.oov_token = str(self.oov_token)\n",
    "            for i in range(len(X)):\n",
    "                if X[i] in self.word_index:\n",
    "                    X_transformed.append(self.vocabulary[X[i].decode()])\n",
    "                else:\n",
    "                    X_transformed.append(self.vocabulary[self.oov_token])\n",
    "        else:\n",
    "            for i in range(len(X)):\n",
    "                if X[i] in self.word_index:\n",
    "                    X_transformed.append(self.vocabulary[X[i]])\n",
    "                else:\n",
    "                    X_transformed.append(self.vocabulary[self.oov_token])\n",
    "\n",
    "        return np.array(X_transformed)\n",
    "\n",
    "    def inverse_transform(self, X, y=None):\n",
    "        return np.array([self.word_index[X[i]] for i in range(len(X))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Train/Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Val / Test Ratio : 70% / 15% / 15%\n",
    "train_val_set, test_set = train_test_split(original_dataset, test_size=0.15, shuffle=False)\n",
    "#train_set, val_set = train_test_split(train_val_set, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_gpa = train_val_set[\"gpa\"].values.astype(np.int64)\n",
    "train_val_rip = train_val_set[\"rip\"].values.astype(np.uint64)      # As uint64 not exists in pandas\n",
    "\n",
    "test_gpa = test_set[\"gpa\"].values.astype(np.int64)\n",
    "test_rip = test_set[\"rip\"].values.astype(np.uint64)      # As uint64 not exists in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpa_train_pipeline = Pipeline([\n",
    "    ('calculate_delta', CalculateDelta()),\n",
    "    ('noise_tokenizer', NoiseTokenizer()),\n",
    "    ('sparse_category_encoder', SparseCategoryEncoder())\n",
    "])\n",
    "\n",
    "rip_train_pipeline = Pipeline([\n",
    "    ('calculate_delta', CalculateDelta()),\n",
    "    ('noise_tokenizer', NoiseTokenizer()),\n",
    "    ('sparse_category_encoder', SparseCategoryEncoder())\n",
    "])"
   ]
  },
  {
   "source": [
    "processed_train_val_gpa = gpa_train_pipeline.fit_transform(train_val_gpa.copy())\n",
    "processed_train_val_gpa"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([     1,  55708, 156914, ...,  15814,   7211,      1])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([3361,    0,    0, ...,    0,    0,    0])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "processed_train_val_rip = rip_train_pipeline.fit_transform(train_val_rip)\n",
    "processed_train_val_rip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0         713760\n",
       " 1         643963\n",
       " 2         405516\n",
       " 3          36270\n",
       " 4          21875\n",
       "            ...  \n",
       " 123691         3\n",
       " 121644         3\n",
       " 119597         3\n",
       " 117550         3\n",
       " 142076         3\n",
       " Length: 159264, dtype: int64,\n",
       " 0       2591789\n",
       " 1         46918\n",
       " 2         34063\n",
       " 3         32504\n",
       " 4         28812\n",
       "          ...   \n",
       " 5785          3\n",
       " 6777          3\n",
       " 6778          3\n",
       " 6779          3\n",
       " 7051          3\n",
       " Length: 7240, dtype: int64)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "pd.Series(processed_train_val_gpa).value_counts(), pd.Series(processed_train_val_rip).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3         58791\n",
       " 4         27044\n",
       " 5         13694\n",
       " 6          7978\n",
       " 7          5203\n",
       "           ...  \n",
       " 203           1\n",
       " 229           1\n",
       " 995           1\n",
       " 158           1\n",
       " 643963        1\n",
       " Length: 263, dtype: int64,\n",
       " 3        1890\n",
       " 4        1120\n",
       " 5         703\n",
       " 6         550\n",
       " 7         439\n",
       "          ... \n",
       " 2331        1\n",
       " 290         1\n",
       " 4392        1\n",
       " 314         1\n",
       " 10033       1\n",
       " Length: 374, dtype: int64)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# Index = Occurence | Column = Number of included categories\n",
    "pd.Series(processed_train_val_gpa).value_counts().value_counts(), pd.Series(processed_train_val_rip).value_counts().value_counts()"
   ]
  },
  {
   "source": [
    "## gpa : N / P ratio"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "22.18604329917621"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "# n : p ratio at threshold = 2\n",
    "(processed_train_gpa.shape[0] + processed_val_gpa.shape[0]) / len(pd.Series(processed_train_val_gpa).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpa_threshold = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11225"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "# p\n",
    "len(pd.Series(processed_train_val_gpa).value_counts()) - sum(pd.Series(processed_train_val_gpa).value_counts().value_counts()[:gpa_threshold].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.28239295552943056"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "# Upper Limit for trian/val accuracy\n",
    "sum(pd.Series(processed_train_val_gpa).value_counts().value_counts()[:gpa_threshold].values * pd.Series(processed_train_val_gpa).value_counts().value_counts()[:gpa_threshold].index) / (processed_train_gpa.shape[0] + processed_val_gpa.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "314.78289532293985"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "# n : p ratio at threshold = {threshold}\n",
    "(processed_train_gpa.shape[0] + processed_val_gpa.shape[0]) / (len(pd.Series(processed_train_val_gpa).value_counts()) - sum(pd.Series(processed_train_val_gpa).value_counts().value_counts()[:gpa_threshold].values))"
   ]
  },
  {
   "source": [
    "## rip : N / P ratio"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "488.0439226519337"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "# n : p ratio at threshold = 2\n",
    "(processed_train_rip.shape[0] + processed_val_rip.shape[0]) / len(pd.Series(processed_train_val_rip).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "rip_threshold = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p\n",
    "len(pd.Series(processed_train_val_gpa).value_counts()) - sum(pd.Series(processed_train_val_gpa).value_counts().value_counts()[:gpa_threshold].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upper Limit for trian/val accuracy\n",
    "sum(pd.Series(processed_train_val_gpa).value_counts().value_counts()[:gpa_threshold].values * pd.Series(processed_train_val_gpa).value_counts().value_counts()[:gpa_threshold].index) / (processed_train_gpa.shape[0] + processed_val_gpa.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n : p ratio at threshold = {threshold}\n",
    "(processed_train_gpa.shape[0] + processed_val_gpa.shape[0]) / (len(pd.Series(processed_train_val_gpa).value_counts()) - sum(pd.Series(processed_train_val_gpa).value_counts().value_counts()[:gpa_threshold].values))"
   ]
  },
  {
   "source": [
    "## Split Train / Val / Test set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_gpa, processed_val_gpa = train_test_split(processed_train_val_gpa, test_size=0.2, shuffle=False)\n",
    "processed_train_rip, processed_val_rip = train_test_split(processed_train_val_rip, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((2826750,), (706688,), (2826750,), (706688,))"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "processed_train_gpa.shape, processed_val_gpa.shape, processed_train_rip.shape, processed_val_rip.shape  # check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gpa = train_val_gpa[:processed_train_gpa.shape[0]+1]\n",
    "val_gpa = train_val_gpa[processed_train_gpa.shape[0]:]\n",
    "\n",
    "train_rip = train_val_rip[:processed_train_rip.shape[0]+1]\n",
    "val_rip = train_val_rip[processed_train_rip.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((2826751,), (706689,), (2826751,), (706689,))"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "train_gpa.shape, val_gpa.shape, train_rip.shape, val_rip.shape"
   ]
  },
  {
   "source": [
    "## Process Test Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([7822, 2983,  771, ...,    1,    1,    1])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "processed_test_gpa = gpa_train_pipeline.transform(test_gpa)\n",
    "processed_test_gpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "processed_test_rip = rip_train_pipeline.transform(test_rip)\n",
    "processed_test_rip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '-1': 1,\n",
       " '18446744073709551579': 2,\n",
       " '37': 3,\n",
       " '18446744073709551612': 4,\n",
       " '4': 5,\n",
       " '18446744073709551587': 6,\n",
       " '29': 7,\n",
       " '18446650193870300916': 8,\n",
       " '93879839250700': 9}"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "dict(list(rip_train_pipeline[\"sparse_category_encoder\"].vocabulary.items())[:10])"
   ]
  },
  {
   "source": [
    "## Concat GPA and RIP"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[2.51797631e+08, 1.84467441e+19],\n",
       "        [1.00700570e+09, 1.84467441e+19],\n",
       "        [9.06555392e+08, 1.84467441e+19],\n",
       "        ...,\n",
       "        [1.47925811e+09, 1.84467441e+19],\n",
       "        [1.47925811e+09, 1.84467441e+19],\n",
       "        [1.25628826e+09, 9.41682691e+13]]),\n",
       " array([[1.25628826e+09, 9.41682691e+13],\n",
       "        [1.48969882e+09, 9.41682691e+13],\n",
       "        [1.48970291e+09, 9.41682691e+13],\n",
       "        ...,\n",
       "        [5.23194368e+08, 1.84467441e+19],\n",
       "        [5.31795968e+08, 1.84467441e+19],\n",
       "        [2.47767040e+07, 1.84467441e+19]]),\n",
       " array([[4.89844736e+08, 1.84467441e+19],\n",
       "        [5.22874880e+08, 1.84467441e+19],\n",
       "        [5.19757824e+08, 1.84467441e+19],\n",
       "        ...,\n",
       "        [5.96315344e+08, 1.84467441e+19],\n",
       "        [5.97544452e+08, 1.84467441e+19],\n",
       "        [6.03197568e+08, 1.39675253e+14]]))"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "train_set = np.c_[train_gpa, train_rip]\n",
    "val_set = np.c_[val_gpa, val_rip]\n",
    "test_set = np.c_[test_gpa, test_rip]\n",
    "\n",
    "processed_train_set = np.c_[processed_train_gpa, processed_train_rip]\n",
    "processed_val_set = np.c_[processed_val_gpa, processed_val_rip]\n",
    "processed_test_set = np.c_[processed_test_gpa, processed_test_rip]\n",
    "train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  gpa           rip\n",
       "0        2.517976e+08  1.844674e+19\n",
       "1        1.007006e+09  1.844674e+19\n",
       "2        9.065554e+08  1.844674e+19\n",
       "3        1.914262e+09  1.844674e+19\n",
       "4        2.593300e+08  1.844674e+19\n",
       "...               ...           ...\n",
       "2826746  1.495933e+09  9.416827e+13\n",
       "2826747  1.282355e+09  9.416827e+13\n",
       "2826748  1.479258e+09  1.844674e+19\n",
       "2826749  1.479258e+09  1.844674e+19\n",
       "2826750  1.256288e+09  9.416827e+13\n",
       "\n",
       "[2826751 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gpa</th>\n      <th>rip</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.517976e+08</td>\n      <td>1.844674e+19</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.007006e+09</td>\n      <td>1.844674e+19</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9.065554e+08</td>\n      <td>1.844674e+19</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.914262e+09</td>\n      <td>1.844674e+19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.593300e+08</td>\n      <td>1.844674e+19</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2826746</th>\n      <td>1.495933e+09</td>\n      <td>9.416827e+13</td>\n    </tr>\n    <tr>\n      <th>2826747</th>\n      <td>1.282355e+09</td>\n      <td>9.416827e+13</td>\n    </tr>\n    <tr>\n      <th>2826748</th>\n      <td>1.479258e+09</td>\n      <td>1.844674e+19</td>\n    </tr>\n    <tr>\n      <th>2826749</th>\n      <td>1.479258e+09</td>\n      <td>1.844674e+19</td>\n    </tr>\n    <tr>\n      <th>2826750</th>\n      <td>1.256288e+09</td>\n      <td>9.416827e+13</td>\n    </tr>\n  </tbody>\n</table>\n<p>2826751 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "train_set = pd.DataFrame(train_set, columns=[\"gpa\", \"rip\"], index=None)\n",
    "val_set = pd.DataFrame(val_set, columns=[\"gpa\", \"rip\"], index=None)\n",
    "test_set = pd.DataFrame(test_set, columns=[\"gpa\", \"rip\"], index=None)\n",
    "\n",
    "processed_train_set = pd.DataFrame(processed_train_set, columns=[\"gpa\", \"rip\"], index=None)\n",
    "processed_val_set = pd.DataFrame(processed_val_set, columns=[\"gpa\", \"rip\"], index=None)\n",
    "processed_test_set = pd.DataFrame(processed_test_set, columns=[\"gpa\", \"rip\"], index=None)\n",
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Processed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original \n",
    "train_set.to_csv(\"data/{}_train_set_original.csv\".format(model_name), index=None)\n",
    "val_set.to_csv(\"data/{}_val_set_original.csv\".format(model_name), index=None)\n",
    "test_set.to_csv(\"data/{}_test_set_original.csv\".format(model_name), index=None)\n",
    "\n",
    "# Processed \n",
    "processed_train_set.to_csv(\"data/{}_train_set.csv\".format(model_name), index=None)\n",
    "processed_val_set.to_csv(\"data/{}_val_set.csv\".format(model_name), index=None)\n",
    "processed_test_set.to_csv(\"data/{}_test_set.csv\".format(model_name), index=None)"
   ]
  },
  {
   "source": [
    "## Save Pipeline/Statics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "with open(\"static/pipeline_gpa.pkl\", 'wb') as f:\n",
    "    dill.dump(gpa_train_pipeline, f)\n",
    "\n",
    "with open(\"static/pipeline_rip.pkl\", 'wb') as f:\n",
    "    dill.dump(rip_train_pipeline, f)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 25,
   "outputs": []
  },
  {
   "source": [
    "np.savetxt(\"static/vocabulary_gpa.csv\", np.array(list(gpa_train_pipeline[\"sparse_category_encoder\"].vocabulary.keys())), fmt=\"%d\", delimiter=\"\\n\")\n",
    "\n",
    "np.savetxt(\"static/vocabulary_rip.csv\", np.array(list(rip_train_pipeline[\"sparse_category_encoder\"].vocabulary.keys())), fmt=\"%s\", delimiter=\"\\n\")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{-4096: 0,\n",
       " -1: 1,\n",
       " 0: 2,\n",
       " -12288: 3,\n",
       " -8192: 4,\n",
       " -643931498: 5,\n",
       " 643931490: 6,\n",
       " 643931494: 7,\n",
       " -643931494: 8,\n",
       " -643931490: 9,\n",
       " 643931498: 10,\n",
       " 333: 11,\n",
       " -24576: 12,\n",
       " -20480: 13,\n",
       " -16384: 14,\n",
       " -64: 15,\n",
       " -49: 16,\n",
       " -36864: 17,\n",
       " -28672: 18,\n",
       " -3872: 19}"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "dict(list(gpa_train_pipeline[\"sparse_category_encoder\"].vocabulary.items())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '-1': 1,\n",
       " '18446744073709551579': 2,\n",
       " '37': 3,\n",
       " '18446744073709551612': 4,\n",
       " '4': 5,\n",
       " '18446744073709551587': 6,\n",
       " '29': 7,\n",
       " '18446650193870300916': 8,\n",
       " '93879839250700': 9,\n",
       " '18446649955753248500': 10,\n",
       " '94117956303116': 11,\n",
       " '18446649904182912756': 12,\n",
       " '18446649249859774196': 13,\n",
       " '94169526638860': 14,\n",
       " '94823849777420': 15,\n",
       " '18446649929458829044': 16,\n",
       " '94144250722572': 17,\n",
       " '18446649957954295540': 18,\n",
       " '94115755256076': 19}"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "dict(list(rip_train_pipeline[\"sparse_category_encoder\"].vocabulary.items())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(159264, 7240)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "gpa_train_pipeline[\"sparse_category_encoder\"].vocab_size, rip_train_pipeline[\"sparse_category_encoder\"].vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ]
}
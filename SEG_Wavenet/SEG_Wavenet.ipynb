{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit (conda)",
   "display_name": "Python 3.7.6 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mixtures import discretized_mix_logistic_loss, sample_from_discretized_mix_logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1D(keras.layers.Conv1D):\n",
    "    def __init__(self, filters, kernel_size, strides=1, padding=\"causal\", dilation_rate=1, use_bias=False, *args, **kwargs):\n",
    "        super().__init__(filters, kernel_size=kernel_size, strides=strides, padding=padding, dilation_rate=dilation_rate)\n",
    "        \n",
    "        ## (issue) Set name other than k and d invoke error : TypeError: unsupported operand type(s) for +: 'int' and 'tuple'\n",
    "        self.k = kernel_size                \n",
    "        self.d = dilation_rate\n",
    "\n",
    "        self.use_bias = use_bias\n",
    "\n",
    "        if kernel_size > 1:\n",
    "            self.current_receptive_field = kernel_size + (kernel_size - 1) * (dilation_rate - 1)       # == queue_len (tf2)\n",
    "            self.residual_channels = residual_channels\n",
    "            self.queue = tf.zeros([1, self.current_receptive_field, filters])\n",
    "\n",
    "    def build(self, x_shape):\n",
    "        super().build(x_shape)\n",
    "\n",
    "        self.linearized_weights = tf.cast(tf.reshape(self.kernel, [-1, self.filters]), dtype=tf.float32)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        if not training:\n",
    "            return super().call(x)\n",
    "\n",
    "        if self.kernel_size > 1:\n",
    "            self.queue = self.queue[:, 1:, :]\n",
    "            self.queue = tf.concat([self.queue, tf.expand_dims(x[:, -1, :], axis=1)], axis=1)\n",
    "\n",
    "            if self.dilation_rate > 1:\n",
    "                x = self.queue[:, 0::self.d, :]\n",
    "            else:\n",
    "                x = self.queue\n",
    "\n",
    "            outputs = tf.matmul(tf.reshape(x, [1, -1]), self.linearized_weights)\n",
    "            \n",
    "            if self.use_bias:\n",
    "                outputs = tf.nn.bias_add(outputs, self.bias)\n",
    "\n",
    "            return tf.reshape(outputs, [-1, 1, self.filters])\n",
    "\n",
    "    #def init_queue(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.Model):\n",
    "    def __init__(self, layer_index, dilation, filter_width, dilation_channels, residual_channels, skip_channels, use_biases, output_width):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_index = layer_index\n",
    "        self.dilation = dilation\n",
    "        self.filter_width = filter_width\n",
    "        self.dilation_channels = dilation_channels\n",
    "        self.residual_channels = residual_channels\n",
    "        self.skip_channels = skip_channels\n",
    "        self.use_biases = use_biases\n",
    "        self.output_width = output_width        # = Receptive Field\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        with tf.name_scope(\"residual_block_{}\".format(self.layer_index)):\n",
    "            self.conv_filter = keras.layers.Conv1D(\n",
    "                filters=self.dilation_channels,\n",
    "                kernel_size=self.filter_width,\n",
    "                dilation_rate=self.dilation,\n",
    "                padding='valid',\n",
    "                use_bias=self.use_biases,\n",
    "                name=\"conv_filter\"\n",
    "            )\n",
    "            self.conv_gate = keras.layers.Conv1D(\n",
    "                filters=self.dilation_channels,\n",
    "                kernel_size=self.filter_width,\n",
    "                dilation_rate=self.dilation,\n",
    "                padding='valid',\n",
    "                use_bias=self.use_biases,\n",
    "                name=\"conv_gate\"\n",
    "            )\n",
    "            ## transformed : 1x1 conv to out (= gate * filter) to produce residuals (= dense output)\n",
    "            ## conv_residual (=skip_contribution in original)\n",
    "            self.conv_residual = keras.layers.Conv1D(\n",
    "                filters=self.residual_channels,\n",
    "                kernel_size=1,\n",
    "                padding=\"same\",\n",
    "                use_bias=self.use_biases,\n",
    "                name=\"dense\"\n",
    "            )\n",
    "            self.conv_skip = keras.layers.Conv1D(\n",
    "                filters=self.skip_channels,\n",
    "                kernel_size=1,\n",
    "                padding=\"same\",\n",
    "                use_bias=self.use_biases,\n",
    "                name=\"skip\"\n",
    "            )\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=False):\n",
    "        out = tf.tanh(self.conv_filter(inputs)) * tf.sigmoid(self.conv_gate(inputs))\n",
    "        \n",
    "        ## skip_output (=skip contribution in original) : Summed up to create output\n",
    "        skip_cut = tf.shape(out)[1] - self.output_width\n",
    "        out_skip = tf.slice(out, [0, skip_cut, 0], [-1, -1, self.dilation_channels])\n",
    "        skip_output = self.conv_skip(out_skip)\n",
    "\n",
    "        transformed = self.conv_residual(out)\n",
    "        input_cut = tf.shape(x)[1] - tf.shape(transformed)[1]\n",
    "        x_cut = tf.slice(x, [0, input_cut, 0], [-1, -1, -1])\n",
    "        dense_output = x_cut + transformed\n",
    "\n",
    "        return skip_output, dense_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostProcessing(keras.Model):\n",
    "    def __init__(self, skip_channels, out_channels, use_biases):\n",
    "        super().__init__()\n",
    "\n",
    "        self.skip_channels = skip_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.use_biases = use_biases\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        with tf.name_scope(\"postprocessing\"):\n",
    "            self.conv_1 = keras.layers.Conv1D(\n",
    "                filters=self.skip_channels,\n",
    "                kernel_size=1,\n",
    "                padding=\"same\",\n",
    "                use_bias=self.use_biases\n",
    "            )\n",
    "            self.conv_2 = keras.layers.Conv1D(\n",
    "                filters=self.out_channels,\n",
    "                kernel_size=1,\n",
    "                padding=\"same\",\n",
    "                use_bias=self.use_biases\n",
    "            )\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs, training=False):\n",
    "        x = tf.nn.relu(inputs)\n",
    "        x = self.conv_1(x)\n",
    "\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv_2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveNet(keras.Model):\n",
    "    def __init__(self, batch_size, dilations, filter_width, initial_filter_width, dilation_channels, residual_channels, skip_channels, quantization_channels, out_channels, use_biases):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.dilations = dilations\n",
    "        self.filter_width = filter_width\n",
    "        self.initial_filter_width = initial_filter_width\n",
    "        self.dilation_channels = dilation_channels\n",
    "        self.residual_channels = residual_channels\n",
    "        self.skip_channels = skip_channels\n",
    "        self.quantization_channels = quantization_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.use_biases = use_biases\n",
    "\n",
    "        self.receptive_field = (self.filter_width - 1) * sum(self.dilations) + self.initial_filter_width\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        #self.receptive_field = input_shape[1] - sum(self.dilations)      \n",
    "        self.output_width = input_shape[1] - self.receptive_field + 1       # total output width of model\n",
    "\n",
    "        with tf.name_scope(\"preprocessing\"):\n",
    "            self.preprocessing_layer = keras.layers.Conv1D(\n",
    "                filters=self.residual_channels,\n",
    "                kernel_size=self.initial_filter_width,\n",
    "                use_bias=self.use_biases)\n",
    "\n",
    "        self.residual_blocks = []\n",
    "        for _ in range(1):\n",
    "            for i, dilation in enumerate(self.dilations):\n",
    "                self.residual_blocks.append(\n",
    "                    ResidualBlock(\n",
    "                        layer_index=i,\n",
    "                        dilation=self.dilations[0], \n",
    "                        filter_width=self.filter_width, \n",
    "                        dilation_channels=self.dilation_channels, \n",
    "                        residual_channels=self.residual_channels, \n",
    "                        skip_channels=self.skip_channels, \n",
    "                        use_biases=self.use_biases, \n",
    "                        output_width=self.output_width)\n",
    "                    )\n",
    "\n",
    "        self.postprocessing_layer = PostProcessing(self.skip_channels, self.out_channels, self.use_biases)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=False):\n",
    "        '''\n",
    "        == predict_proba_incremental\n",
    "\n",
    "        Assume that x is integer (== scalar_input = True)\n",
    "        '''\n",
    "\n",
    "        x = self.preprocessing_layer(inputs)\n",
    "        skip_outputs = []\n",
    "\n",
    "        for layer_index in range(len(self.dilations)):\n",
    "            skip_output, x = self.residual_blocks[layer_index](x)\n",
    "            skip_outputs.append(skip_output)\n",
    "\n",
    "        skip_sum = tf.math.add_n(skip_outputs)          \n",
    "        \n",
    "        raw_output = self.postprocessing_layer(skip_sum)\n",
    "\n",
    "        out = tf.reshape(raw_output, [self.batch_size, -1, self.out_channels])\n",
    "        proba = sample_from_discretized_mix_logistic(out)\n",
    "\n",
    "        return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1024, 1), dtype=float32, numpy=\n",
       "array([[[122.],\n",
       "        [ 63.],\n",
       "        [110.],\n",
       "        ...,\n",
       "        [222.],\n",
       "        [200.],\n",
       "        [154.]]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 173
    }
   ],
   "source": [
    "x = tf.random.uniform([1, 1024, 1], minval=0, maxval=255, dtype=tf.int32)\n",
    "x = tf.cast(x, tf.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HParms follows the Diagram \n",
    "batch_size = 1\n",
    "dilations = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "filter_width = 2        # == kernel_size\n",
    "initial_filter_width = 32       # from tacokr\n",
    "dilation_channels = 32  # unknown\n",
    "residual_channels = 24\n",
    "skip_channels = 128\n",
    "quantization_channels = 2**8\n",
    "out_channels = 10*3\n",
    "use_biases = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavenet = WaveNet(batch_size, dilations, filter_width, initial_filter_width, dilation_channels, residual_channels, skip_channels, quantization_channels, out_channels, use_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 738), dtype=float32, numpy=\n",
       "array([[ -3.9543817,  -1.       ,  -1.5890498,  -1.       ,  -4.748875 ,\n",
       "        -10.696519 ,  -1.       ,  -1.       ,  -6.1428704,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -2.676597 ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -8.228392 ,  -2.2503147,  -1.4384542,  -2.3819356,  -1.       ,\n",
       "         -1.       ,  -2.6098852,  -1.       ,  -2.3426914,  -1.       ,\n",
       "         -3.7028098,  -3.713524 ,  -2.4401789,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -7.271158 ,  -1.1489387,\n",
       "         -1.5377283,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -3.0452144,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.2507843,  -1.       ,\n",
       "         -4.0857596,  -1.9923627,  -1.       ,  -1.0543884,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -3.3614228,  -1.       ,\n",
       "         -1.3797487,  -1.       ,  -2.8437972,  -4.0081096,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.9096619,  -1.       ,\n",
       "         -1.440906 ,  -1.       ,  -1.       ,  -1.6879652,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.0157936,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.9232168,  -1.       ,  -1.       ,\n",
       "         -8.405339 ,  -1.       ,  -2.6107836,  -8.97031  ,  -1.2819273,\n",
       "         -1.       ,  -1.       ,  -1.5700283,  -1.1991351,  -1.0911543,\n",
       "         -1.       ,  -3.4166012,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.1311485,  -1.       ,  -1.       ,  -6.8449197,\n",
       "         -1.       ,  -1.7620789,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.9527246,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.0473635,  -1.       ,  -9.917637 ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -3.4902503,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.8611205,  -1.       ,  -4.6972404,  -1.       ,  -1.3780627,\n",
       "         -1.       ,  -7.477475 ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -4.1630883,  -1.9964985,  -1.       ,  -4.372342 ,  -7.7127557,\n",
       "         -6.0721703,  -1.       ,  -1.       ,  -2.1338449,  -1.1372527,\n",
       "         -1.       ,  -1.5667679,  -1.       ,  -2.0403175,  -1.       ,\n",
       "         -2.5842965,  -1.6495807,  -2.3937004,  -1.       ,  -1.1766267,\n",
       "         -1.       ,  -2.7374372,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.7888287,  -2.0802975,  -1.       ,  -5.3178215,\n",
       "         -2.443088 ,  -1.       ,  -1.2634985,  -1.0176475,  -1.6535194,\n",
       "         -2.2350957,  -1.4537405,  -1.       ,  -3.1397805,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -3.6070507,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.909496 ,  -2.8041523,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.0636849,  -2.2147214,  -1.       ,\n",
       "         -1.       , -10.307958 ,  -1.       ,  -1.0694686,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -4.8205457,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.1339142,  -1.       ,  -6.3234167,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -2.7319415,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.608706 ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.2681482,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -1.0227361,\n",
       "         -3.5971804,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -3.682912 ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.2602651,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -4.7922935,  -4.013529 ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -4.860169 ,  -1.       ,  -1.       ,  -4.0242968,\n",
       "         -1.       ,  -3.764914 ,  -1.       ,  -1.2645828,  -3.9366386,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.5086018,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -5.0102806,  -1.       ,  -2.324544 ,\n",
       "         -3.9662416,  -1.       ,  -1.       ,  -3.780994 ,  -1.       ,\n",
       "         -5.2260623,  -2.6314979,  -1.       ,  -1.9599946,  -1.       ,\n",
       "         -5.0642858,  -1.       , -10.478675 ,  -1.       ,  -3.5562181,\n",
       "         -1.4979295,  -1.       ,  -1.       ,  -1.6801938,  -1.       ,\n",
       "         -3.5522504,  -1.       ,  -1.       ,  -1.       ,  -4.916968 ,\n",
       "         -1.       ,  -3.2944505,  -1.       ,  -1.       ,  -2.4685154,\n",
       "         -1.       ,  -1.9437621,  -2.073072 ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.686858 ,  -9.669108 ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -3.2164598,  -2.4714684,  -2.028078 ,  -1.0888306,\n",
       "         -1.       ,  -1.       ,  -2.6396751,  -1.       ,  -1.       ,\n",
       "         -1.8293442,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.2927265,  -5.0679083,  -1.       ,  -1.1755064,  -1.       ,\n",
       "         -2.2842445,  -1.       ,  -3.2989419,  -1.       ,  -1.6263835,\n",
       "         -1.491049 ,  -1.       ,  -1.       ,  -1.5461626,  -1.       ,\n",
       "         -1.       ,  -3.1590672,  -4.741929 ,  -1.       ,  -1.       ,\n",
       "         -1.       , -11.170083 ,  -3.5947888,  -1.       ,  -2.6058621,\n",
       "         -1.       ,  -1.       ,  -2.7600522,  -1.       ,  -6.9417477,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -5.356878 ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.4524794,  -2.0171652,  -1.6618398,  -1.       ,  -1.1147608,\n",
       "         -1.       ,  -5.6489735,  -1.       ,  -1.1642314,  -1.       ,\n",
       "         -1.       ,  -6.5617485,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.0440552,  -1.       ,  -3.2580132,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -4.0685067,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.5762011,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.0397952,  -1.       ,  -2.8105044,\n",
       "         -1.       ,  -1.       ,  -1.9053038,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.058696 ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.0459012,  -1.       ,  -3.22402  ,  -1.2210569,  -1.       ,\n",
       "         -2.7464015,  -1.2038169,  -4.8156843,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.1478621,  -1.       ,  -1.1178628,\n",
       "         -2.270629 ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -6.926299 ,  -1.       ,  -1.       ,  -1.       ,  -8.185668 ,\n",
       "         -1.       ,  -3.7778115,  -1.722825 ,  -1.       ,  -1.       ,\n",
       "         -3.0814493,  -1.       ,  -4.9204745,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -2.2061617,  -3.9446504,  -1.       ,  -1.       ,\n",
       "         -9.084392 ,  -2.314149 ,  -2.4029424,  -1.       ,  -4.1935515,\n",
       "         -2.9298048,  -1.       ,  -1.1428542,  -1.       ,  -7.4942527,\n",
       "         -9.852905 ,  -1.6679301,  -1.       ,  -5.328917 ,  -1.       ,\n",
       "         -1.       ,  -3.9762242,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -2.2651658,\n",
       "         -5.2379546,  -1.       ,  -1.       ,  -5.236444 ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -2.5842156,  -1.       ,\n",
       "         -1.       ,  -1.483692 ,  -1.       ,  -1.       ,  -8.29218  ,\n",
       "         -1.       ,  -1.       ,  -3.0965767,  -1.       ,  -1.       ,\n",
       "         -7.7242255,  -1.       ,  -1.       ,  -1.       ,  -4.38897  ,\n",
       "         -4.1891994,  -4.422999 ,  -1.       ,  -2.174538 ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -3.375471 ,  -1.       ,  -2.6343307,  -1.1720998,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -5.3984632,  -1.       ,\n",
       "         -6.3458366,  -1.       ,  -1.       ,  -2.4752412,  -1.       ,\n",
       "         -2.3835375,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -2.116703 ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -2.037862 ,  -1.       ,  -1.8929113,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -5.8155622,  -1.       ,  -1.       ,\n",
       "        -10.599942 ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -4.222397 ,  -1.1163142,  -1.       ,  -1.       ,\n",
       "         -1.0479692,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -2.9315226,\n",
       "        -11.222402 ,  -1.       ,  -1.       ,  -1.       ,  -4.2141647,\n",
       "         -1.       ,  -1.       ,  -5.11886  ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.3557379,  -1.       ,  -4.2724504,\n",
       "         -1.       ,  -7.0246553,  -3.82342  ,  -1.       ,  -1.       ,\n",
       "         -1.1321523,  -1.       ,  -1.       ,  -1.       ,  -1.5859854,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       , -11.9032135,\n",
       "         -2.8456137, -15.243007 ,  -1.       ,  -1.       ,  -1.1358546,\n",
       "         -1.594133 ,  -1.       ,  -1.894227 ,  -1.       ,  -5.6110044,\n",
       "         -1.       ,  -2.2555783,  -1.7347548,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -6.624675 ,  -1.9551549,  -1.       ,\n",
       "         -1.9691801,  -1.       ,  -1.6258754,  -1.       ,  -1.0031717,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -5.4916353,  -2.340736 ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -2.3618233,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -1.6129527,\n",
       "         -1.       ,  -2.4714985,  -1.       ,  -1.       ,  -4.335902 ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -3.0096955,  -2.3782601,\n",
       "         -1.       ,  -4.879593 ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -1.1623782,\n",
       "         -1.       ,  -1.       ,  -1.3387539,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -4.834745 ,  -1.       ,  -1.       ,  -1.3925072,\n",
       "         -1.       ,  -1.       ,  -1.       ,  -1.       ,  -1.       ,\n",
       "         -1.       ,  -1.       ,  -3.620271 ]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 176
    }
   ],
   "source": [
    "wavenet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "738"
      ]
     },
     "metadata": {},
     "execution_count": 171
    }
   ],
   "source": [
    "wavenet.output_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
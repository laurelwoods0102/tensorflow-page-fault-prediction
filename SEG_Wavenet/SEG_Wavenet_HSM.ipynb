{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import kerastuner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import dill\n",
    "import tqdm\n",
    "from queue import PriorityQueue\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "from copy import copy\n",
    "\n",
    "class TreeTools:\n",
    "    def __init__(self):\n",
    "        #memoization for _count_nodes functions\n",
    "        self._count_nodes_dict = {}\n",
    "                \n",
    "    def _get_subtrees(self, tree):\n",
    "        yield tree\n",
    "        for subtree in tree:\n",
    "            if type(subtree) == list:\n",
    "                for x in self._get_subtrees(subtree):\n",
    "                    yield x\n",
    "\n",
    "    # Returns pairs of paths and leaves of a tree\n",
    "    def _get_leaves_paths(self, tree):\n",
    "        for i, subtree in enumerate(tree):\n",
    "            if type(subtree) == list:\n",
    "                for path, value in self._get_leaves_paths(subtree):\n",
    "                    yield [i] + path, value\n",
    "            else:\n",
    "                yield [i], subtree\n",
    "    \n",
    "    # Returns the number of nodes in a tree (not including root)\n",
    "    def _count_nodes(self, tree):\n",
    "        if id(tree) in self._count_nodes_dict:\n",
    "            return self._count_nodes_dict[id(tree)]\n",
    "        size = 0\n",
    "        for node in tree:\n",
    "            if type(node) == list:\n",
    "                size += 1 + self._count_nodes(node)\n",
    "        self._count_nodes_dict[id(self._count_nodes_dict)] = size\n",
    "        return size\n",
    "\n",
    "\n",
    "    # Returns all the nodes in a path\n",
    "    def _get_nodes(self, tree, path):\n",
    "        next_node = 0\n",
    "        nodes = []\n",
    "        for decision in path:\n",
    "            nodes.append(next_node)\n",
    "            next_node += 1 + self._count_nodes(tree[:decision])\n",
    "            tree = tree[decision]\n",
    "        return nodes\n",
    "\n",
    "    def _value_to_path_nodes_dict(self, tree):\n",
    "        value_to_path_nodes_dict = {}\n",
    "        for path, value in tqdm.tqdm(self._get_leaves_paths(tree)):\n",
    "            nodes = self._get_nodes(tree, path)\n",
    "            value_to_path_nodes_dict[value] = path, nodes\n",
    "        return value_to_path_nodes_dict\n",
    "\n",
    "\n",
    "# turns a list to a binary tree\n",
    "def random_binary_full_tree(outputs):\n",
    "    outputs = copy(outputs)\n",
    "    shuffle(outputs)\n",
    "\n",
    "    while len(outputs) > 2:\n",
    "        temp_outputs = []\n",
    "        for i in range(0, len(outputs), 2):\n",
    "            if len(outputs) - (i+1) > 0:\n",
    "                temp_outputs.append([outputs[i], outputs[i+1]])\n",
    "            else:\n",
    "                temp_outputs.append(outputs[i])\n",
    "        outputs = temp_outputs\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Our tree: [[[[4, 8], [5, 6]], [[0, 2], [9, 7]]], [1, 3]]\n",
      "All subtrees:\n",
      "\t [[[[4, 8], [5, 6]], [[0, 2], [9, 7]]], [1, 3]] (Len : 2)\n",
      "\t [[[4, 8], [5, 6]], [[0, 2], [9, 7]]] (Len : 2)\n",
      "\t [[4, 8], [5, 6]] (Len : 2)\n",
      "\t [4, 8] (Len : 2)\n",
      "\t [5, 6] (Len : 2)\n",
      "\t [[0, 2], [9, 7]] (Len : 2)\n",
      "\t [0, 2] (Len : 2)\n",
      "\t [9, 7] (Len : 2)\n",
      "\t [1, 3] (Len : 2)\n",
      "All paths and leaves:\n",
      "\t ([0, 0, 0, 0], 4)\n",
      "\t ([0, 0, 0, 1], 8)\n",
      "\t ([0, 0, 1, 0], 5)\n",
      "\t ([0, 0, 1, 1], 6)\n",
      "\t ([0, 1, 0, 0], 0)\n",
      "\t ([0, 1, 0, 1], 2)\n",
      "\t ([0, 1, 1, 0], 9)\n",
      "\t ([0, 1, 1, 1], 7)\n",
      "\t ([1, 0], 1)\n",
      "\t ([1, 1], 3)\n",
      "Number of nodes in the tree: 8\n",
      "all nodes in path [0, 0, 0, 0]:\n",
      "\t 0\n",
      "\t 1\n",
      "\t 2\n",
      "\t 3\n",
      "all nodes in path [1, 0]:\n",
      "\t 0\n",
      "\t 8\n"
     ]
    }
   ],
   "source": [
    "tree = random_binary_full_tree(list(range(10)))\n",
    "print('Our tree:',tree)\n",
    "\n",
    "tree_tools = TreeTools()    \n",
    "\n",
    "print('All subtrees:')\n",
    "for subtree in tree_tools._get_subtrees(tree):\n",
    "    print('\\t {} (Len : {})'.format(subtree, len(subtree)))\n",
    "\n",
    "print('All paths and leaves:')\n",
    "for subtree in tree_tools._get_leaves_paths(tree):\n",
    "    print('\\t',subtree)\n",
    "    \n",
    "print('Number of nodes in the tree:',tree_tools._count_nodes(tree))\n",
    "\n",
    "print('all nodes in path [0, 0, 0, 0]:')\n",
    "for nodes in tree_tools._get_nodes(tree, [0, 0, 0, 0]):\n",
    "    print('\\t',nodes)\n",
    "\n",
    "print('all nodes in path [1, 0]:')\n",
    "for nodes in tree_tools._get_nodes(tree, [1, 0]):\n",
    "    print('\\t',nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'TreeTools' object has no attribute 'value_to_path_and_nodes_dict'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0a621acfef8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtree_tools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_to_path_and_nodes_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'TreeTools' object has no attribute 'value_to_path_and_nodes_dict'"
     ]
    }
   ],
   "source": [
    "tree_tools._value_to_path_and_nodes_dict(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hier_softmax:\n",
    "    def __init__(self, tree, contex_size, model):\n",
    "        self._tree_tools = TreeTools()\n",
    "        self.str2weight = {}\n",
    "        #create a weight matrix and bias vector for each node in the tree\n",
    "        for i, subtree in enumerate(self._tree_tools._get_subtrees(tree)):\n",
    "            self.str2weight[\"softmax_node_\"+str(i)+\"_w\"] = model.add_parameters((len(subtree), contex_size))\n",
    "            self.str2weight[\"softmax_node_\" + str(i) + \"_b\"] = model.add_parameters(len(subtree))\n",
    "        \n",
    "        #create a dictionary from each value to its path\n",
    "        value_to_path_and_nodes_dict = {}\n",
    "        for path, value in self._tree_tools._get_leaves_paths(tree):\n",
    "            nodes = self._tree_tools._get_nodes(tree, path)\n",
    "            value_to_path_and_nodes_dict[data.char2int[value]] = path, nodes\n",
    "        self.value_to_path_and_nodes_dict = value_to_path_and_nodes_dict\n",
    "        self.model = model\n",
    "        self.tree = tree\n",
    "    \n",
    "    #get the loss on a given value (for training)\n",
    "    def get_loss(self, context, value):\n",
    "        loss = []\n",
    "        path, nodes = self.value_to_path_and_nodes_dict[value]\n",
    "        for p, n in zip(path, nodes):\n",
    "            w = dy.parameter(self.str2weight[\"softmax_node_\"+str(n)+\"_w\"])\n",
    "            b = dy.parameter(self.str2weight[\"softmax_node_\" + str(n) + \"_b\"])\n",
    "            probs = tf.nn.softmax(w*context+b)\n",
    "            #loss.append(-tf.math.log(dy.pick(probs, p)))\n",
    "            print(probs)\n",
    "            print(p)\n",
    "        #return dy.esum(loss)\n",
    "\n",
    "    #get the most likely\n",
    "    def generate(self, context):\n",
    "        best_value = None\n",
    "        best_loss = float(100000)\n",
    "        for value in self.value_to_path_and_nodes_dict:\n",
    "            loss = self.get_loss(context, value)\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_value = value\n",
    "        return best_value"
   ]
  },
  {
   "source": [
    "Huffman Encoding \n",
    "\n",
    "# Main function implementing huffman coding\n",
    "def huffman_code_tree(node, path, left=True):\n",
    "    if type(node) is not Node:\n",
    "        return {node: path}\n",
    "    (l, r) = node.children()\n",
    "    d = dict()\n",
    "\n",
    "    l_path = copy(path)\n",
    "    l_path.append(0)\n",
    "    r_path = copy(path)\n",
    "    r_path.append(1)\n",
    "\n",
    "    d.update(huffman_code_tree(l, l_path, True))\n",
    "    d.update(huffman_code_tree(r, r_path, False))\n",
    "    return d\n",
    "\n",
    "nodes = list(freq.items())\n",
    "\n",
    "while len(nodes) > 1:\n",
    "    (key1, c1) = nodes[-1]\n",
    "    (key2, c2) = nodes[-2]\n",
    "    nodes = nodes[:-2]\n",
    "    node = Node(key1, key2)\n",
    "    nodes.append((node, c1 + c2))\n",
    "\n",
    "    nodes = sorted(nodes, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "huffmanCode = huffman_code_tree(nodes[0][0], [])\n",
    "huffmanCode"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Huffman Binary Tree as Node (not as list)\n",
    "\n",
    "class Node(object):\n",
    "    node_id = 0\n",
    "    def __init__(self, symbol, freq, left=None, right=None):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.symbol = symbol\n",
    "        self.freq = freq\n",
    "\n",
    "        if self.symbol == None:\n",
    "            self.node_id = Node.node_id\n",
    "            Node.node_id += 1\n",
    "\n",
    "    def children(self):\n",
    "        return (self.left, self.right)\n",
    "\n",
    "    def __lt__(self, target):\n",
    "        if type(target) == Node:\n",
    "            return self.freq < target.freq\n",
    "        else:\n",
    "            return self.freq < target\n",
    "    \n",
    "    def __gt__(self, target):\n",
    "        return not self.__lt__(target)\n",
    "\n",
    "nodes = list(freq.items())\n",
    "q = PriorityQueue()\n",
    "\n",
    "for node in nodes:\n",
    "    q.put(Node(node[0], node[1]))\n",
    "\n",
    "while q.qsize() > 1:\n",
    "    node_1 = q.get()\n",
    "    node_2 = q.get()\n",
    "    print(node_1.symbol, node_1.freq)\n",
    "    print(node_2.symbol, node_2.freq)\n",
    "    node = Node(None, node_1.freq + node_2.freq, node_1, node_2)\n",
    "    q.put(node)\n",
    "\n",
    "def traverse(tree):\n",
    "    l, r = tree.children()\n",
    "    if l == None or r == None:\n",
    "        print(tree.symbol)\n",
    "        return\n",
    "    #print(tree.freq)    \n",
    "    \n",
    "    traverse(l)\n",
    "    traverse(r)\n",
    "\n",
    "traverse(tree)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    '''\n",
    "    Wrapping List with Node class Since pythn PriorityQueue cannot recognize nested items in its input tuple.\n",
    "    '''\n",
    "    def __init__(self, symbol, freq, symbol_2=None):\n",
    "        if symbol_2:\n",
    "            self.symbol = [symbol, symbol_2]\n",
    "        else:\n",
    "            self.symbol = symbol\n",
    "        self.freq = freq\n",
    "\n",
    "    def __lt__(self, target):\n",
    "        if type(target) == Node:\n",
    "            return self.freq < target.freq\n",
    "        else:\n",
    "            return self.freq < target\n",
    "    \n",
    "    def __gt__(self, target):\n",
    "        return not self.__lt__(target)\n",
    "\n",
    "def create_huffman_tree(input_dict):\n",
    "    '''\n",
    "    input : dictionary with {category:freq} pairs\n",
    "    NOTE : input dict must be ASCENDING order\n",
    "    '''\n",
    "    q = PriorityQueue()\n",
    "    nodes = list(input_dict.items())\n",
    "\n",
    "    for node in nodes:\n",
    "        q.put(Node(node[0], node[1]))\n",
    "\n",
    "    while q.qsize() > 1:\n",
    "        node_1 = q.get()\n",
    "        node_2 = q.get()\n",
    "        #print(node_1.symbol, node_1.freq)\n",
    "        #print(node_2.symbol, node_2.freq)\n",
    "        node = Node(node_1.symbol, node_1.freq + node_2.freq, node_2.symbol)\n",
    "        q.put(node)\n",
    "    return q.get().symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.genfromtxt(\"data/{}_train_set_2.csv\".format(\"SEG_Wavenet\"), delimiter=\"\\n\", dtype=np.int64)\n",
    "val_set = np.genfromtxt(\"data/{}_val_set_2.csv\".format(\"SEG_Wavenet\"), delimiter=\"\\n\", dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([46144, 52215, 23250, ...,   889,   246,  1385], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "dataset = np.r_[train_set, val_set]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_freq = pd.Series(dataset).value_counts(ascending=True).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1        26424\n",
       "2         6295\n",
       "3         1849\n",
       "4         1848\n",
       "5         1207\n",
       "         ...  \n",
       "53853        1\n",
       "33367        1\n",
       "35414        1\n",
       "37461        1\n",
       "36397        1\n",
       "Length: 55277, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "pd.Series(dataset).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = create_huffman_tree(dataset_freq)"
   ]
  },
  {
   "source": [
    "tree_tools = TreeTools()    \n",
    "'''\n",
    "print('All subtrees:')      # Num of All subtrees : 55276\n",
    "for subtree in tree_tools._get_subtrees(tree):\n",
    "    print('\\t {} (Len : {})'.format(subtree, len(subtree)))\n",
    "\n",
    "print('All paths and leaves:')\n",
    "for subtree in tree_tools._get_leaves_paths(tree):\n",
    "    print('\\t',subtree)\n",
    "'''\n",
    "num_nodes = tree_tools._count_nodes(tree)\n",
    "print('Number of nodes in the tree:', num_nodes) # Num of All nodes (except root): 55275\n",
    "\n",
    "print('all nodes in path [0, 0, 0, 0]:')\n",
    "for nodes in tree_tools._get_nodes(tree, [1, 1, 0, 0]):\n",
    "    print('\\t',nodes)\n",
    "\n",
    "print('all nodes in path [1, 0]:')\n",
    "for nodes in tree_tools._get_nodes(tree, [1, 0]):\n",
    "    print('\\t',nodes)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of nodes in the tree: 55275\n",
      "all nodes in path [0, 0, 0, 0]:\n",
      "\t 0\n",
      "\t 17143\n",
      "\t 19783\n",
      "\t 19784\n",
      "all nodes in path [1, 0]:\n",
      "\t 0\n",
      "\t 17143\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "55277it [15:20, 60.08it/s]\n"
     ]
    }
   ],
   "source": [
    "mapping_dict = tree_tools._value_to_path_nodes_dict(tree)"
   ]
  },
  {
   "source": [
    "import json\n",
    "\n",
    "with open(\"static/mappding_dict.json\", \"w\") as j:\n",
    "    json.dump(mapping_dict, j, indent=4)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierachicalSoftmax(keras.Model):\n",
    "    def __init__(self, mapping_dict):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mapping_dict = mapping_dict\n",
    "        self.decision_function = {1:1, 0:-1}\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.initializer = keras.initializers.GlorotNormal()\n",
    "        self.softmax_weights = tf.Variable(self.initializer(shape=(len(self.mapping_dict)-1, input_shape[-1], 1)))\n",
    "\n",
    "    def call(self, x):\n",
    "        total_loss =[]\n",
    "        for category, (path, nodes) in  self.mapping_dict.items()[:11]:\n",
    "            loss = []\n",
    "            for p, n in zip(path, nodes):\n",
    "                w = self.softmax_weights[n]\n",
    "                d = self.decision_function[p]\n",
    "                sigma = tf.nn.softmax(w*x)\n",
    "                loss.append(tf.tensordot(sigma, d))\n",
    "            total_loss.append(tf.math.reduce_prod(loss))\n",
    "        return total_loss\n",
    "\n",
    "    def train_step(self, data):\n",
    "        loss = []\n",
    "        for p, n in zip(path, nodes):\n",
    "            raw_prob = tf.nn.softmax(x * self.softmax_weights[n])\n",
    "            loss.append(tf.tensordot(raw_prob, self.decision_function[p]))\n",
    "        return tf.reduce_prod(loss, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "0",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-160f0a0042d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmapping_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "mapping_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "55277"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "len(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(ListWrapper([1, 0, 0]), ListWrapper([0, 17143, 17144]))"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "mapping_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "20456 ListWrapper([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) ListWrapper([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])\n"
     ]
    }
   ],
   "source": [
    "for category, (path, nodes) in mapping_dict.items():\n",
    "    print(category, path, nodes)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 6, 4])>"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "tf.math.multiply(tf.constant([1, 2, 1]), tf.constant([2, 3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=6>"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "tf.reduce_prod(tf.constant([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 30), dtype=float32, numpy=\n",
       "array([[[0.18911195, 0.37342346, 0.9745028 , 0.66212094, 0.879431  ,\n",
       "         0.7414323 , 0.5117035 , 0.6403229 , 0.67704856, 0.3146212 ,\n",
       "         0.8127583 , 0.05822527, 0.18394876, 0.30106592, 0.4722501 ,\n",
       "         0.98014295, 0.6283145 , 0.16613781, 0.6566857 , 0.66950905,\n",
       "         0.24273705, 0.60346067, 0.5234035 , 0.5597247 , 0.9225699 ,\n",
       "         0.3113091 , 0.69289136, 0.24133515, 0.9949957 , 0.05192733]]],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 1, 30))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsm = HierachicalSoftmax(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Tensor is unhashable. Instead, use tensor.ref() as the key.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-30780892d2b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhsm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-64-4afae4566089>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapping_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    821\u001b[0m     if (Tensor._USE_EQUALITY and executing_eagerly_outside_functions() and\n\u001b[0;32m    822\u001b[0m         (g is None or g.building_function)):\n\u001b[1;32m--> 823\u001b[1;33m       raise TypeError(\"Tensor is unhashable. \"\n\u001b[0m\u001b[0;32m    824\u001b[0m                       \"Instead, use tensor.ref() as the key.\")\n\u001b[0;32m    825\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Tensor is unhashable. Instead, use tensor.ref() as the key."
     ]
    }
   ],
   "source": [
    "hsm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = keras.initializers.GlorotNormal()\n",
    "softmax_weights = tf.Variable(initializer(shape=(len(mapping_dict)-1, x.shape[-1], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_function = {1:1, 0:-1}\n",
    "\n",
    "def call(x):\n",
    "    total_loss =[]\n",
    "    for category, (path, nodes) in list(mapping_dict.items())[:11]:\n",
    "        loss = []\n",
    "        for p, n in zip(path, nodes):\n",
    "            w = softmax_weights[n]\n",
    "            d = decision_function[p]\n",
    "            sigma = tf.nn.softmax(w*x)\n",
    "            loss.append(tf.tensordot(sigma, d, axes=))\n",
    "        total_loss.append(tf.math.reduce_prod(loss))\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "tensordot() missing 1 required positional argument: 'axes'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-ff00170b0994>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-88-bd7ef865331d>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecision_function\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mtotal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_prod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: tensordot() missing 1 required positional argument: 'axes'"
     ]
    }
   ],
   "source": [
    "call(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
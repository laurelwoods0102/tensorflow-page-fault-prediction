{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import dill\n",
    "import tqdm\n",
    "from queue import PriorityQueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hier_softmax:\n",
    "    def __init__(self, tree, contex_size, model):\n",
    "        self._tree_tools = TreeTools()\n",
    "        self.str2weight = {}\n",
    "        #create a weight matrix and bias vector for each node in the tree\n",
    "        for i, subtree in enumerate(self._tree_tools._get_subtrees(tree)):\n",
    "            self.str2weight[\"softmax_node_\"+str(i)+\"_w\"] = model.add_parameters((len(subtree), contex_size))\n",
    "            self.str2weight[\"softmax_node_\" + str(i) + \"_b\"] = model.add_parameters(len(subtree))\n",
    "        \n",
    "        #create a dictionary from each value to its path\n",
    "        value_to_path_and_nodes_dict = {}\n",
    "        for path, value in self._tree_tools._get_leaves_paths(tree):\n",
    "            nodes = self._tree_tools._get_nodes(tree, path)\n",
    "            value_to_path_and_nodes_dict[data.char2int[value]] = path, nodes\n",
    "        self.value_to_path_and_nodes_dict = value_to_path_and_nodes_dict\n",
    "        self.model = model\n",
    "        self.tree = tree\n",
    "    \n",
    "    #get the loss on a given value (for training)\n",
    "    def get_loss(self, context, value):\n",
    "        loss = []\n",
    "        path, nodes = self.value_to_path_and_nodes_dict[value]\n",
    "        for p, n in zip(path, nodes):\n",
    "            w = dy.parameter(self.str2weight[\"softmax_node_\"+str(n)+\"_w\"])\n",
    "            b = dy.parameter(self.str2weight[\"softmax_node_\" + str(n) + \"_b\"])\n",
    "            probs = tf.nn.softmax(w*context+b)\n",
    "            #loss.append(-tf.math.log(dy.pick(probs, p)))\n",
    "            print(probs)\n",
    "            print(p)\n",
    "        #return dy.esum(loss)\n",
    "\n",
    "    #get the most likely\n",
    "    def generate(self, context):\n",
    "        best_value = None\n",
    "        best_loss = float(100000)\n",
    "        for value in self.value_to_path_and_nodes_dict:\n",
    "            loss = self.get_loss(context, value)\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_value = value\n",
    "        return best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.genfromtxt(\"data/{}_train_set.csv\".format(\"SEG_Wavenet\"), delimiter=\"\\n\", dtype=np.int64)\n",
    "val_set = np.genfromtxt(\"data/{}_val_set.csv\".format(\"SEG_Wavenet\"), delimiter=\"\\n\", dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  0,   0,   0, ..., 897, 242, 961], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "dataset = np.r_[train_set, val_set]\n",
    "dataset"
   ]
  },
  {
   "source": [
    "## NOTE\n",
    "Intermediate Nodes are indexed by **Preorder Traversal**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 16293\n",
    "num_of_nodes = vocab_size - 1   # num of intermediate nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{2192: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]],\n",
       " 2396: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]],\n",
       " 2647: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14]],\n",
       " 1579: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14]],\n",
       " 2247: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16]]}"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "with open(\"outputs/tree_mapping.json\", \"r\") as j:\n",
    "    tree_mapping = json.load(j)     # category : [path, nodes in path]\n",
    "tree_mapping = {int(i):j for i, j in tree_mapping.items()}      # As JSON converts key values to string\n",
    "dict(list(tree_mapping.items())[:5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([[0, 1], [0, 1]], [[1, 0, 1], [0, 5436, 5437]])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "tree_mapping[0], tree_mapping[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_matrix = np.full([vocab_size, 2, num_of_nodes], -1, dtype=np.int32)    # tree_matrix[][0] : path / tree_matrix[][1] : nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category, (path, nodes) in tree_mapping.items():\n",
    "    tree_matrix[category][0][:len(path)] = path\n",
    "    tree_matrix[category][1][:len(path)] = nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierachicalSoftmax(keras.Model):\n",
    "    def __init__(self, tree_mapping, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        # decision_function = {1:1, 0:-1}\n",
    "        self.decision_function = tf.lookup.StaticHashTable(\n",
    "            tf.lookup.KeyValueTensorInitializer(tf.constant([0, 1], dtype=tf.int32), tf.constant([-1, 1], dtype=tf.float32)), -1\n",
    "        )      \n",
    "\n",
    "        self.tree_mapping = np.full([vocab_size, 2, vocab_size-1], -1, dtype=np.int32)\n",
    "        for category, (path, nodes) in tree_mapping.items():\n",
    "            self.tree_mapping[category][0][:len(path)] = path\n",
    "            self.tree_mapping[category][1][:len(path)] = nodes\n",
    "        self.tree_mapping = tf.constant(self.tree_mapping)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.initializer = keras.initializers.GlorotNormal()\n",
    "        self.softmax_weights = tf.Variable(self.initializer(shape=(len(self.tree_mapping)-1, input_shape[-1])))\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        total_loss = tf.TensorArray(dtype=tf.float32, size=vocab_size)\n",
    "        for x in inputs:\n",
    "            for i in tf.range(self.vocab_size):\n",
    "                path = self.tree_mapping[i][0]\n",
    "                nodes = self.tree_mapping[i][1]\n",
    "                loss = tf.TensorArray(dtype=tf.float32, size=path.shape[0])\n",
    "                for j in tf.range(path.shape[0]):\n",
    "                    w = self.softmax_weights[nodes[j]]\n",
    "                    d = self.decision_function.lookup(path[j])\n",
    "                    sigma = tf.nn.softmax(w*x)\n",
    "                    loss = loss.write(j, tf.tensordot(sigma, d, axes=0))\n",
    "                total_loss = total_loss.write(i, tf.reduce_prod(loss.stack(), axis=-1))\n",
    "        return total_loss.stack()\n",
    "\n",
    "    def train_step(self, data):\n",
    "        loss = []\n",
    "        for p, n in zip(path, nodes):\n",
    "            raw_prob = tf.nn.softmax(x * self.softmax_weights[n])\n",
    "            loss.append(tf.tensordot(raw_prob, self.decision_function[p]))\n",
    "        return tf.reduce_prod(loss, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsm = HierachicalSoftmax(tree_mapping, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 1., 2., 3.], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "x = tf.constant([0, 1], dtype=tf.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.TensorArray(tf.int32, size=2)\n",
    "t = t.write(0, tf.constant(1))\n",
    "t = t.write(1, tf.constant(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 3])>"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "t.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
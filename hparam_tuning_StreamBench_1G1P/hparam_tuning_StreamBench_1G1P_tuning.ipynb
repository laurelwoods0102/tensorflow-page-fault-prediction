{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598098422272",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'20200822-234051'"
     },
     "metadata": {},
     "execution_count": 175
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = \"logs/fit/\" + timestamp\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "version_dir = \"version/\" + timestamp \n",
    "\n",
    "os.makedirs(log_dir)\n",
    "os.makedirs(version_dir)\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"StreamBench_1G1P\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              t           t+1  delta  tokenized_data\n0  104291368960  104291373056   4096            4096\n1  104291373056  104291377152   4096            4096\n2  104291377152  104291381248   4096            4096\n3  104291381248  104291385344   4096            4096\n4  104291385344  104291389440   4096            4096",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t</th>\n      <th>t+1</th>\n      <th>delta</th>\n      <th>tokenized_data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>104291368960</td>\n      <td>104291373056</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>104291373056</td>\n      <td>104291377152</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>104291377152</td>\n      <td>104291381248</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>104291381248</td>\n      <td>104291385344</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>104291385344</td>\n      <td>104291389440</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 177
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"data/{}_train_set.csv\".format(dataset_name))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static Parameters \n",
    "static_params = dict()\n",
    "static_params[\"PAST_HISTORY\"] = 16\n",
    "static_params[\"FUTURE_TARGET\"] = 8\n",
    "static_params[\"BUFFER_SIZE\"] = 200000\n",
    "static_params[\"ACTIVATION\"] = 'softmax'\n",
    "static_params[\"LOSS_FUNCTION\"] = 'categorical_crossentropy'\n",
    "static_params[\"VAL_SPLIT\"] = 0.2\n",
    "static_params[\"METRIC_ACCURACY\"] = 'accuracy'\n",
    "\n",
    "# Hyper Parameters\n",
    "HP_BATCH_SIZE = hp.HParam('batch_size', hp.Discrete([256, 512, 1024]))\n",
    "HP_EPOCHS = hp.HParam('epochs', hp.Discrete([5, 10]))   #250, 500, 750, 1000\n",
    "HP_LAYER_1_UNITS = hp.HParam('layer_1_units', hp.Discrete([4, 8]))  #, 16, 32, 64, 128\n",
    "HP_LAYER_2_UNITS = hp.HParam('layer_2_units', hp.Discrete([4, 8, 16, 32, 64, 128]))\n",
    "HP_LAYER_1_DROPOUT = hp.HParam('layer_1_dropout', hp.RealInterval(0.1, 0.2))\n",
    "HP_LAYER_2_DROPOUT = hp.HParam('layer_2_dropout', hp.RealInterval(0.1, 0.2))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_BATCH_SIZE, HP_EPOCHS, HP_LAYER_1_UNITS, HP_LAYER_2_UNITS, HP_LAYER_1_DROPOUT, HP_LAYER_2_DROPOUT, HP_OPTIMIZER],\n",
    "    metrics=[hp.Metric(static_params[\"METRIC_ACCURACY\"], display_name='Accuracy')],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timeseries(dataset, start_index, end_index, history_size, target_size, n_features):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i)\n",
    "        # Reshape data from (history_size,) to (history_size, n_feature)\n",
    "        data.append(np.reshape(dataset[indices], (history_size, n_features)))\n",
    "        labels.append(dataset[i:i+target_size])\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(<1x5 sparse matrix of type '<class 'numpy.float32'>'\n \twith 1 stored elements in Compressed Sparse Row format>,\n [array([-6291456,       -1,        0,     4096,  2097152], dtype=int64)])"
     },
     "metadata": {},
     "execution_count": 180
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(dtype=np.float32)\n",
    "encoded_data = encoder.fit_transform(dataset[\"tokenized_data\"].values.reshape(-1, 1))\n",
    "encoded_data[0], encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((33634, 16, 5), (33634, 8, 5))"
     },
     "metadata": {},
     "execution_count": 181
    }
   ],
   "source": [
    "x_train, y_train = generate_timeseries(encoded_data.toarray(), 0, None, static_params[\"PAST_HISTORY\"], static_params[\"FUTURE_TARGET\"], len(encoder.categories_[0]))\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              t           t+1    delta  tokenized_data\n0  103653834752  103655931904  2097152         2097152\n1  103655931904  103655931904        0               0\n2  103655931904  103649640448 -6291456        -6291456\n3  103649640448  103649640448        0               0\n4  103649640448  103651737600  2097152         2097152",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t</th>\n      <th>t+1</th>\n      <th>delta</th>\n      <th>tokenized_data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>103653834752</td>\n      <td>103655931904</td>\n      <td>2097152</td>\n      <td>2097152</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>103655931904</td>\n      <td>103655931904</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>103655931904</td>\n      <td>103649640448</td>\n      <td>-6291456</td>\n      <td>-6291456</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>103649640448</td>\n      <td>103649640448</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>103649640448</td>\n      <td>103651737600</td>\n      <td>2097152</td>\n      <td>2097152</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 182
    }
   ],
   "source": [
    "test_dataset = pd.read_csv(\"data/{}_test_set.csv\".format(dataset_name))\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<1x5 sparse matrix of type '<class 'numpy.float32'>'\n\twith 1 stored elements in Compressed Sparse Row format>"
     },
     "metadata": {},
     "execution_count": 183
    }
   ],
   "source": [
    "encoded_test_data = encoder.transform(test_dataset[\"tokenized_data\"].values.reshape(-1, 1))\n",
    "encoded_test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(11196, 16, 5)"
     },
     "metadata": {},
     "execution_count": 184
    }
   ],
   "source": [
    "x_test, y_test = generate_timeseries(encoded_test_data.toarray(), 0, None, static_params[\"PAST_HISTORY\"], static_params[\"FUTURE_TARGET\"], len(encoder.categories_[0]))\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hparams):\n",
    "    print(hparams[HP_LAYER_1_UNITS])\n",
    "    print(hparams[HP_OPTIMIZER])\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Bidirectional(keras.layers.LSTM(hparams[HP_LAYER_1_UNITS])),\n",
    "        keras.layers.Dropout(hparams[HP_LAYER_1_DROPOUT]),\n",
    "        keras.layers.RepeatVector(static_params[\"FUTURE_TARGET\"]),\n",
    "        keras.layers.Bidirectional(keras.layers.LSTM(hparams[HP_LAYER_2_UNITS], return_sequences=True)),\n",
    "        keras.layers.Dropout(hparams[HP_LAYER_2_DROPOUT]),\n",
    "        keras.layers.TimeDistributed(keras.layers.Dense(len(encoder.categories_[0]), activation=static_params[\"ACTIVATION\"]))\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=hparams[HP_OPTIMIZER],\n",
    "        loss=static_params[\"LOSS_FUNCTION\"],\n",
    "        metrics=static_params[\"METRIC_ACCURACY\"]\n",
    "    )\n",
    "    history = model.fit(x_train, y_train, batch_size=hparams[HP_BATCH_SIZE], validation_split=static_params[\"VAL_SPLIT\"], epochs=hparams[HP_EPOCHS])\n",
    "    _, accuracy = model.evaluate(x_test, y_test)\n",
    "    return history, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)\n",
    "        history, accuracy = create_model(hparams)\n",
    "        tf.summary.scalar(static_params[\"METRIC_ACCURACY\"], accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "--- Starting trial: run-0\n{'layer_1_units': 4, 'layer_1_dropout': 0.1, 'layer_2_units': 8, 'layer_2_dropout': 0.1, 'batch_size': 256, 'epochs': 5, 'optimizer': 'adam'}\n4\nadam\nEpoch 1/5\n106/106 [==============================] - 2s 14ms/step - loss: 0.8883 - accuracy: 0.8516 - val_loss: 0.1609 - val_accuracy: 0.9882\nEpoch 2/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.1047 - accuracy: 0.9879 - val_loss: 0.0743 - val_accuracy: 0.9881\nEpoch 3/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.0735 - accuracy: 0.9879 - val_loss: 0.0666 - val_accuracy: 0.9879\nEpoch 4/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.0677 - accuracy: 0.9877 - val_loss: 0.0617 - val_accuracy: 0.9878\nEpoch 5/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.0628 - accuracy: 0.9878 - val_loss: 0.0571 - val_accuracy: 0.9880\n350/350 [==============================] - 1s 3ms/step - loss: 0.1471 - accuracy: 0.9770\n--- Starting trial: run-1\n{'layer_1_units': 4, 'layer_1_dropout': 0.1, 'layer_2_units': 8, 'layer_2_dropout': 0.1, 'batch_size': 256, 'epochs': 5, 'optimizer': 'sgd'}\n4\nsgd\nEpoch 1/5\n106/106 [==============================] - 2s 14ms/step - loss: 0.8775 - accuracy: 0.9044 - val_loss: 0.4549 - val_accuracy: 0.9882\nEpoch 2/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.3255 - accuracy: 0.9879 - val_loss: 0.2241 - val_accuracy: 0.9882\nEpoch 3/5\n106/106 [==============================] - 1s 7ms/step - loss: 0.1919 - accuracy: 0.9879 - val_loss: 0.1531 - val_accuracy: 0.9882\nEpoch 4/5\n106/106 [==============================] - 1s 7ms/step - loss: 0.1435 - accuracy: 0.9879 - val_loss: 0.1227 - val_accuracy: 0.9882\nEpoch 5/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.1202 - accuracy: 0.9879 - val_loss: 0.1069 - val_accuracy: 0.9882\n350/350 [==============================] - 1s 3ms/step - loss: 0.1533 - accuracy: 0.9776\n--- Starting trial: run-2\n{'layer_1_units': 4, 'layer_1_dropout': 0.2, 'layer_2_units': 8, 'layer_2_dropout': 0.1, 'batch_size': 256, 'epochs': 5, 'optimizer': 'adam'}\n4\nadam\nEpoch 1/5\n106/106 [==============================] - 2s 15ms/step - loss: 1.0965 - accuracy: 0.7727 - val_loss: 0.2952 - val_accuracy: 0.9882\nEpoch 2/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.1464 - accuracy: 0.9879 - val_loss: 0.0724 - val_accuracy: 0.9881\nEpoch 3/5\n106/106 [==============================] - 1s 7ms/step - loss: 0.0711 - accuracy: 0.9880 - val_loss: 0.0609 - val_accuracy: 0.9877\nEpoch 4/5\n106/106 [==============================] - 1s 7ms/step - loss: 0.0631 - accuracy: 0.9879 - val_loss: 0.0563 - val_accuracy: 0.9880\nEpoch 5/5\n106/106 [==============================] - 1s 7ms/step - loss: 0.0599 - accuracy: 0.9879 - val_loss: 0.0530 - val_accuracy: 0.9877\n350/350 [==============================] - 1s 3ms/step - loss: 0.1346 - accuracy: 0.9771\n--- Starting trial: run-3\n{'layer_1_units': 4, 'layer_1_dropout': 0.2, 'layer_2_units': 8, 'layer_2_dropout': 0.1, 'batch_size': 256, 'epochs': 5, 'optimizer': 'sgd'}\n4\nsgd\nEpoch 1/5\n106/106 [==============================] - 2s 15ms/step - loss: 0.9091 - accuracy: 0.9554 - val_loss: 0.4800 - val_accuracy: 0.9882\nEpoch 2/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.3450 - accuracy: 0.9879 - val_loss: 0.2296 - val_accuracy: 0.9882\nEpoch 3/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.1997 - accuracy: 0.9879 - val_loss: 0.1538 - val_accuracy: 0.9882\nEpoch 4/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.1475 - accuracy: 0.9879 - val_loss: 0.1222 - val_accuracy: 0.9882\nEpoch 5/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.1230 - accuracy: 0.9879 - val_loss: 0.1061 - val_accuracy: 0.9882\n350/350 [==============================] - 1s 3ms/step - loss: 0.1532 - accuracy: 0.9776\n--- Starting trial: run-4\n{'layer_1_units': 8, 'layer_1_dropout': 0.1, 'layer_2_units': 8, 'layer_2_dropout': 0.1, 'batch_size': 256, 'epochs': 5, 'optimizer': 'adam'}\n8\nadam\nEpoch 1/5\n106/106 [==============================] - 2s 16ms/step - loss: 0.6119 - accuracy: 0.9457 - val_loss: 0.0912 - val_accuracy: 0.9882\nEpoch 2/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.0806 - accuracy: 0.9879 - val_loss: 0.0656 - val_accuracy: 0.9881\nEpoch 3/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.0683 - accuracy: 0.9879 - val_loss: 0.0600 - val_accuracy: 0.9885\nEpoch 4/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.0627 - accuracy: 0.9880 - val_loss: 0.0546 - val_accuracy: 0.9887\nEpoch 5/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.0577 - accuracy: 0.9878 - val_loss: 0.0476 - val_accuracy: 0.9892\n350/350 [==============================] - 1s 3ms/step - loss: 0.1292 - accuracy: 0.9781\n--- Starting trial: run-5\n{'layer_1_units': 8, 'layer_1_dropout': 0.1, 'layer_2_units': 8, 'layer_2_dropout': 0.1, 'batch_size': 256, 'epochs': 5, 'optimizer': 'sgd'}\n8\nsgd\nEpoch 1/5\n106/106 [==============================] - 2s 15ms/step - loss: 0.8559 - accuracy: 0.9569 - val_loss: 0.4278 - val_accuracy: 0.9882\nEpoch 2/5\n106/106 [==============================] - 1s 7ms/step - loss: 0.3056 - accuracy: 0.9879 - val_loss: 0.2085 - val_accuracy: 0.9882\nEpoch 3/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.1801 - accuracy: 0.9879 - val_loss: 0.1434 - val_accuracy: 0.9882\nEpoch 4/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.1357 - accuracy: 0.9879 - val_loss: 0.1158 - val_accuracy: 0.9882\nEpoch 5/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.1146 - accuracy: 0.9879 - val_loss: 0.1017 - val_accuracy: 0.9882\n350/350 [==============================] - 1s 3ms/step - loss: 0.1493 - accuracy: 0.9776\n--- Starting trial: run-6\n{'layer_1_units': 8, 'layer_1_dropout': 0.2, 'layer_2_units': 8, 'layer_2_dropout': 0.1, 'batch_size': 256, 'epochs': 5, 'optimizer': 'adam'}\n8\nadam\nEpoch 1/5\n106/106 [==============================] - 2s 15ms/step - loss: 0.6543 - accuracy: 0.8645 - val_loss: 0.0950 - val_accuracy: 0.9882\nEpoch 2/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.0824 - accuracy: 0.9879 - val_loss: 0.0662 - val_accuracy: 0.9876\nEpoch 3/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.0672 - accuracy: 0.9879 - val_loss: 0.0597 - val_accuracy: 0.9879\nEpoch 4/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.0626 - accuracy: 0.9880 - val_loss: 0.0548 - val_accuracy: 0.9882\nEpoch 5/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.0587 - accuracy: 0.9879 - val_loss: 0.0511 - val_accuracy: 0.9885\n350/350 [==============================] - 1s 3ms/step - loss: 0.1458 - accuracy: 0.9771\n--- Starting trial: run-7\n{'layer_1_units': 8, 'layer_1_dropout': 0.2, 'layer_2_units': 8, 'layer_2_dropout': 0.1, 'batch_size': 256, 'epochs': 5, 'optimizer': 'sgd'}\n8\nsgd\nEpoch 1/5\n106/106 [==============================] - 2s 14ms/step - loss: 1.0729 - accuracy: 0.8453 - val_loss: 0.5807 - val_accuracy: 0.9882\nEpoch 2/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.4016 - accuracy: 0.9879 - val_loss: 0.2583 - val_accuracy: 0.9882\nEpoch 3/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.2167 - accuracy: 0.9879 - val_loss: 0.1644 - val_accuracy: 0.9882\nEpoch 4/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.1539 - accuracy: 0.9879 - val_loss: 0.1272 - val_accuracy: 0.9882\nEpoch 5/5\n106/106 [==============================] - 1s 8ms/step - loss: 0.1258 - accuracy: 0.9879 - val_loss: 0.1090 - val_accuracy: 0.9882\n350/350 [==============================] - 1s 3ms/step - loss: 0.1549 - accuracy: 0.9776\n"
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for layer_1_units in HP_LAYER_1_UNITS.domain.values:\n",
    "    for layer_1_dropout in (HP_LAYER_1_DROPOUT.domain.min_value, HP_LAYER_1_DROPOUT.domain.max_value):\n",
    "        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "            hparams = {\n",
    "                HP_LAYER_1_UNITS: layer_1_units,\n",
    "                HP_LAYER_1_DROPOUT: layer_1_dropout,\n",
    "                HP_LAYER_2_UNITS: 8,\n",
    "                HP_LAYER_2_DROPOUT: 0.1,\n",
    "                HP_BATCH_SIZE: 256,\n",
    "                HP_EPOCHS: 5,\n",
    "                HP_OPTIMIZER: optimizer,\n",
    "            }\n",
    "            run_name = \"run-{}\".format(session_num)\n",
    "            print('--- Starting trial: {}'.format(run_name))\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "\n",
    "\n",
    "            run('logs/hparam_tuning/' + run_name, hparams)\n",
    "            session_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_true = []\n",
    "for i in range(y_test.shape[0]):\n",
    "    y_true.extend(np.argmax(y_test[i], axis=1).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred = []\n",
    "for i in range(x_test.shape[0]):\n",
    "    y_pred.extend(np.argmax(model.predict(x_test[i].reshape(1, 16, 5))[0], axis=1).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.predict(x_test[0].reshape(1, 16, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.argmax(model.predict(x_test[0].reshape(1, 16, 5))[0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "with open(\"version/{}/accuracy.txt\".format(timestamp), \"w\") as t:\n",
    "    t.write(str(accuracy.tolist()))\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = pd.DataFrame(classification_report(y_true, y_pred, output_dict=True)).transpose()\n",
    "report.to_csv(\"version/{}/report.csv\".format(timestamp))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
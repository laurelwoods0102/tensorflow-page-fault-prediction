{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599629147172",
   "display_name": "Python 3.7.6 64-bit ('ProgramData': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import kerastuner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"SEG_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0., 0., 0., ..., 1., 3., 1.], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "dataset = np.genfromtxt(\"data/{}_train_set.csv\".format(dataset_name), delimiter=\"\\n\", dtype=np.float32) #np.int64\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "14882"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "word_index = np.genfromtxt(\"data/word_index.csv\", delimiter=\"\\n\", dtype=np.int64)\n",
    "vocab_size = len(word_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = dict()\n",
    "\n",
    "param_list[\"PAST_HISTORY\"] = 16\n",
    "param_list[\"FUTURE_TARGET\"] = 8\n",
    "param_list[\"BATCH_SIZE\"] = 128\n",
    "param_list[\"EPOCHS\"] = 100\n",
    "param_list[\"BUFFER_SIZE\"] = 200000\n",
    "param_list[\"VOCAB_SIZE\"] = vocab_size\n",
    "param_list[\"LEARNING_RATE\"] = 0.01\n",
    "param_list[\"NUM_1_NEURONS\"] = 177\n",
    "param_list[\"NUM_2_NEURONS\"] = 177\n",
    "param_list[\"DROPOUT_1\"] = 0.1\n",
    "param_list[\"DROPOUT_2\"] = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timeseries(dataset, start_index, end_index, history_size, target_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i)\n",
    "        # Reshape data from (history_size,) to (history_size, n_feature)\n",
    "        data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
    "        #data.append(dataset[indices])\n",
    "        labels.append(np.reshape(dataset[i:i+target_size], (target_size, 1)))\n",
    "        #labels.append(dataset[i:i+target_size])\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((14858, 16, 1), (14858, 8, 1))"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "x_train, y_train = generate_timeseries(dataset, 0, None, param_list[\"PAST_HISTORY\"], param_list[\"FUTURE_TARGET\"])\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TimeDistributed, Dense, Conv1D, MaxPooling1D, Bidirectional, LSTM, Flatten, Reshape, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=9, padding=\"causal\", activation='relu'))\n",
    "#model.add(Conv1D(filters=32, kernel_size=3, padding=\"causal\", activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Flatten())\n",
    "#model.add(Lambda(lambda x:tf.expand_dims(x,axis=-1),input_shape=[None]))\n",
    "\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "#model.add(LSTM(32, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(param_list[\"VOCAB_SIZE\"], activation=\"softmax\")))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Nadam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1, 8, 14882)"
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "result = model.predict(x_train[10000].reshape(1, -1, 1))\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0s - loss: 0.5676 - accuracy: 0.8683/93 [=========================>....] - ETA: 0s - loss: 0.5674 - accuracy: 0.8685/93 [==========================>...] - ETA: 0s - loss: 0.5662 - accuracy: 0.8687/93 [===========================>..] - ETA: 0s - loss: 0.5671 - accuracy: 0.8689/93 [===========================>..] - ETA: 0s - loss: 0.5683 - accuracy: 0.8691/93 [============================>.] - ETA: 0s - loss: 0.5669 - accuracy: 0.8693/93 [==============================] - 3s 32ms/step - loss: 0.5675 - accuracy: 0.8668 - val_loss: 0.7037 - val_accuracy: 0.7345\nEpoch 96/100\n 1/93 [..............................] - ETA: 0s - loss: 0.3945 - accuracy: 0.88 3/93 [..............................] - ETA: 1s - loss: 0.6135 - accuracy: 0.83 5/93 [>.............................] - ETA: 1s - loss: 0.6298 - accuracy: 0.84 7/93 [=>............................] - ETA: 1s - loss: 0.6117 - accuracy: 0.85 9/93 [=>............................] - ETA: 1s - loss: 0.5993 - accuracy: 0.8511/93 [==>...........................] - ETA: 1s - loss: 0.5853 - accuracy: 0.8513/93 [===>..........................] - ETA: 1s - loss: 0.5772 - accuracy: 0.8515/93 [===>..........................] - ETA: 1s - loss: 0.5872 - accuracy: 0.8517/93 [====>.........................] - ETA: 1s - loss: 0.5795 - accuracy: 0.8519/93 [=====>........................] - ETA: 1s - loss: 0.5886 - accuracy: 0.8521/93 [=====>........................] - ETA: 1s - loss: 0.5949 - accuracy: 0.8523/93 [======>.......................] - ETA: 1s - loss: 0.6018 - accuracy: 0.8525/93 [=======>......................] - ETA: 1s - loss: 0.6056 - accuracy: 0.8527/93 [=======>......................] - ETA: 1s - loss: 0.5979 - accuracy: 0.8529/93 [========>.....................] - ETA: 1s - loss: 0.5959 - accuracy: 0.8531/93 [=========>....................] - ETA: 1s - loss: 0.5871 - accuracy: 0.8633/93 [=========>....................] - ETA: 1s - loss: 0.5889 - accuracy: 0.8635/93 [==========>...................] - ETA: 1s - loss: 0.5917 - accuracy: 0.8637/93 [==========>...................] - ETA: 1s - loss: 0.5877 - accuracy: 0.8639/93 [===========>..................] - ETA: 1s - loss: 0.5815 - accuracy: 0.8641/93 [============>.................] - ETA: 1s - loss: 0.5820 - accuracy: 0.8643/93 [============>.................] - ETA: 1s - loss: 0.5831 - accuracy: 0.8645/93 [=============>................] - ETA: 1s - loss: 0.5782 - accuracy: 0.8647/93 [==============>...............] - ETA: 1s - loss: 0.5782 - accuracy: 0.8649/93 [==============>...............] - ETA: 1s - loss: 0.5720 - accuracy: 0.8651/93 [===============>..............] - ETA: 1s - loss: 0.5711 - accuracy: 0.8653/93 [================>.............] - ETA: 1s - loss: 0.5699 - accuracy: 0.8655/93 [================>.............] - ETA: 0s - loss: 0.5675 - accuracy: 0.8657/93 [=================>............] - ETA: 0s - loss: 0.5694 - accuracy: 0.8659/93 [==================>...........] - ETA: 0s - loss: 0.5654 - accuracy: 0.8661/93 [==================>...........] - ETA: 0s - loss: 0.5633 - accuracy: 0.8663/93 [===================>..........] - ETA: 0s - loss: 0.5587 - accuracy: 0.8665/93 [===================>..........] - ETA: 0s - loss: 0.5545 - accuracy: 0.8667/93 [====================>.........] - ETA: 0s - loss: 0.5581 - accuracy: 0.8669/93 [=====================>........] - ETA: 0s - loss: 0.5625 - accuracy: 0.8671/93 [=====================>........] - ETA: 0s - loss: 0.5597 - accuracy: 0.8673/93 [======================>.......] - ETA: 0s - loss: 0.5633 - accuracy: 0.8675/93 [=======================>......] - ETA: 0s - loss: 0.5633 - accuracy: 0.8677/93 [=======================>......] - ETA: 0s - loss: 0.5663 - accuracy: 0.8679/93 [========================>.....] - ETA: 0s - loss: 0.5658 - accuracy: 0.8681/93 [=========================>....] - ETA: 0s - loss: 0.5646 - accuracy: 0.8683/93 [=========================>....] - ETA: 0s - loss: 0.5630 - accuracy: 0.8685/93 [==========================>...] - ETA: 0s - loss: 0.5622 - accuracy: 0.8687/93 [===========================>..] - ETA: 0s - loss: 0.5628 - accuracy: 0.8689/93 [===========================>..] - ETA: 0s - loss: 0.5634 - accuracy: 0.8691/93 [============================>.] - ETA: 0s - loss: 0.5645 - accuracy: 0.8693/93 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.8693/93 [==============================] - 3s 32ms/step - loss: 0.5662 - accuracy: 0.8668 - val_loss: 0.6830 - val_accuracy: 0.7381\nEpoch 97/100\n 1/93 [..............................] - ETA: 0s - loss: 0.4632 - accuracy: 0.86 3/93 [..............................] - ETA: 1s - loss: 0.4441 - accuracy: 0.87 5/93 [>.............................] - ETA: 1s - loss: 0.4953 - accuracy: 0.86 7/93 [=>............................] - ETA: 2s - loss: 0.5183 - accuracy: 0.87 9/93 [=>............................] - ETA: 2s - loss: 0.5200 - accuracy: 0.8711/93 [==>...........................] - ETA: 2s - loss: 0.5084 - accuracy: 0.8713/93 [===>..........................] - ETA: 2s - loss: 0.5272 - accuracy: 0.8715/93 [===>..........................] - ETA: 2s - loss: 0.5293 - accuracy: 0.8717/93 [====>.........................] - ETA: 1s - loss: 0.5346 - accuracy: 0.8719/93 [=====>........................] - ETA: 1s - loss: 0.5347 - accuracy: 0.8721/93 [=====>........................] - ETA: 1s - loss: 0.5372 - accuracy: 0.8723/93 [======>.......................] - ETA: 1s - loss: 0.5315 - accuracy: 0.8725/93 [=======>......................] - ETA: 1s - loss: 0.5289 - accuracy: 0.8727/93 [=======>......................] - ETA: 1s - loss: 0.5366 - accuracy: 0.8729/93 [========>.....................] - ETA: 1s - loss: 0.5397 - accuracy: 0.8631/93 [=========>....................] - ETA: 1s - loss: 0.5478 - accuracy: 0.8633/93 [=========>....................] - ETA: 1s - loss: 0.5513 - accuracy: 0.8635/93 [==========>...................] - ETA: 1s - loss: 0.5587 - accuracy: 0.8637/93 [==========>...................] - ETA: 1s - loss: 0.5556 - accuracy: 0.8639/93 [===========>..................] - ETA: 1s - loss: 0.5577 - accuracy: 0.8641/93 [============>.................] - ETA: 1s - loss: 0.5589 - accuracy: 0.8643/93 [============>.................] - ETA: 1s - loss: 0.5593 - accuracy: 0.8645/93 [=============>................] - ETA: 1s - loss: 0.5573 - accuracy: 0.8647/93 [==============>...............] - ETA: 1s - loss: 0.5603 - accuracy: 0.8649/93 [==============>...............] - ETA: 1s - loss: 0.5587 - accuracy: 0.8651/93 [===============>..............] - ETA: 1s - loss: 0.5654 - accuracy: 0.8653/93 [================>.............] - ETA: 1s - loss: 0.5710 - accuracy: 0.8655/93 [================>.............] - ETA: 1s - loss: 0.5686 - accuracy: 0.8657/93 [=================>............] - ETA: 1s - loss: 0.5675 - accuracy: 0.8659/93 [==================>...........] - ETA: 0s - loss: 0.5667 - accuracy: 0.8661/93 [==================>...........] - ETA: 0s - loss: 0.5670 - accuracy: 0.8663/93 [===================>..........] - ETA: 0s - loss: 0.5671 - accuracy: 0.8665/93 [===================>..........] - ETA: 0s - loss: 0.5659 - accuracy: 0.8667/93 [====================>.........] - ETA: 0s - loss: 0.5670 - accuracy: 0.8669/93 [=====================>........] - ETA: 0s - loss: 0.5678 - accuracy: 0.8671/93 [=====================>........] - ETA: 0s - loss: 0.5655 - accuracy: 0.8673/93 [======================>.......] - ETA: 0s - loss: 0.5650 - accuracy: 0.8675/93 [=======================>......] - ETA: 0s - loss: 0.5672 - accuracy: 0.8677/93 [=======================>......] - ETA: 0s - loss: 0.5623 - accuracy: 0.8679/93 [========================>.....] - ETA: 0s - loss: 0.5616 - accuracy: 0.8681/93 [=========================>....] - ETA: 0s - loss: 0.5609 - accuracy: 0.8683/93 [=========================>....] - ETA: 0s - loss: 0.5616 - accuracy: 0.8685/93 [==========================>...] - ETA: 0s - loss: 0.5629 - accuracy: 0.8687/93 [===========================>..] - ETA: 0s - loss: 0.5658 - accuracy: 0.8689/93 [===========================>..] - ETA: 0s - loss: 0.5660 - accuracy: 0.8691/93 [============================>.] - ETA: 0s - loss: 0.5657 - accuracy: 0.8693/93 [==============================] - 3s 32ms/step - loss: 0.5648 - accuracy: 0.8673 - val_loss: 0.6873 - val_accuracy: 0.7367\nEpoch 98/100\n 1/93 [..............................] - ETA: 0s - loss: 0.5651 - accuracy: 0.84 3/93 [..............................] - ETA: 1s - loss: 0.5499 - accuracy: 0.86 5/93 [>.............................] - ETA: 1s - loss: 0.5452 - accuracy: 0.87 7/93 [=>............................] - ETA: 1s - loss: 0.5104 - accuracy: 0.87 9/93 [=>............................] - ETA: 1s - loss: 0.5368 - accuracy: 0.8711/93 [==>...........................] - ETA: 1s - loss: 0.5174 - accuracy: 0.8713/93 [===>..........................] - ETA: 1s - loss: 0.5219 - accuracy: 0.8715/93 [===>..........................] - ETA: 1s - loss: 0.5235 - accuracy: 0.8717/93 [====>.........................] - ETA: 1s - loss: 0.5484 - accuracy: 0.8619/93 [=====>........................] - ETA: 1s - loss: 0.5570 - accuracy: 0.8621/93 [=====>........................] - ETA: 1s - loss: 0.5615 - accuracy: 0.8623/93 [======>.......................] - ETA: 1s - loss: 0.5733 - accuracy: 0.8625/93 [=======>......................] - ETA: 1s - loss: 0.5747 - accuracy: 0.8627/93 [=======>......................] - ETA: 1s - loss: 0.5691 - accuracy: 0.8629/93 [========>.....................] - ETA: 1s - loss: 0.5744 - accuracy: 0.8631/93 [=========>....................] - ETA: 1s - loss: 0.5761 - accuracy: 0.8633/93 [=========>....................] - ETA: 1s - loss: 0.5717 - accuracy: 0.8635/93 [==========>...................] - ETA: 1s - loss: 0.5648 - accuracy: 0.8637/93 [==========>...................] - ETA: 1s - loss: 0.5579 - accuracy: 0.8639/93 [===========>..................] - ETA: 1s - loss: 0.5508 - accuracy: 0.8641/93 [============>.................] - ETA: 1s - loss: 0.5505 - accuracy: 0.8643/93 [============>.................] - ETA: 1s - loss: 0.5509 - accuracy: 0.8645/93 [=============>................] - ETA: 1s - loss: 0.5557 - accuracy: 0.8647/93 [==============>...............] - ETA: 1s - loss: 0.5605 - accuracy: 0.8649/93 [==============>...............] - ETA: 1s - loss: 0.5597 - accuracy: 0.8651/93 [===============>..............] - ETA: 1s - loss: 0.5574 - accuracy: 0.8653/93 [================>.............] - ETA: 1s - loss: 0.5589 - accuracy: 0.8655/93 [================>.............] - ETA: 0s - loss: 0.5574 - accuracy: 0.8657/93 [=================>............] - ETA: 0s - loss: 0.5580 - accuracy: 0.8659/93 [==================>...........] - ETA: 0s - loss: 0.5577 - accuracy: 0.8661/93 [==================>...........] - ETA: 0s - loss: 0.5550 - accuracy: 0.8663/93 [===================>..........] - ETA: 0s - loss: 0.5603 - accuracy: 0.8665/93 [===================>..........] - ETA: 0s - loss: 0.5611 - accuracy: 0.8667/93 [====================>.........] - ETA: 0s - loss: 0.5583 - accuracy: 0.8669/93 [=====================>........] - ETA: 0s - loss: 0.5591 - accuracy: 0.8671/93 [=====================>........] - ETA: 0s - loss: 0.5609 - accuracy: 0.8673/93 [======================>.......] - ETA: 0s - loss: 0.5649 - accuracy: 0.8675/93 [=======================>......] - ETA: 0s - loss: 0.5625 - accuracy: 0.8677/93 [=======================>......] - ETA: 0s - loss: 0.5617 - accuracy: 0.8679/93 [========================>.....] - ETA: 0s - loss: 0.5649 - accuracy: 0.8681/93 [=========================>....] - ETA: 0s - loss: 0.5671 - accuracy: 0.8683/93 [=========================>....] - ETA: 0s - loss: 0.5678 - accuracy: 0.8685/93 [==========================>...] - ETA: 0s - loss: 0.5679 - accuracy: 0.8687/93 [===========================>..] - ETA: 0s - loss: 0.5662 - accuracy: 0.8689/93 [===========================>..] - ETA: 0s - loss: 0.5645 - accuracy: 0.8691/93 [============================>.] - ETA: 0s - loss: 0.5655 - accuracy: 0.8693/93 [==============================] - ETA: 0s - loss: 0.5633 - accuracy: 0.8693/93 [==============================] - 3s 31ms/step - loss: 0.5633 - accuracy: 0.8677 - val_loss: 0.6810 - val_accuracy: 0.7396\nEpoch 99/100\n 1/93 [..............................] - ETA: 0s - loss: 0.8649 - accuracy: 0.83 3/93 [..............................] - ETA: 1s - loss: 0.6791 - accuracy: 0.84 5/93 [>.............................] - ETA: 1s - loss: 0.6827 - accuracy: 0.84 7/93 [=>............................] - ETA: 1s - loss: 0.6239 - accuracy: 0.85 9/93 [=>............................] - ETA: 2s - loss: 0.6107 - accuracy: 0.8511/93 [==>...........................] - ETA: 1s - loss: 0.5864 - accuracy: 0.8613/93 [===>..........................] - ETA: 1s - loss: 0.5829 - accuracy: 0.8615/93 [===>..........................] - ETA: 1s - loss: 0.5813 - accuracy: 0.8617/93 [====>.........................] - ETA: 1s - loss: 0.5775 - accuracy: 0.8619/93 [=====>........................] - ETA: 1s - loss: 0.5643 - accuracy: 0.8621/93 [=====>........................] - ETA: 1s - loss: 0.5754 - accuracy: 0.8623/93 [======>.......................] - ETA: 1s - loss: 0.5703 - accuracy: 0.8625/93 [=======>......................] - ETA: 1s - loss: 0.5705 - accuracy: 0.8627/93 [=======>......................] - ETA: 1s - loss: 0.5653 - accuracy: 0.8629/93 [========>.....................] - ETA: 1s - loss: 0.5741 - accuracy: 0.8631/93 [=========>....................] - ETA: 1s - loss: 0.5674 - accuracy: 0.8633/93 [=========>....................] - ETA: 1s - loss: 0.5687 - accuracy: 0.8635/93 [==========>...................] - ETA: 1s - loss: 0.5632 - accuracy: 0.8637/93 [==========>...................] - ETA: 1s - loss: 0.5589 - accuracy: 0.8639/93 [===========>..................] - ETA: 1s - loss: 0.5597 - accuracy: 0.8641/93 [============>.................] - ETA: 1s - loss: 0.5589 - accuracy: 0.8643/93 [============>.................] - ETA: 1s - loss: 0.5554 - accuracy: 0.8645/93 [=============>................] - ETA: 1s - loss: 0.5559 - accuracy: 0.8647/93 [==============>...............] - ETA: 1s - loss: 0.5543 - accuracy: 0.8649/93 [==============>...............] - ETA: 1s - loss: 0.5558 - accuracy: 0.8651/93 [===============>..............] - ETA: 1s - loss: 0.5554 - accuracy: 0.8653/93 [================>.............] - ETA: 1s - loss: 0.5552 - accuracy: 0.8655/93 [================>.............] - ETA: 1s - loss: 0.5570 - accuracy: 0.8657/93 [=================>............] - ETA: 0s - loss: 0.5580 - accuracy: 0.8659/93 [==================>...........] - ETA: 0s - loss: 0.5573 - accuracy: 0.8661/93 [==================>...........] - ETA: 0s - loss: 0.5570 - accuracy: 0.8663/93 [===================>..........] - ETA: 0s - loss: 0.5584 - accuracy: 0.8665/93 [===================>..........] - ETA: 0s - loss: 0.5603 - accuracy: 0.8667/93 [====================>.........] - ETA: 0s - loss: 0.5589 - accuracy: 0.8669/93 [=====================>........] - ETA: 0s - loss: 0.5619 - accuracy: 0.8671/93 [=====================>........] - ETA: 0s - loss: 0.5586 - accuracy: 0.8673/93 [======================>.......] - ETA: 0s - loss: 0.5597 - accuracy: 0.8675/93 [=======================>......] - ETA: 0s - loss: 0.5593 - accuracy: 0.8677/93 [=======================>......] - ETA: 0s - loss: 0.5601 - accuracy: 0.8679/93 [========================>.....] - ETA: 0s - loss: 0.5588 - accuracy: 0.8681/93 [=========================>....] - ETA: 0s - loss: 0.5572 - accuracy: 0.8683/93 [=========================>....] - ETA: 0s - loss: 0.5593 - accuracy: 0.8685/93 [==========================>...] - ETA: 0s - loss: 0.5587 - accuracy: 0.8687/93 [===========================>..] - ETA: 0s - loss: 0.5605 - accuracy: 0.8689/93 [===========================>..] - ETA: 0s - loss: 0.5598 - accuracy: 0.8691/93 [============================>.] - ETA: 0s - loss: 0.5590 - accuracy: 0.8693/93 [==============================] - ETA: 0s - loss: 0.5618 - accuracy: 0.8693/93 [==============================] - 3s 31ms/step - loss: 0.5618 - accuracy: 0.8674 - val_loss: 0.6793 - val_accuracy: 0.7396\nEpoch 100/100\n 1/93 [..............................] - ETA: 0s - loss: 0.6150 - accuracy: 0.85 3/93 [..............................] - ETA: 1s - loss: 0.6054 - accuracy: 0.86 5/93 [>.............................] - ETA: 1s - loss: 0.6054 - accuracy: 0.85 7/93 [=>............................] - ETA: 2s - loss: 0.5667 - accuracy: 0.86 9/93 [=>............................] - ETA: 2s - loss: 0.5419 - accuracy: 0.8611/93 [==>...........................] - ETA: 2s - loss: 0.5334 - accuracy: 0.8713/93 [===>..........................] - ETA: 2s - loss: 0.5176 - accuracy: 0.8715/93 [===>..........................] - ETA: 1s - loss: 0.5190 - accuracy: 0.8717/93 [====>.........................] - ETA: 1s - loss: 0.5144 - accuracy: 0.8719/93 [=====>........................] - ETA: 1s - loss: 0.5194 - accuracy: 0.8721/93 [=====>........................] - ETA: 1s - loss: 0.5353 - accuracy: 0.8723/93 [======>.......................] - ETA: 1s - loss: 0.5354 - accuracy: 0.8725/93 [=======>......................] - ETA: 1s - loss: 0.5377 - accuracy: 0.8727/93 [=======>......................] - ETA: 1s - loss: 0.5346 - accuracy: 0.8729/93 [========>.....................] - ETA: 1s - loss: 0.5337 - accuracy: 0.8731/93 [=========>....................] - ETA: 1s - loss: 0.5400 - accuracy: 0.8733/93 [=========>....................] - ETA: 1s - loss: 0.5455 - accuracy: 0.8735/93 [==========>...................] - ETA: 1s - loss: 0.5432 - accuracy: 0.8737/93 [==========>...................] - ETA: 1s - loss: 0.5366 - accuracy: 0.8739/93 [===========>..................] - ETA: 1s - loss: 0.5344 - accuracy: 0.8741/93 [============>.................] - ETA: 1s - loss: 0.5353 - accuracy: 0.8743/93 [============>.................] - ETA: 1s - loss: 0.5369 - accuracy: 0.8745/93 [=============>................] - ETA: 1s - loss: 0.5345 - accuracy: 0.8747/93 [==============>...............] - ETA: 1s - loss: 0.5350 - accuracy: 0.8749/93 [==============>...............] - ETA: 1s - loss: 0.5350 - accuracy: 0.8751/93 [===============>..............] - ETA: 1s - loss: 0.5373 - accuracy: 0.8753/93 [================>.............] - ETA: 1s - loss: 0.5427 - accuracy: 0.8755/93 [================>.............] - ETA: 0s - loss: 0.5407 - accuracy: 0.8757/93 [=================>............] - ETA: 0s - loss: 0.5406 - accuracy: 0.8759/93 [==================>...........] - ETA: 0s - loss: 0.5410 - accuracy: 0.8761/93 [==================>...........] - ETA: 0s - loss: 0.5448 - accuracy: 0.8763/93 [===================>..........] - ETA: 0s - loss: 0.5453 - accuracy: 0.8765/93 [===================>..........] - ETA: 0s - loss: 0.5474 - accuracy: 0.8767/93 [====================>.........] - ETA: 0s - loss: 0.5497 - accuracy: 0.8769/93 [=====================>........] - ETA: 0s - loss: 0.5506 - accuracy: 0.8771/93 [=====================>........] - ETA: 0s - loss: 0.5510 - accuracy: 0.8773/93 [======================>.......] - ETA: 0s - loss: 0.5486 - accuracy: 0.8775/93 [=======================>......] - ETA: 0s - loss: 0.5520 - accuracy: 0.8677/93 [=======================>......] - ETA: 0s - loss: 0.5549 - accuracy: 0.8679/93 [========================>.....] - ETA: 0s - loss: 0.5566 - accuracy: 0.8681/93 [=========================>....] - ETA: 0s - loss: 0.5585 - accuracy: 0.8683/93 [=========================>....] - ETA: 0s - loss: 0.5590 - accuracy: 0.8685/93 [==========================>...] - ETA: 0s - loss: 0.5605 - accuracy: 0.8687/93 [===========================>..] - ETA: 0s - loss: 0.5601 - accuracy: 0.8689/93 [===========================>..] - ETA: 0s - loss: 0.5605 - accuracy: 0.8691/93 [============================>.] - ETA: 0s - loss: 0.5632 - accuracy: 0.8693/93 [==============================] - ETA: 0s - loss: 0.5616 - accuracy: 0.8693/93 [==============================] - 3s 32ms/step - loss: 0.5616 - accuracy: 0.8673 - val_loss: 0.6899 - val_accuracy: 0.7347\n"
    }
   ],
   "source": [
    "model_history = model.fit(x_train, y_train, batch_size=param_list[\"BATCH_SIZE\"], validation_split=0.2, epochs=param_list[\"EPOCHS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'20200909-155423'"
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "'''\n",
    "log_dir = \"logs/fit/\" + timestamp\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "'''\n",
    "version_dir = \"version/\" + timestamp \n",
    "\n",
    "os.makedirs(version_dir)\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"version/{}/model.h5\".format(timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
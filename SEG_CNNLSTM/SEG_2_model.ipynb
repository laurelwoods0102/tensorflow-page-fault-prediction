{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599555457426",
   "display_name": "Python 3.7.6 64-bit ('ProgramData': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import kerastuner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"SEG_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0., 0., 0., ..., 1., 3., 1.], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "dataset = np.genfromtxt(\"data/{}_train_set.csv\".format(dataset_name), delimiter=\"\\n\", dtype=np.float32) #np.int64\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "14882"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "word_index = np.genfromtxt(\"data/word_index.csv\", delimiter=\"\\n\", dtype=np.int64)\n",
    "vocab_size = len(word_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = dict()\n",
    "\n",
    "param_list[\"PAST_HISTORY\"] = 64\n",
    "param_list[\"FUTURE_TARGET\"] = 8\n",
    "param_list[\"BATCH_SIZE\"] = 128\n",
    "param_list[\"EPOCHS\"] = 100\n",
    "param_list[\"BUFFER_SIZE\"] = 200000\n",
    "param_list[\"VOCAB_SIZE\"] = vocab_size\n",
    "param_list[\"LEARNING_RATE\"] = 0.01\n",
    "param_list[\"NUM_1_NEURONS\"] = 177\n",
    "param_list[\"NUM_2_NEURONS\"] = 177\n",
    "param_list[\"DROPOUT_1\"] = 0.1\n",
    "param_list[\"DROPOUT_2\"] = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timeseries(dataset, start_index, end_index, history_size, target_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i)\n",
    "        # Reshape data from (history_size,) to (history_size, n_feature)\n",
    "        data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
    "        #data.append(dataset[indices])\n",
    "        labels.append(np.reshape(dataset[i:i+target_size], (target_size, 1)))\n",
    "        #labels.append(dataset[i:i+target_size])\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((14810, 64, 1), (14810, 8, 1))"
     },
     "metadata": {},
     "execution_count": 264
    }
   ],
   "source": [
    "x_train, y_train = generate_timeseries(dataset, 0, None, param_list[\"PAST_HISTORY\"], param_list[\"FUTURE_TARGET\"])\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TimeDistributed, Dense, Conv1D, MaxPooling1D, Bidirectional, LSTM, Flatten, Reshape, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = keras.models.Sequential()\n",
    "model_1.add(Conv1D(filters=32, kernel_size=3, padding=\"causal\", activation='relu'))\n",
    "model_1.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Flatten())\n",
    "#model.add(Lambda(lambda x:tf.expand_dims(x,axis=-1),input_shape=[None]))\n",
    "model_1.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(param_list[\"NUM_1_NEURONS\"])))\n",
    "model_1.add(keras.layers.Dropout(param_list[\"DROPOUT_2\"]))\n",
    "model_1.add(keras.layers.RepeatVector(param_list[\"FUTURE_TARGET\"]))\n",
    "model_1.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(param_list[\"NUM_2_NEURONS\"], return_sequences=True)))\n",
    "model_1.add(keras.layers.Dropout(param_list[\"DROPOUT_2\"]))\n",
    "model_1.add(keras.layers.TimeDistributed(keras.layers.Dense(param_list[\"VOCAB_SIZE\"], activation='softmax')))\n",
    "\n",
    "model_1.compile(optimizer=keras.optimizers.Adam(param_list[\"LEARNING_RATE\"]), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1, 8, 14882)"
     },
     "metadata": {},
     "execution_count": 293
    }
   ],
   "source": [
    "result_1 = model_1.predict(x_train[10000].reshape(1, -1, 1))\n",
    "result_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0s - loss: 0.3552 - accuracy: 0.8987/93 [===========================>..] - ETA: 0s - loss: 0.3556 - accuracy: 0.8989/93 [===========================>..] - ETA: 0s - loss: 0.3569 - accuracy: 0.8991/93 [============================>.] - ETA: 0s - loss: 0.3563 - accuracy: 0.8993/93 [==============================] - ETA: 0s - loss: 0.3562 - accuracy: 0.8993/93 [==============================] - 4s 38ms/step - loss: 0.3562 - accuracy: 0.8961 - val_loss: 0.5398 - val_accuracy: 0.8121\nEpoch 96/100\n 1/93 [..............................] - ETA: 0s - loss: 0.3599 - accuracy: 0.88 3/93 [..............................] - ETA: 2s - loss: 0.3478 - accuracy: 0.89 5/93 [>.............................] - ETA: 2s - loss: 0.3753 - accuracy: 0.88 7/93 [=>............................] - ETA: 2s - loss: 0.3714 - accuracy: 0.89 9/93 [=>............................] - ETA: 2s - loss: 0.3728 - accuracy: 0.8811/93 [==>...........................] - ETA: 2s - loss: 0.3693 - accuracy: 0.8813/93 [===>..........................] - ETA: 2s - loss: 0.3614 - accuracy: 0.8915/93 [===>..........................] - ETA: 2s - loss: 0.3524 - accuracy: 0.8917/93 [====>.........................] - ETA: 2s - loss: 0.3508 - accuracy: 0.8919/93 [=====>........................] - ETA: 2s - loss: 0.3555 - accuracy: 0.8921/93 [=====>........................] - ETA: 2s - loss: 0.3539 - accuracy: 0.8923/93 [======>.......................] - ETA: 2s - loss: 0.3537 - accuracy: 0.8925/93 [=======>......................] - ETA: 2s - loss: 0.3585 - accuracy: 0.8927/93 [=======>......................] - ETA: 2s - loss: 0.3568 - accuracy: 0.8929/93 [========>.....................] - ETA: 2s - loss: 0.3570 - accuracy: 0.8931/93 [=========>....................] - ETA: 2s - loss: 0.3566 - accuracy: 0.8933/93 [=========>....................] - ETA: 1s - loss: 0.3603 - accuracy: 0.8935/93 [==========>...................] - ETA: 1s - loss: 0.3604 - accuracy: 0.8937/93 [==========>...................] - ETA: 1s - loss: 0.3590 - accuracy: 0.8939/93 [===========>..................] - ETA: 1s - loss: 0.3553 - accuracy: 0.8941/93 [============>.................] - ETA: 1s - loss: 0.3548 - accuracy: 0.8943/93 [============>.................] - ETA: 1s - loss: 0.3541 - accuracy: 0.8945/93 [=============>................] - ETA: 1s - loss: 0.3532 - accuracy: 0.8947/93 [==============>...............] - ETA: 1s - loss: 0.3554 - accuracy: 0.8949/93 [==============>...............] - ETA: 1s - loss: 0.3531 - accuracy: 0.8951/93 [===============>..............] - ETA: 1s - loss: 0.3529 - accuracy: 0.8953/93 [================>.............] - ETA: 1s - loss: 0.3558 - accuracy: 0.8955/93 [================>.............] - ETA: 1s - loss: 0.3550 - accuracy: 0.8957/93 [=================>............] - ETA: 1s - loss: 0.3543 - accuracy: 0.8959/93 [==================>...........] - ETA: 1s - loss: 0.3564 - accuracy: 0.8961/93 [==================>...........] - ETA: 1s - loss: 0.3571 - accuracy: 0.8963/93 [===================>..........] - ETA: 0s - loss: 0.3568 - accuracy: 0.8965/93 [===================>..........] - ETA: 0s - loss: 0.3579 - accuracy: 0.8967/93 [====================>.........] - ETA: 0s - loss: 0.3576 - accuracy: 0.8969/93 [=====================>........] - ETA: 0s - loss: 0.3595 - accuracy: 0.8971/93 [=====================>........] - ETA: 0s - loss: 0.3596 - accuracy: 0.8973/93 [======================>.......] - ETA: 0s - loss: 0.3566 - accuracy: 0.8975/93 [=======================>......] - ETA: 0s - loss: 0.3555 - accuracy: 0.8977/93 [=======================>......] - ETA: 0s - loss: 0.3560 - accuracy: 0.8979/93 [========================>.....] - ETA: 0s - loss: 0.3571 - accuracy: 0.8981/93 [=========================>....] - ETA: 0s - loss: 0.3550 - accuracy: 0.8983/93 [=========================>....] - ETA: 0s - loss: 0.3543 - accuracy: 0.8985/93 [==========================>...] - ETA: 0s - loss: 0.3534 - accuracy: 0.8987/93 [===========================>..] - ETA: 0s - loss: 0.3530 - accuracy: 0.8989/93 [===========================>..] - ETA: 0s - loss: 0.3548 - accuracy: 0.8991/93 [============================>.] - ETA: 0s - loss: 0.3562 - accuracy: 0.8993/93 [==============================] - ETA: 0s - loss: 0.3564 - accuracy: 0.8993/93 [==============================] - 4s 38ms/step - loss: 0.3564 - accuracy: 0.8954 - val_loss: 0.5759 - val_accuracy: 0.8041\nEpoch 97/100\n 1/93 [..............................] - ETA: 0s - loss: 0.4148 - accuracy: 0.84 3/93 [..............................] - ETA: 2s - loss: 0.3661 - accuracy: 0.88 5/93 [>.............................] - ETA: 2s - loss: 0.3362 - accuracy: 0.89 7/93 [=>............................] - ETA: 2s - loss: 0.3475 - accuracy: 0.89 9/93 [=>............................] - ETA: 2s - loss: 0.3435 - accuracy: 0.8911/93 [==>...........................] - ETA: 2s - loss: 0.3516 - accuracy: 0.8913/93 [===>..........................] - ETA: 2s - loss: 0.3479 - accuracy: 0.8915/93 [===>..........................] - ETA: 2s - loss: 0.3619 - accuracy: 0.8817/93 [====>.........................] - ETA: 2s - loss: 0.3611 - accuracy: 0.8919/93 [=====>........................] - ETA: 2s - loss: 0.3579 - accuracy: 0.8921/93 [=====>........................] - ETA: 2s - loss: 0.3489 - accuracy: 0.8923/93 [======>.......................] - ETA: 2s - loss: 0.3517 - accuracy: 0.8925/93 [=======>......................] - ETA: 2s - loss: 0.3473 - accuracy: 0.8927/93 [=======>......................] - ETA: 2s - loss: 0.3441 - accuracy: 0.8929/93 [========>.....................] - ETA: 2s - loss: 0.3435 - accuracy: 0.8931/93 [=========>....................] - ETA: 1s - loss: 0.3414 - accuracy: 0.8933/93 [=========>....................] - ETA: 1s - loss: 0.3418 - accuracy: 0.8935/93 [==========>...................] - ETA: 1s - loss: 0.3442 - accuracy: 0.8937/93 [==========>...................] - ETA: 1s - loss: 0.3470 - accuracy: 0.8939/93 [===========>..................] - ETA: 1s - loss: 0.3518 - accuracy: 0.8941/93 [============>.................] - ETA: 1s - loss: 0.3528 - accuracy: 0.8943/93 [============>.................] - ETA: 1s - loss: 0.3553 - accuracy: 0.8945/93 [=============>................] - ETA: 1s - loss: 0.3571 - accuracy: 0.8947/93 [==============>...............] - ETA: 1s - loss: 0.3606 - accuracy: 0.8949/93 [==============>...............] - ETA: 1s - loss: 0.3631 - accuracy: 0.8951/93 [===============>..............] - ETA: 1s - loss: 0.3627 - accuracy: 0.8953/93 [================>.............] - ETA: 1s - loss: 0.3618 - accuracy: 0.8955/93 [================>.............] - ETA: 1s - loss: 0.3579 - accuracy: 0.8957/93 [=================>............] - ETA: 1s - loss: 0.3559 - accuracy: 0.8959/93 [==================>...........] - ETA: 1s - loss: 0.3580 - accuracy: 0.8961/93 [==================>...........] - ETA: 1s - loss: 0.3615 - accuracy: 0.8963/93 [===================>..........] - ETA: 0s - loss: 0.3606 - accuracy: 0.8965/93 [===================>..........] - ETA: 0s - loss: 0.3579 - accuracy: 0.8967/93 [====================>.........] - ETA: 0s - loss: 0.3577 - accuracy: 0.8969/93 [=====================>........] - ETA: 0s - loss: 0.3558 - accuracy: 0.8971/93 [=====================>........] - ETA: 0s - loss: 0.3573 - accuracy: 0.8973/93 [======================>.......] - ETA: 0s - loss: 0.3573 - accuracy: 0.8975/93 [=======================>......] - ETA: 0s - loss: 0.3561 - accuracy: 0.8977/93 [=======================>......] - ETA: 0s - loss: 0.3565 - accuracy: 0.8979/93 [========================>.....] - ETA: 0s - loss: 0.3566 - accuracy: 0.8981/93 [=========================>....] - ETA: 0s - loss: 0.3556 - accuracy: 0.8983/93 [=========================>....] - ETA: 0s - loss: 0.3561 - accuracy: 0.8985/93 [==========================>...] - ETA: 0s - loss: 0.3566 - accuracy: 0.8987/93 [===========================>..] - ETA: 0s - loss: 0.3569 - accuracy: 0.8989/93 [===========================>..] - ETA: 0s - loss: 0.3556 - accuracy: 0.8991/93 [============================>.] - ETA: 0s - loss: 0.3560 - accuracy: 0.8993/93 [==============================] - ETA: 0s - loss: 0.3538 - accuracy: 0.8993/93 [==============================] - 4s 38ms/step - loss: 0.3538 - accuracy: 0.8959 - val_loss: 0.5579 - val_accuracy: 0.8095\nEpoch 98/100\n 1/93 [..............................] - ETA: 0s - loss: 0.2598 - accuracy: 0.93 3/93 [..............................] - ETA: 1s - loss: 0.3881 - accuracy: 0.87 5/93 [>.............................] - ETA: 2s - loss: 0.3689 - accuracy: 0.88 7/93 [=>............................] - ETA: 2s - loss: 0.3761 - accuracy: 0.88 9/93 [=>............................] - ETA: 2s - loss: 0.3581 - accuracy: 0.8811/93 [==>...........................] - ETA: 2s - loss: 0.3462 - accuracy: 0.8913/93 [===>..........................] - ETA: 2s - loss: 0.3592 - accuracy: 0.8915/93 [===>..........................] - ETA: 2s - loss: 0.3631 - accuracy: 0.8817/93 [====>.........................] - ETA: 2s - loss: 0.3603 - accuracy: 0.8819/93 [=====>........................] - ETA: 2s - loss: 0.3572 - accuracy: 0.8921/93 [=====>........................] - ETA: 2s - loss: 0.3533 - accuracy: 0.8923/93 [======>.......................] - ETA: 2s - loss: 0.3538 - accuracy: 0.8925/93 [=======>......................] - ETA: 2s - loss: 0.3537 - accuracy: 0.8927/93 [=======>......................] - ETA: 2s - loss: 0.3506 - accuracy: 0.8929/93 [========>.....................] - ETA: 2s - loss: 0.3558 - accuracy: 0.8931/93 [=========>....................] - ETA: 2s - loss: 0.3565 - accuracy: 0.8933/93 [=========>....................] - ETA: 1s - loss: 0.3567 - accuracy: 0.8935/93 [==========>...................] - ETA: 1s - loss: 0.3588 - accuracy: 0.8937/93 [==========>...................] - ETA: 1s - loss: 0.3561 - accuracy: 0.8939/93 [===========>..................] - ETA: 1s - loss: 0.3510 - accuracy: 0.8941/93 [============>.................] - ETA: 1s - loss: 0.3457 - accuracy: 0.8943/93 [============>.................] - ETA: 1s - loss: 0.3436 - accuracy: 0.8945/93 [=============>................] - ETA: 1s - loss: 0.3499 - accuracy: 0.8947/93 [==============>...............] - ETA: 1s - loss: 0.3489 - accuracy: 0.8949/93 [==============>...............] - ETA: 1s - loss: 0.3516 - accuracy: 0.8951/93 [===============>..............] - ETA: 1s - loss: 0.3514 - accuracy: 0.8953/93 [================>.............] - ETA: 1s - loss: 0.3535 - accuracy: 0.8955/93 [================>.............] - ETA: 1s - loss: 0.3563 - accuracy: 0.8957/93 [=================>............] - ETA: 1s - loss: 0.3573 - accuracy: 0.8959/93 [==================>...........] - ETA: 1s - loss: 0.3564 - accuracy: 0.8961/93 [==================>...........] - ETA: 1s - loss: 0.3542 - accuracy: 0.8963/93 [===================>..........] - ETA: 0s - loss: 0.3568 - accuracy: 0.8965/93 [===================>..........] - ETA: 0s - loss: 0.3560 - accuracy: 0.8967/93 [====================>.........] - ETA: 0s - loss: 0.3553 - accuracy: 0.8969/93 [=====================>........] - ETA: 0s - loss: 0.3555 - accuracy: 0.8971/93 [=====================>........] - ETA: 0s - loss: 0.3567 - accuracy: 0.8973/93 [======================>.......] - ETA: 0s - loss: 0.3573 - accuracy: 0.8975/93 [=======================>......] - ETA: 0s - loss: 0.3551 - accuracy: 0.8977/93 [=======================>......] - ETA: 0s - loss: 0.3563 - accuracy: 0.8979/93 [========================>.....] - ETA: 0s - loss: 0.3571 - accuracy: 0.8981/93 [=========================>....] - ETA: 0s - loss: 0.3577 - accuracy: 0.8983/93 [=========================>....] - ETA: 0s - loss: 0.3591 - accuracy: 0.8985/93 [==========================>...] - ETA: 0s - loss: 0.3587 - accuracy: 0.8987/93 [===========================>..] - ETA: 0s - loss: 0.3596 - accuracy: 0.8989/93 [===========================>..] - ETA: 0s - loss: 0.3588 - accuracy: 0.8991/93 [============================>.] - ETA: 0s - loss: 0.3575 - accuracy: 0.8993/93 [==============================] - ETA: 0s - loss: 0.3575 - accuracy: 0.8993/93 [==============================] - 4s 38ms/step - loss: 0.3575 - accuracy: 0.8955 - val_loss: 0.5329 - val_accuracy: 0.8100\nEpoch 99/100\n 1/93 [..............................] - ETA: 0s - loss: 0.3369 - accuracy: 0.90 3/93 [..............................] - ETA: 1s - loss: 0.3012 - accuracy: 0.90 5/93 [>.............................] - ETA: 2s - loss: 0.2985 - accuracy: 0.91 7/93 [=>............................] - ETA: 2s - loss: 0.3107 - accuracy: 0.91 9/93 [=>............................] - ETA: 2s - loss: 0.3107 - accuracy: 0.9011/93 [==>...........................] - ETA: 2s - loss: 0.3277 - accuracy: 0.9013/93 [===>..........................] - ETA: 2s - loss: 0.3383 - accuracy: 0.9015/93 [===>..........................] - ETA: 2s - loss: 0.3336 - accuracy: 0.9017/93 [====>.........................] - ETA: 2s - loss: 0.3307 - accuracy: 0.9019/93 [=====>........................] - ETA: 2s - loss: 0.3344 - accuracy: 0.9021/93 [=====>........................] - ETA: 2s - loss: 0.3459 - accuracy: 0.8923/93 [======>.......................] - ETA: 2s - loss: 0.3495 - accuracy: 0.8925/93 [=======>......................] - ETA: 2s - loss: 0.3443 - accuracy: 0.8927/93 [=======>......................] - ETA: 2s - loss: 0.3496 - accuracy: 0.8929/93 [========>.....................] - ETA: 2s - loss: 0.3515 - accuracy: 0.8931/93 [=========>....................] - ETA: 1s - loss: 0.3516 - accuracy: 0.8933/93 [=========>....................] - ETA: 1s - loss: 0.3556 - accuracy: 0.8935/93 [==========>...................] - ETA: 1s - loss: 0.3585 - accuracy: 0.8937/93 [==========>...................] - ETA: 1s - loss: 0.3568 - accuracy: 0.8939/93 [===========>..................] - ETA: 1s - loss: 0.3541 - accuracy: 0.8941/93 [============>.................] - ETA: 1s - loss: 0.3521 - accuracy: 0.8943/93 [============>.................] - ETA: 1s - loss: 0.3523 - accuracy: 0.8945/93 [=============>................] - ETA: 1s - loss: 0.3479 - accuracy: 0.8947/93 [==============>...............] - ETA: 1s - loss: 0.3497 - accuracy: 0.8949/93 [==============>...............] - ETA: 1s - loss: 0.3483 - accuracy: 0.8951/93 [===============>..............] - ETA: 1s - loss: 0.3522 - accuracy: 0.8953/93 [================>.............] - ETA: 1s - loss: 0.3533 - accuracy: 0.8955/93 [================>.............] - ETA: 1s - loss: 0.3532 - accuracy: 0.8957/93 [=================>............] - ETA: 1s - loss: 0.3531 - accuracy: 0.8959/93 [==================>...........] - ETA: 1s - loss: 0.3578 - accuracy: 0.8961/93 [==================>...........] - ETA: 1s - loss: 0.3567 - accuracy: 0.8963/93 [===================>..........] - ETA: 0s - loss: 0.3591 - accuracy: 0.8965/93 [===================>..........] - ETA: 0s - loss: 0.3599 - accuracy: 0.8967/93 [====================>.........] - ETA: 0s - loss: 0.3600 - accuracy: 0.8969/93 [=====================>........] - ETA: 0s - loss: 0.3599 - accuracy: 0.8971/93 [=====================>........] - ETA: 0s - loss: 0.3590 - accuracy: 0.8973/93 [======================>.......] - ETA: 0s - loss: 0.3585 - accuracy: 0.8975/93 [=======================>......] - ETA: 0s - loss: 0.3562 - accuracy: 0.8977/93 [=======================>......] - ETA: 0s - loss: 0.3546 - accuracy: 0.8979/93 [========================>.....] - ETA: 0s - loss: 0.3559 - accuracy: 0.8981/93 [=========================>....] - ETA: 0s - loss: 0.3581 - accuracy: 0.8983/93 [=========================>....] - ETA: 0s - loss: 0.3585 - accuracy: 0.8985/93 [==========================>...] - ETA: 0s - loss: 0.3578 - accuracy: 0.8987/93 [===========================>..] - ETA: 0s - loss: 0.3580 - accuracy: 0.8989/93 [===========================>..] - ETA: 0s - loss: 0.3584 - accuracy: 0.8991/93 [============================>.] - ETA: 0s - loss: 0.3582 - accuracy: 0.8993/93 [==============================] - ETA: 0s - loss: 0.3564 - accuracy: 0.8993/93 [==============================] - 4s 38ms/step - loss: 0.3564 - accuracy: 0.8963 - val_loss: 0.5168 - val_accuracy: 0.8044\nEpoch 100/100\n 1/93 [..............................] - ETA: 0s - loss: 0.3300 - accuracy: 0.91 3/93 [..............................] - ETA: 1s - loss: 0.4231 - accuracy: 0.88 5/93 [>.............................] - ETA: 2s - loss: 0.3991 - accuracy: 0.89 7/93 [=>............................] - ETA: 2s - loss: 0.3669 - accuracy: 0.89 9/93 [=>............................] - ETA: 2s - loss: 0.3697 - accuracy: 0.8911/93 [==>...........................] - ETA: 2s - loss: 0.3705 - accuracy: 0.8913/93 [===>..........................] - ETA: 2s - loss: 0.3609 - accuracy: 0.8915/93 [===>..........................] - ETA: 2s - loss: 0.3647 - accuracy: 0.8917/93 [====>.........................] - ETA: 2s - loss: 0.3665 - accuracy: 0.8919/93 [=====>........................] - ETA: 2s - loss: 0.3598 - accuracy: 0.8921/93 [=====>........................] - ETA: 2s - loss: 0.3492 - accuracy: 0.9023/93 [======>.......................] - ETA: 2s - loss: 0.3491 - accuracy: 0.9025/93 [=======>......................] - ETA: 2s - loss: 0.3467 - accuracy: 0.9027/93 [=======>......................] - ETA: 2s - loss: 0.3432 - accuracy: 0.9029/93 [========>.....................] - ETA: 2s - loss: 0.3436 - accuracy: 0.9031/93 [=========>....................] - ETA: 1s - loss: 0.3462 - accuracy: 0.9033/93 [=========>....................] - ETA: 1s - loss: 0.3487 - accuracy: 0.8935/93 [==========>...................] - ETA: 1s - loss: 0.3503 - accuracy: 0.8937/93 [==========>...................] - ETA: 1s - loss: 0.3535 - accuracy: 0.8939/93 [===========>..................] - ETA: 1s - loss: 0.3538 - accuracy: 0.8941/93 [============>.................] - ETA: 1s - loss: 0.3534 - accuracy: 0.8943/93 [============>.................] - ETA: 1s - loss: 0.3505 - accuracy: 0.8945/93 [=============>................] - ETA: 1s - loss: 0.3491 - accuracy: 0.8947/93 [==============>...............] - ETA: 1s - loss: 0.3479 - accuracy: 0.8949/93 [==============>...............] - ETA: 1s - loss: 0.3478 - accuracy: 0.8951/93 [===============>..............] - ETA: 1s - loss: 0.3483 - accuracy: 0.8953/93 [================>.............] - ETA: 1s - loss: 0.3496 - accuracy: 0.8955/93 [================>.............] - ETA: 1s - loss: 0.3541 - accuracy: 0.8957/93 [=================>............] - ETA: 1s - loss: 0.3560 - accuracy: 0.8959/93 [==================>...........] - ETA: 1s - loss: 0.3560 - accuracy: 0.8961/93 [==================>...........] - ETA: 1s - loss: 0.3570 - accuracy: 0.8963/93 [===================>..........] - ETA: 0s - loss: 0.3556 - accuracy: 0.8965/93 [===================>..........] - ETA: 0s - loss: 0.3548 - accuracy: 0.8967/93 [====================>.........] - ETA: 0s - loss: 0.3566 - accuracy: 0.8969/93 [=====================>........] - ETA: 0s - loss: 0.3536 - accuracy: 0.8971/93 [=====================>........] - ETA: 0s - loss: 0.3568 - accuracy: 0.8973/93 [======================>.......] - ETA: 0s - loss: 0.3588 - accuracy: 0.8975/93 [=======================>......] - ETA: 0s - loss: 0.3584 - accuracy: 0.8977/93 [=======================>......] - ETA: 0s - loss: 0.3589 - accuracy: 0.8979/93 [========================>.....] - ETA: 0s - loss: 0.3591 - accuracy: 0.8981/93 [=========================>....] - ETA: 0s - loss: 0.3574 - accuracy: 0.8983/93 [=========================>....] - ETA: 0s - loss: 0.3583 - accuracy: 0.8985/93 [==========================>...] - ETA: 0s - loss: 0.3579 - accuracy: 0.8987/93 [===========================>..] - ETA: 0s - loss: 0.3564 - accuracy: 0.8989/93 [===========================>..] - ETA: 0s - loss: 0.3555 - accuracy: 0.8991/93 [============================>.] - ETA: 0s - loss: 0.3542 - accuracy: 0.8993/93 [==============================] - ETA: 0s - loss: 0.3538 - accuracy: 0.8993/93 [==============================] - 4s 38ms/step - loss: 0.3538 - accuracy: 0.8969 - val_loss: 0.4666 - val_accuracy: 0.8324\n"
    }
   ],
   "source": [
    "model_1_history = model_1.fit(x_train, y_train, batch_size=param_list[\"BATCH_SIZE\"], validation_split=0.2, epochs=param_list[\"EPOCHS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'20200909-143624'"
     },
     "metadata": {},
     "execution_count": 295
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "'''\n",
    "log_dir = \"logs/fit/\" + timestamp\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "'''\n",
    "version_dir = \"version/\" + timestamp \n",
    "\n",
    "os.makedirs(version_dir)\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save(\"version/{}/model.h5\".format(timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
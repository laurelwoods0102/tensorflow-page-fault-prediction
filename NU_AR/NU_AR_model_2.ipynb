{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600435265769",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorboard.plugins.hparams import api as hp_api\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Dense, \n",
    "    Dropout,\n",
    "    LSTMCell,\n",
    "    RNN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'20200918-233033'"
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = \"logs/\" + timestamp\n",
    "version_dir = \"version/\" + timestamp \n",
    "\n",
    "os.makedirs(log_dir)\n",
    "os.makedirs(version_dir)\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"NU_AR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_params = {\n",
    "    'PAST_HISTORY': 16,\n",
    "    'FUTURE_TARGET': 8,\n",
    "    'BATCH_SIZE': 1024,\n",
    "    'BUFFER_SIZE': 200000,\n",
    "    'EPOCHS': 500,\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'PAST_HISTORY': 16,\n 'FUTURE_TARGET': 8,\n 'BATCH_SIZE': 1024,\n 'BUFFER_SIZE': 200000,\n 'EPOCHS': 500,\n 'VOCAB_SIZE': 6}"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "with open(\"static/pipeline.pkl\", \"rb\") as p:\n",
    "    pipeline = dill.load(p)\n",
    "\n",
    "static_params[\"VOCAB_SIZE\"] = pipeline[\"sparse_category_encoder\"].vocab_size\n",
    "static_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_simple = {\n",
    "    \"HP_LSTM_1_UNITS\" : 128,\n",
    "    \"HP_LSTM_1_DROPOUT\" : 0.5,\n",
    "    \"HP_LEARNING_RATE\" : 1e-3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_multiple = {\n",
    "    \"HP_LSTM_1_UNITS\" : 32,\n",
    "    \"HP_LSTM_2_UNITS\" : 32,\n",
    "    \"HP_LSTM_1_DROPOUT\" : 0.0,\n",
    "    \"HP_LSTM_2_DROPOUT\" : 0.0,\n",
    "    \"HP_LEARNING_RATE\" : 1e-3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timeseries(dataset, start_index, end_index, history_size, target_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i)\n",
    "        # Reshape data from (history_size,) to (history_size, n_feature)\n",
    "        data.append(np.reshape(dataset[indices], (history_size, 5)))\n",
    "        #data.append(dataset[indices])\n",
    "        labels.append(np.reshape(dataset[i:i+target_size], (target_size, 5)))\n",
    "        #labels.append(dataset[i:i+target_size])\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.genfromtxt(\"data/{}_train_set.csv\".format(dataset_name), delimiter=\"\\n\", dtype=np.int32)\n",
    "encoder = OneHotEncoder(dtype=np.float32)\n",
    "onehot_train_set = encoder.fit_transform(train_set.reshape(-1, 1))\n",
    "x_train, y_train = generate_timeseries(onehot_train_set.toarray(), 0, None, static_params[\"PAST_HISTORY\"], static_params[\"FUTURE_TARGET\"])\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train[:-1], y_train[:-1]))   # As 5 (= -1) is artificially injected at the end\n",
    "train_data = train_data.cache().batch(static_params[\"BATCH_SIZE\"]).shuffle(static_params[\"BUFFER_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = np.genfromtxt(\"data/{}_val_set.csv\".format(dataset_name), delimiter=\"\\n\", dtype=np.int32)\n",
    "onehot_val_set = encoder.transform(val_set.reshape(-1, 1))\n",
    "x_val, y_val = generate_timeseries(onehot_val_set.toarray(), 0, None, static_params[\"PAST_HISTORY\"], static_params[\"FUTURE_TARGET\"])\n",
    "val_data = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_data = val_data.cache().batch(static_params[\"BATCH_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = np.genfromtxt(\"data/{}_test_set_original.csv\".format(dataset_name), delimiter=\"\\n\", dtype=np.int64)\n",
    "processed_test_set = pipeline.transform(test_set.copy())\n",
    "onehot_test_set = encoder.transform(processed_test_set.reshape(-1, 1))\n",
    "x_test, y_test = generate_timeseries(onehot_test_set.toarray(), 0, None, static_params[\"PAST_HISTORY\"], static_params[\"FUTURE_TARGET\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARSimple(keras.Model):\n",
    "    def __init__(self, units, dropout, output_steps, output_size):\n",
    "        super().__init__()\n",
    "        self.output_steps = output_steps\n",
    "        self.units = units\n",
    "        self.lstm_cell = LSTMCell(units, dropout=dropout)\n",
    "\n",
    "        self.lstm_rnn = RNN(self.lstm_cell, return_state=True)\n",
    "        self.dense = Dense(output_size, activation=\"softmax\")\n",
    "\n",
    "    @tf.function\n",
    "    def warmup(self, inputs):\n",
    "        #onehot_inputs = tf.squeeze(tf.one_hot(inputs, static_params[\"VOCAB_SIZE\"]), axis=2)\n",
    "\n",
    "        # inputs.shape => (batch, time, features)\n",
    "        # x.shape => (batch, lstm_units)\n",
    "        x, *state = self.lstm_rnn(inputs)\n",
    "\n",
    "        # predictions.shape => (batch, features)\n",
    "        prediction = self.dense(x)\n",
    "\n",
    "        return prediction, state\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=None):\n",
    "        # Use a TensorArray to capture dynamically unrolled outputs.\n",
    "        #predictions = []\n",
    "        predictions = tf.TensorArray(tf.float32, size=self.output_steps, clear_after_read=False)\n",
    "        # Initialize the lstm state\n",
    "        prediction, state = self.warmup(inputs)\n",
    "\n",
    "        # Insert the first prediction\n",
    "        #predictions.append(prediction)\n",
    "        predictions = predictions.write(0, prediction)\n",
    "\n",
    "        # Run the rest of the prediction steps\n",
    "        for i in tf.range(1, self.output_steps):\n",
    "            # Use the last prediction as input.\n",
    "            x = prediction\n",
    "\n",
    "            # Execute one lstm step.\n",
    "            x, state = self.lstm_cell(x, states=state, training=training)\n",
    "\n",
    "            # Convert the lstm output to a prediction.\n",
    "            prediction = self.dense(x)\n",
    "\n",
    "            # Add the prediction to the output\n",
    "            #predictions.append(prediction)\n",
    "            predictions = predictions.write(i, prediction)\n",
    "\n",
    "        # predictions.shape => (time, batch, features)\n",
    "        #predictions = tf.stack(predictions)\n",
    "        predictions = predictions.stack()\n",
    "\n",
    "        # predictions.shape => (batch, time, features)\n",
    "        predictions = tf.transpose(predictions, [1, 0, 2])\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARMultiple(keras.Model):\n",
    "    def __init__(self, units_1, units_2, dropout_1, dropout_2, output_steps, output_size):\n",
    "        super().__init__()\n",
    "        self.output_steps = output_steps\n",
    "        self.units_1 = units_1\n",
    "        self.units_2 = units_2\n",
    "        self.dropout_1 = dropout_1\n",
    "        self.dropout_2 = dropout_2\n",
    "\n",
    "        self.lstm_cell_1 = LSTMCell(units_1, dropout=dropout_1)\n",
    "        self.lstm_cell_2 = LSTMCell(units_2, dropout=dropout_2)\n",
    "\n",
    "        self.lstm_rnn_1 = RNN(self.lstm_cell_1, return_state=True, return_sequences=True)\n",
    "        self.lstm_rnn_2 = RNN(self.lstm_cell_2, return_state=True)\n",
    "        self.dense = Dense(output_size, activation=\"softmax\")\n",
    "\n",
    "    @tf.function#(input_signature=[tf.TensorSpec(shape=[None, None, 1], dtype=tf.int32)])\n",
    "    def warmup(self, inputs):\n",
    "        onehot_inputs = tf.squeeze(tf.one_hot(inputs, static_params[\"VOCAB_SIZE\"]), axis=2)\n",
    "\n",
    "        # inputs.shape => (batch, time, features)\n",
    "        # x.shape => (batch, lstm_units)\n",
    "        x_1, *state_1 = self.lstm_rnn_1(onehot_inputs)\n",
    "        x_2, *state_2 = self.lstm_rnn_2(x_1)\n",
    "\n",
    "        # predictions.shape => (batch, features)\n",
    "        prediction = self.dense(x_2)\n",
    "\n",
    "        return prediction, state_1, state_2\n",
    "\n",
    "    @tf.function#(input_signature=[tf.TensorSpec(shape=[None, None, 1], dtype=tf.int32)])\n",
    "    def call(self, inputs, training=None):\n",
    "        # Use a TensorArray to capture dynamically unrolled outputs.\n",
    "        #predictions = []\n",
    "        predictions = tf.TensorArray(tf.float32, size=self.output_steps, clear_after_read=False)\n",
    "\n",
    "        # Initialize the lstm state\n",
    "        prediction, state_1, state_2 = self.warmup(inputs)\n",
    "\n",
    "        # Insert the first prediction\n",
    "        #predictions.append(prediction)\n",
    "        predictions = predictions.write(0, prediction)\n",
    "\n",
    "        # Run the rest of the prediction steps\n",
    "        for i in tf.range(1, self.output_steps):\n",
    "            # Use the last prediction as input.\n",
    "            x = prediction\n",
    "\n",
    "            # Execute one lstm step.\n",
    "            x_1, state_1 = self.lstm_cell_1(x, states=state_1, training=training)\n",
    "            x_2, state_2 = self.lstm_cell_2(x_1, states=state_2, training=training)\n",
    "\n",
    "            # Convert the lstm output to a prediction.\n",
    "            prediction = self.dense(x_2)\n",
    "\n",
    "            # Add the prediction to the output\n",
    "            #predictions.append(prediction)\n",
    "            predictions = predictions.write(i, prediction)\n",
    "\n",
    "        # predictions.shape => (time, batch, features)\n",
    "        #predictions = tf.stack(predictions)\n",
    "        predictions = predictions.stack()\n",
    "\n",
    "        # predictions.shape => (batch, time, features)\n",
    "        predictions = tf.transpose(predictions, [1, 0, 2])\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARSimple(\n",
    "    units=hparams_simple[\"HP_LSTM_1_UNITS\"], dropout=hparams_simple[\"HP_LSTM_1_DROPOUT\"], \n",
    "    output_steps=static_params[\"FUTURE_TARGET\"], output_size=static_params[\"VOCAB_SIZE\"])"
   ]
  },
  {
   "source": [
    "model = ARMultiple(\n",
    "    units_1=hparams_multiple[\"HP_LSTM_1_UNITS\"], units_2=hparams_multiple[\"HP_LSTM_2_UNITS\"], dropout_1=hparams_multiple[\"HP_LSTM_1_DROPOUT\"], \n",
    "    dropout_2=hparams_multiple[\"HP_LSTM_2_DROPOUT\"], output_steps=static_params[\"FUTURE_TARGET\"], output_size=static_params[\"VOCAB_SIZE\"])"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Nadam(hparams_simple[\"HP_LEARNING_RATE\"]),\n",
    "    loss=tfa.losses.SigmoidFocalCrossEntropy(),\n",
    "    #loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/50\n7/7 [==============================] - 0s 49ms/step - loss: 0.0204 - accuracy: 0.9741 - val_loss: 0.0043 - val_accuracy: 0.9994\nEpoch 2/50\n7/7 [==============================] - 0s 43ms/step - loss: 0.0200 - accuracy: 0.9742 - val_loss: 0.0056 - val_accuracy: 0.9994\nEpoch 3/50\n7/7 [==============================] - 0s 45ms/step - loss: 0.0198 - accuracy: 0.9742 - val_loss: 0.0065 - val_accuracy: 0.9994\nEpoch 4/50\n7/7 [==============================] - 0s 41ms/step - loss: 0.0199 - accuracy: 0.9742 - val_loss: 0.0047 - val_accuracy: 0.9994\nEpoch 5/50\n7/7 [==============================] - 0s 41ms/step - loss: 0.0192 - accuracy: 0.9743 - val_loss: 0.0056 - val_accuracy: 0.9994\nEpoch 6/50\n7/7 [==============================] - 0s 41ms/step - loss: 0.0188 - accuracy: 0.9746 - val_loss: 0.0035 - val_accuracy: 0.9994\nEpoch 7/50\n7/7 [==============================] - 0s 39ms/step - loss: 0.0187 - accuracy: 0.9749 - val_loss: 0.0059 - val_accuracy: 0.9994\nEpoch 8/50\n7/7 [==============================] - 0s 41ms/step - loss: 0.0185 - accuracy: 0.9749 - val_loss: 0.0051 - val_accuracy: 0.9994\nEpoch 9/50\n7/7 [==============================] - 0s 43ms/step - loss: 0.0180 - accuracy: 0.9750 - val_loss: 0.0103 - val_accuracy: 0.9994\nEpoch 10/50\n7/7 [==============================] - 0s 43ms/step - loss: 0.0183 - accuracy: 0.9750 - val_loss: 0.0067 - val_accuracy: 0.9994\nEpoch 11/50\n7/7 [==============================] - 0s 41ms/step - loss: 0.0175 - accuracy: 0.9743 - val_loss: 0.0070 - val_accuracy: 0.9994\n45/45 [==============================] - 0s 6ms/step - loss: 0.0189 - accuracy: 0.9807\n"
    }
   ],
   "source": [
    "with tf.summary.create_file_writer(log_dir).as_default():\n",
    "    hp_api.hparams(hparams_simple)\n",
    "    history = model.fit(train_data, validation_data=val_data, epochs=50, callbacks=[\n",
    "        keras.callbacks.EarlyStopping('val_loss', patience=5),\n",
    "        keras.callbacks.TensorBoard(log_dir)\n",
    "        ])\n",
    "\n",
    "    loss, acc = model.evaluate(x_test, y_test)\n",
    "    tf.summary.scalar('test_loss', loss, step=x_test.shape[0])\n",
    "    tf.summary.scalar('test_accuracy', acc, step=x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"ar_simple\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #\n=================================================================\nlstm_cell (LSTMCell)         multiple                  4992\n_________________________________________________________________\nrnn (RNN)                    multiple                  4992\n_________________________________________________________________\ndense (Dense)                multiple                  198\n=================================================================\nTotal params: 5,190\nTrainable params: 5,190\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nINFO:tensorflow:Assets written to: version/20200918-205457\\assets\n"
    }
   ],
   "source": [
    "tf.saved_model.save(model, version_dir, \n",
    "    signatures=model.call.get_concrete_function(tf.TensorSpec(shape=[None, None, 1], dtype=tf.int32, name=\"call\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"version/{}/evaluate.csv\".format(timestamp), \"w\") as r:\n",
    "    r.write(\"loss, accuracy\\n\")\n",
    "    r.write(\"{}, {}\".format(loss, acc))"
   ]
  },
  {
   "source": [
    "new_model = tf.saved_model.load(\"version/\" + \"20200918-210348\")"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "inference = new_model.signatures[\"serving_default\"]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "inference(tf.constant(x_train[0].reshape(1, -1, 1)))"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600248737147",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorboard.plugins.hparams import api as hp_api\n",
    "import kerastuner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    TimeDistributed, \n",
    "    Dense, \n",
    "    Conv1D, \n",
    "    MaxPooling1D, \n",
    "    Bidirectional, \n",
    "    LSTM, \n",
    "    Dropout,\n",
    "    Lambda\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"SEG_AR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_params = {\n",
    "    'PAST_HISTORY': 16,\n",
    "    'FUTURE_TARGET': 8,\n",
    "    'BATCH_SIZE': 1024,\n",
    "    'BUFFER_SIZE': 200000,\n",
    "    'EPOCHS': 500,\n",
    "    'VOCAB_SIZE': 16293\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timeseries(dataset, start_index, end_index, history_size, target_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i)\n",
    "        # Reshape data from (history_size,) to (history_size, n_feature)\n",
    "        data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
    "        #data.append(dataset[indices])\n",
    "        labels.append(np.reshape(dataset[i:i+target_size], (target_size, 1)))\n",
    "        #labels.append(dataset[i:i+target_size])\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.genfromtxt(\"data/SEG_train_set.csv\", delimiter=\"\\n\", dtype=np.int32)\n",
    "x_train, y_train = generate_timeseries(train_set, 0, None, static_params[\"PAST_HISTORY\"], static_params[\"FUTURE_TARGET\"])\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.cache().batch(static_params[\"BATCH_SIZE\"]).shuffle(static_params[\"BUFFER_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = np.genfromtxt(\"data/SEG_val_set.csv\", delimiter=\"\\n\", dtype=np.int32)\n",
    "x_val, y_val = generate_timeseries(val_set, 0, None, static_params[\"PAST_HISTORY\"], static_params[\"FUTURE_TARGET\"])\n",
    "val_data = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_data = val_data.cache().batch(static_params[\"BATCH_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(161267, 16, 1)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedBack(keras.Model):\n",
    "    def __init__(self, units, out_steps):\n",
    "        super().__init__()\n",
    "        self.out_steps = out_steps\n",
    "        self.units = units\n",
    "        self.lstm_cell = keras.layers.LSTMCell(units)\n",
    "\n",
    "        # Also wrap the LSTMCell in an RNN to simplify the `warmup` method.\n",
    "        self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n",
    "        self.dense = Dense(static_params[\"VOCAB_SIZE\"], activation=\"softmax\")\n",
    "        #self.decode = Lambda(lambda x: tf.reshape(tf.cast(tf.math.argmax(x, axis=1), tf.float32), (-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_model = FeedBack(units=128, out_steps=static_params[\"FUTURE_TARGET\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup(self, inputs):\n",
    "    onehot_inputs = tf.squeeze(tf.one_hot(inputs, static_params[\"VOCAB_SIZE\"]), axis=2)\n",
    "\n",
    "    # inputs.shape => (batch, time, features)\n",
    "    # x.shape => (batch, lstm_units)\n",
    "    x, *state = self.lstm_rnn(onehot_inputs)\n",
    "\n",
    "    # predictions.shape => (batch, features)\n",
    "    #prediction = self.dense(x)\n",
    "    prediction = self.dense(x)\n",
    "    #prediction = self.decode(prediction)\n",
    "\n",
    "    return prediction, state\n",
    "\n",
    "FeedBack.warmup = warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 16293), dtype=float32, numpy=\narray([[6.1300219e-05, 6.1480685e-05, 6.1337698e-05, ..., 6.1370658e-05,\n        6.1381965e-05, 6.1353712e-05],\n       [6.1300219e-05, 6.1480685e-05, 6.1337698e-05, ..., 6.1370658e-05,\n        6.1381965e-05, 6.1353712e-05]], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "prediction, state = feedback_model.warmup(x_train[:2].reshape(2, -1, 1))\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call(self, inputs, training=None):\n",
    "    # Use a TensorArray to capture dynamically unrolled outputs.\n",
    "    predictions = []\n",
    "    # Initialize the lstm state\n",
    "    prediction, state = self.warmup(inputs)\n",
    "\n",
    "    # Insert the first prediction\n",
    "    predictions.append(prediction)\n",
    "\n",
    "    # Run the rest of the prediction steps\n",
    "    for _ in range(self.out_steps - 1):\n",
    "        # Use the last prediction as input.\n",
    "        x = prediction\n",
    "\n",
    "        # Execute one lstm step.\n",
    "        x, state = self.lstm_cell(x, states=state, training=training)\n",
    "\n",
    "        # Convert the lstm output to a prediction.\n",
    "        #prediction = self.dense(x)\n",
    "        prediction = self.dense(x)\n",
    "        #prediction = self.decode(prediction)\n",
    "\n",
    "\n",
    "        # Add the prediction to the output\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    # predictions.shape => (time, batch, features)\n",
    "    predictions = tf.stack(predictions)\n",
    "\n",
    "    # predictions.shape => (batch, time, features)\n",
    "    predictions = tf.transpose(predictions, [1, 0, 2])\n",
    "    return predictions\n",
    "\n",
    "FeedBack.call = call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "TensorShape([2, 8, 16293])"
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "result = feedback_model(x_train[:2].reshape(2, -1, 1))\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_model.compile(\n",
    "    optimizer=keras.optimizers.Nadam(1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'20200916-191719'"
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = \"logs/\" + timestamp\n",
    "\n",
    "os.makedirs(log_dir)\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " ETA: 21s - loss: 1.1723 - accuracy: 0.622 81/158 [==============>...............] - ETA: 21s - loss: 1.1764 - accuracy: 0.621 82/158 [==============>...............] - ETA: 21s - loss: 1.1784 - accuracy: 0.620 83/158 [==============>...............] - ETA: 21s - loss: 1.1790 - accuracy: 0.620 84/158 [==============>...............] - ETA: 20s - loss: 1.1787 - accuracy: 0.620 85/158 [===============>..............] - ETA: 20s - loss: 1.1816 - accuracy: 0.619 86/158 [===============>..............] - ETA: 20s - loss: 1.1836 - accuracy: 0.618 87/158 [===============>..............] - ETA: 19s - loss: 1.1834 - accuracy: 0.619 88/158 [===============>..............] - ETA: 19s - loss: 1.1860 - accuracy: 0.618 89/158 [===============>..............] - ETA: 19s - loss: 1.1862 - accuracy: 0.617 90/158 [================>.............] - ETA: 19s - loss: 1.1848 - accuracy: 0.618 91/158 [================>.............] - ETA: 18s - loss: 1.1756 - accuracy: 0.621 92/158 [================>.............] - ETA: 18s - loss: 1.1746 - accuracy: 0.619 93/158 [================>.............] - ETA: 18s - loss: 1.1754 - accuracy: 0.619 94/158 [================>.............] - ETA: 17s - loss: 1.1781 - accuracy: 0.618 95/158 [=================>............] - ETA: 17s - loss: 1.1769 - accuracy: 0.616 96/158 [=================>............] - ETA: 17s - loss: 1.1775 - accuracy: 0.616 97/158 [=================>............] - ETA: 17s - loss: 1.1819 - accuracy: 0.615 98/158 [=================>............] - ETA: 16s - loss: 1.1873 - accuracy: 0.613 99/158 [=================>............] - ETA: 16s - loss: 1.1862 - accuracy: 0.611100/158 [=================>............] - ETA: 16s - loss: 1.1887 - accuracy: 0.610101/158 [==================>...........] - ETA: 15s - loss: 1.1863 - accuracy: 0.611102/158 [==================>...........] - ETA: 15s - loss: 1.1878 - accuracy: 0.610103/158 [==================>...........] - ETA: 15s - loss: 1.1913 - accuracy: 0.609104/158 [==================>...........] - ETA: 15s - loss: 1.1961 - accuracy: 0.607105/158 [==================>...........] - ETA: 14s - loss: 1.1848 - accuracy: 0.611106/158 [===================>..........] - ETA: 14s - loss: 1.1844 - accuracy: 0.611107/158 [===================>..........] - ETA: 14s - loss: 1.1869 - accuracy: 0.610108/158 [===================>..........] - ETA: 13s - loss: 1.1760 - accuracy: 0.614109/158 [===================>..........] - ETA: 13s - loss: 1.1756 - accuracy: 0.615110/158 [===================>..........] - ETA: 13s - loss: 1.1776 - accuracy: 0.614111/158 [====================>.........] - ETA: 13s - loss: 1.1787 - accuracy: 0.614112/158 [====================>.........] - ETA: 12s - loss: 1.1794 - accuracy: 0.614113/158 [====================>.........] - ETA: 12s - loss: 1.1813 - accuracy: 0.613114/158 [====================>.........] - ETA: 12s - loss: 1.1825 - accuracy: 0.612115/158 [====================>.........] - ETA: 12s - loss: 1.1826 - accuracy: 0.613116/158 [=====================>........] - ETA: 11s - loss: 1.1843 - accuracy: 0.613117/158 [=====================>........] - ETA: 11s - loss: 1.1863 - accuracy: 0.612118/158 [=====================>........] - ETA: 11s - loss: 1.1883 - accuracy: 0.612119/158 [=====================>........] - ETA: 10s - loss: 1.1884 - accuracy: 0.612120/158 [=====================>........] - ETA: 10s - loss: 1.1872 - accuracy: 0.611121/158 [=====================>........] - ETA: 10s - loss: 1.1912 - accuracy: 0.609122/158 [======================>.......] - ETA: 10s - loss: 1.1923 - accuracy: 0.609123/158 [======================>.......] - ETA: 9s - loss: 1.1827 - accuracy: 0.61124/158 [======================>.......] - ETA: 9s - loss: 1.1828 - accuracy: 0.61125/158 [======================>.......] - ETA: 9s - loss: 1.1832 - accuracy: 0.61126/158 [======================>.......] - ETA: 8s - loss: 1.1839 - accuracy: 0.61127/158 [=======================>......] - ETA: 8s - loss: 1.1863 - accuracy: 0.61128/158 [=======================>......] - ETA: 8s - loss: 1.1879 - accuracy: 0.60129/158 [=======================>......] - ETA: 8s - loss: 1.1842 - accuracy: 0.61130/158 [=======================>......] - ETA: 7s - loss: 1.1870 - accuracy: 0.61131/158 [=======================>......] - ETA: 7s - loss: 1.1879 - accuracy: 0.61132/158 [========================>.....] - ETA: 7s - loss: 1.1789 - accuracy: 0.61133/158 [========================>.....] - ETA: 7s - loss: 1.1825 - accuracy: 0.61134/158 [========================>.....] - ETA: 6s - loss: 1.1863 - accuracy: 0.61135/158 [========================>.....] - ETA: 6s - loss: 1.1883 - accuracy: 0.60136/158 [========================>.....] - ETA: 6s - loss: 1.1902 - accuracy: 0.60137/158 [=========================>....] - ETA: 5s - loss: 1.1929 - accuracy: 0.60138/158 [=========================>....] - ETA: 5s - loss: 1.1941 - accuracy: 0.60139/158 [=========================>....] - ETA: 5s - loss: 1.1898 - accuracy: 0.60140/158 [=========================>....] - ETA: 5s - loss: 1.1933 - accuracy: 0.60141/158 [=========================>....] - ETA: 4s - loss: 1.1973 - accuracy: 0.60142/158 [=========================>....] - ETA: 4s - loss: 1.1976 - accuracy: 0.60143/158 [==========================>...] - ETA: 4s - loss: 1.1995 - accuracy: 0.60144/158 [==========================>...] - ETA: 3s - loss: 1.1960 - accuracy: 0.60145/158 [==========================>...] - ETA: 3s - loss: 1.1967 - accuracy: 0.60146/158 [==========================>...] - ETA: 3s - loss: 1.1962 - accuracy: 0.60147/158 [==========================>...] - ETA: 3s - loss: 1.1965 - accuracy: 0.60148/158 [===========================>..] - ETA: 2s - loss: 1.1956 - accuracy: 0.60149/158 [===========================>..] - ETA: 2s - loss: 1.1974 - accuracy: 0.60150/158 [===========================>..] - ETA: 2s - loss: 1.1984 - accuracy: 0.60151/158 [===========================>..] - ETA: 1s - loss: 1.1907 - accuracy: 0.61152/158 [===========================>..] - ETA: 1s - loss: 1.1875 - accuracy: 0.61153/158 [============================>.] - ETA: 1s - loss: 1.1878 - accuracy: 0.61154/158 [============================>.] - ETA: 1s - loss: 1.1802 - accuracy: 0.61155/158 [============================>.] - ETA: 0s - loss: 1.1826 - accuracy: 0.61156/158 [============================>.] - ETA: 0s - loss: 1.1838 - accuracy: 0.61157/158 [============================>.] - ETA: 0s - loss: 1.1827 - accuracy: 0.61158/158 [==============================] - ETA: 0s - loss: 1.1836 - accuracy: 0.61158/158 [==============================] - 49s 313ms/step - loss: 1.1836 - accuracy: 0.6132 - val_loss: 1.8851 - val_accuracy: 0.4857\nEpoch 50/50\n  1/158 [..............................] - ETA: 0s - loss: 1.2455 - accuracy: 0.52  2/158 [..............................] - ETA: 21s - loss: 1.1641 - accuracy: 0.468  3/158 [..............................] - ETA: 29s - loss: 1.1314 - accuracy: 0.458  4/158 [..............................] - ETA: 32s - loss: 0.9074 - accuracy: 0.578  5/158 [..............................] - ETA: 34s - loss: 0.7296 - accuracy: 0.662  6/158 [>.............................] - ETA: 35s - loss: 0.8109 - accuracy: 0.648  7/158 [>.............................] - ETA: 36s - loss: 0.8589 - accuracy: 0.645  8/158 [>.............................] - ETA: 37s - loss: 0.9147 - accuracy: 0.636  9/158 [>.............................] - ETA: 37s - loss: 0.8870 - accuracy: 0.656 10/158 [>.............................] - ETA: 37s - loss: 0.8084 - accuracy: 0.688 11/158 [=>............................] - ETA: 37s - loss: 0.8723 - accuracy: 0.671 12/158 [=>............................] - ETA: 37s - loss: 0.8982 - accuracy: 0.667 13/158 [=>............................] - ETA: 37s - loss: 0.9059 - accuracy: 0.668 14/158 [=>............................] - ETA: 37s - loss: 0.9576 - accuracy: 0.655 15/158 [=>............................] - ETA: 37s - loss: 0.9785 - accuracy: 0.650 16/158 [==>...........................] - ETA: 37s - loss: 1.0242 - accuracy: 0.634 17/158 [==>...........................] - ETA: 37s - loss: 1.0360 - accuracy: 0.630 18/158 [==>...........................] - ETA: 37s - loss: 1.0472 - accuracy: 0.632 19/158 [==>...........................] - ETA: 37s - loss: 1.0569 - accuracy: 0.630 20/158 [==>...........................] - ETA: 36s - loss: 1.0649 - accuracy: 0.629 21/158 [==>...........................] - ETA: 36s - loss: 1.0711 - accuracy: 0.629 22/158 [===>..........................] - ETA: 36s - loss: 1.0871 - accuracy: 0.625 23/158 [===>..........................] - ETA: 36s - loss: 1.0458 - accuracy: 0.641 24/158 [===>..........................] - ETA: 36s - loss: 1.0711 - accuracy: 0.633 25/158 [===>..........................] - ETA: 35s - loss: 1.0695 - accuracy: 0.636 26/158 [===>..........................] - ETA: 35s - loss: 1.0811 - accuracy: 0.633 27/158 [====>.........................] - ETA: 35s - loss: 1.1045 - accuracy: 0.626 28/158 [====>.........................] - ETA: 35s - loss: 1.1023 - accuracy: 0.630 29/158 [====>.........................] - ETA: 35s - loss: 1.1189 - accuracy: 0.625 30/158 [====>.........................] - ETA: 34s - loss: 1.1214 - accuracy: 0.625 31/158 [====>.........................] - ETA: 34s - loss: 1.1237 - accuracy: 0.624 32/158 [=====>........................] - ETA: 34s - loss: 1.1317 - accuracy: 0.621 33/158 [=====>........................] - ETA: 34s - loss: 1.0988 - accuracy: 0.632 34/158 [=====>........................] - ETA: 33s - loss: 1.1165 - accuracy: 0.627 35/158 [=====>........................] - ETA: 33s - loss: 1.1168 - accuracy: 0.628 36/158 [=====>........................] - ETA: 33s - loss: 1.1159 - accuracy: 0.622 37/158 [======>.......................] - ETA: 33s - loss: 1.1244 - accuracy: 0.620 38/158 [======>.......................] - ETA: 32s - loss: 1.1366 - accuracy: 0.616 39/158 [======>.......................] - ETA: 32s - loss: 1.1425 - accuracy: 0.614 40/158 [======>.......................] - ETA: 32s - loss: 1.1141 - accuracy: 0.624 41/158 [======>.......................] - ETA: 32s - loss: 1.1277 - accuracy: 0.620 42/158 [======>.......................] - ETA: 31s - loss: 1.1010 - accuracy: 0.629 43/158 [=======>......................] - ETA: 31s - loss: 1.1031 - accuracy: 0.630 44/158 [=======>......................] - ETA: 31s - loss: 1.1065 - accuracy: 0.628 45/158 [=======>......................] - ETA: 31s - loss: 1.1093 - accuracy: 0.628 46/158 [=======>......................] - ETA: 30s - loss: 1.1033 - accuracy: 0.632 47/158 [=======>......................] - ETA: 30s - loss: 1.1142 - accuracy: 0.629 48/158 [========>.....................] - ETA: 30s - loss: 1.1132 - accuracy: 0.625 49/158 [========>.....................] - ETA: 30s - loss: 1.1182 - accuracy: 0.624 50/158 [========>.....................] - ETA: 29s - loss: 1.0971 - accuracy: 0.631 51/158 [========>.....................] - ETA: 29s - loss: 1.0979 - accuracy: 0.633 52/158 [========>.....................] - ETA: 29s - loss: 1.1000 - accuracy: 0.632 53/158 [=========>....................] - ETA: 28s - loss: 1.1033 - accuracy: 0.630 54/158 [=========>....................] - ETA: 28s - loss: 1.1085 - accuracy: 0.628 55/158 [=========>....................] - ETA: 28s - loss: 1.1130 - accuracy: 0.626 56/158 [=========>....................] - ETA: 28s - loss: 1.1231 - accuracy: 0.623 57/158 [=========>....................] - ETA: 27s - loss: 1.1241 - accuracy: 0.622 58/158 [==========>...................] - ETA: 27s - loss: 1.1047 - accuracy: 0.629 59/158 [==========>...................] - ETA: 27s - loss: 1.1068 - accuracy: 0.628 60/158 [==========>...................] - ETA: 26s - loss: 1.1051 - accuracy: 0.630 61/158 [==========>...................] - ETA: 26s - loss: 1.1089 - accuracy: 0.628 62/158 [==========>...................] - ETA: 26s - loss: 1.1102 - accuracy: 0.627 63/158 [==========>...................] - ETA: 26s - loss: 1.1128 - accuracy: 0.627 64/158 [===========>..................] - ETA: 25s - loss: 1.1186 - accuracy: 0.625 65/158 [===========>..................] - ETA: 25s - loss: 1.1224 - accuracy: 0.624 66/158 [===========>..................] - ETA: 25s - loss: 1.1272 - accuracy: 0.622 67/158 [===========>..................] - ETA: 25s - loss: 1.1204 - accuracy: 0.626 68/158 [===========>..................] - ETA: 24s - loss: 1.1266 - accuracy: 0.623 69/158 [============>.................] - ETA: 24s - loss: 1.1124 - accuracy: 0.628 70/158 [============>.................] - ETA: 24s - loss: 1.1127 - accuracy: 0.629 71/158 [============>.................] - ETA: 24s - loss: 1.1140 - accuracy: 0.629 72/158 [============>.................] - ETA: 23s - loss: 1.1149 - accuracy: 0.629 73/158 [============>.................] - ETA: 23s - loss: 1.1185 - accuracy: 0.628 74/158 [=============>................] - ETA: 23s - loss: 1.1211 - accuracy: 0.626 75/158 [=============>................] - ETA: 22s - loss: 1.1063 - accuracy: 0.631 76/158 [=============>................] - ETA: 22s - loss: 1.1095 - accuracy: 0.630 77/158 [=============>................] - ETA: 22s - loss: 1.1114 - accuracy: 0.630 78/158 [=============>................] - ETA: 22s - loss: 1.1172 - accuracy: 0.629 79/158 [==============>...............] - ETA: 21s - loss: 1.1204 - accuracy: 0.628 80/158 [==============>...............] - ETA: 21s - loss: 1.1236 - accuracy: 0.627 81/158 [==============>...............] - ETA: 21s - loss: 1.1283 - accuracy: 0.625 82/158 [==============>...............] - ETA: 21s - loss: 1.1315 - accuracy: 0.624 83/158 [==============>...............] - ETA: 20s - loss: 1.1314 - accuracy: 0.624 84/158 [==============>...............] - ETA: 20s - loss: 1.1320 - accuracy: 0.625 85/158 [===============>..............] - ETA: 20s - loss: 1.1345 - accuracy: 0.624 86/158 [===============>..............] - ETA: 19s - loss: 1.1373 - accuracy: 0.623 87/158 [===============>..............] - ETA: 19s - loss: 1.1379 - accuracy: 0.624 88/158 [===============>..............] - ETA: 19s - loss: 1.1411 - accuracy: 0.623 89/158 [===============>..............] - ETA: 19s - loss: 1.1415 - accuracy: 0.624 90/158 [================>.............] - ETA: 18s - loss: 1.1439 - accuracy: 0.623 91/158 [================>.............] - ETA: 18s - loss: 1.1467 - accuracy: 0.622 92/158 [================>.............] - ETA: 18s - loss: 1.1455 - accuracy: 0.620 93/158 [================>.............] - ETA: 18s - loss: 1.1457 - accuracy: 0.621 94/158 [================>.............] - ETA: 17s - loss: 1.1400 - accuracy: 0.624 95/158 [=================>............] - ETA: 17s - loss: 1.1429 - accuracy: 0.623 96/158 [=================>............] - ETA: 17s - loss: 1.1460 - accuracy: 0.622 97/158 [=================>............] - ETA: 16s - loss: 1.1461 - accuracy: 0.622 98/158 [=================>............] - ETA: 16s - loss: 1.1496 - accuracy: 0.621 99/158 [=================>............] - ETA: 16s - loss: 1.1550 - accuracy: 0.619100/158 [=================>............] - ETA: 16s - loss: 1.1564 - accuracy: 0.619101/158 [==================>...........] - ETA: 15s - loss: 1.1586 - accuracy: 0.618102/158 [==================>...........] - ETA: 15s - loss: 1.1523 - accuracy: 0.621103/158 [==================>...........] - ETA: 15s - loss: 1.1520 - accuracy: 0.622104/158 [==================>...........] - ETA: 15s - loss: 1.1508 - accuracy: 0.623105/158 [==================>...........] - ETA: 14s - loss: 1.1527 - accuracy: 0.622106/158 [===================>..........] - ETA: 14s - loss: 1.1534 - accuracy: 0.622107/158 [===================>..........] - ETA: 14s - loss: 1.1549 - accuracy: 0.622108/158 [===================>..........] - ETA: 13s - loss: 1.1565 - accuracy: 0.621109/158 [===================>..........] - ETA: 13s - loss: 1.1522 - accuracy: 0.623110/158 [===================>..........] - ETA: 13s - loss: 1.1538 - accuracy: 0.623111/158 [====================>.........] - ETA: 13s - loss: 1.1557 - accuracy: 0.622112/158 [====================>.........] - ETA: 12s - loss: 1.1485 - accuracy: 0.624113/158 [====================>.........] - ETA: 12s - loss: 1.1510 - accuracy: 0.623114/158 [====================>.........] - ETA: 12s - loss: 1.1517 - accuracy: 0.623115/158 [====================>.........] - ETA: 11s - loss: 1.1526 - accuracy: 0.623116/158 [=====================>........] - ETA: 11s - loss: 1.1524 - accuracy: 0.623117/158 [=====================>........] - ETA: 11s - loss: 1.1545 - accuracy: 0.622118/158 [=====================>........] - ETA: 11s - loss: 1.1593 - accuracy: 0.620119/158 [=====================>........] - ETA: 10s - loss: 1.1606 - accuracy: 0.621120/158 [=====================>........] - ETA: 10s - loss: 1.1627 - accuracy: 0.620121/158 [=====================>........] - ETA: 10s - loss: 1.1647 - accuracy: 0.619122/158 [======================>.......] - ETA: 10s - loss: 1.1637 - accuracy: 0.620123/158 [======================>.......] - ETA: 9s - loss: 1.1652 - accuracy: 0.61124/158 [======================>.......] - ETA: 9s - loss: 1.1666 - accuracy: 0.61125/158 [======================>.......] - ETA: 9s - loss: 1.1618 - accuracy: 0.62126/158 [======================>.......] - ETA: 8s - loss: 1.1550 - accuracy: 0.62127/158 [=======================>......] - ETA: 8s - loss: 1.1556 - accuracy: 0.62128/158 [=======================>......] - ETA: 8s - loss: 1.1573 - accuracy: 0.62129/158 [=======================>......] - ETA: 8s - loss: 1.1579 - accuracy: 0.62130/158 [=======================>......] - ETA: 7s - loss: 1.1565 - accuracy: 0.62131/158 [=======================>......] - ETA: 7s - loss: 1.1478 - accuracy: 0.62132/158 [========================>.....] - ETA: 7s - loss: 1.1479 - accuracy: 0.62133/158 [========================>.....] - ETA: 6s - loss: 1.1506 - accuracy: 0.62134/158 [========================>.....] - ETA: 6s - loss: 1.1420 - accuracy: 0.62135/158 [========================>.....] - ETA: 6s - loss: 1.1439 - accuracy: 0.62136/158 [========================>.....] - ETA: 6s - loss: 1.1450 - accuracy: 0.62137/158 [=========================>....] - ETA: 5s - loss: 1.1477 - accuracy: 0.62138/158 [=========================>....] - ETA: 5s - loss: 1.1490 - accuracy: 0.62139/158 [=========================>....] - ETA: 5s - loss: 1.1516 - accuracy: 0.62140/158 [=========================>....] - ETA: 5s - loss: 1.1487 - accuracy: 0.62141/158 [=========================>....] - ETA: 4s - loss: 1.1498 - accuracy: 0.62142/158 [=========================>....] - ETA: 4s - loss: 1.1531 - accuracy: 0.62143/158 [==========================>...] - ETA: 4s - loss: 1.1528 - accuracy: 0.62144/158 [==========================>...] - ETA: 3s - loss: 1.1538 - accuracy: 0.62145/158 [==========================>...] - ETA: 3s - loss: 1.1556 - accuracy: 0.62146/158 [==========================>...] - ETA: 3s - loss: 1.1580 - accuracy: 0.62147/158 [==========================>...] - ETA: 3s - loss: 1.1607 - accuracy: 0.62148/158 [===========================>..] - ETA: 2s - loss: 1.1598 - accuracy: 0.62149/158 [===========================>..] - ETA: 2s - loss: 1.1607 - accuracy: 0.62150/158 [===========================>..] - ETA: 2s - loss: 1.1618 - accuracy: 0.62151/158 [===========================>..] - ETA: 1s - loss: 1.1624 - accuracy: 0.62152/158 [===========================>..] - ETA: 1s - loss: 1.1631 - accuracy: 0.62153/158 [============================>.] - ETA: 1s - loss: 1.1673 - accuracy: 0.61154/158 [============================>.] - ETA: 1s - loss: 1.1690 - accuracy: 0.61155/158 [============================>.] - ETA: 0s - loss: 1.1710 - accuracy: 0.61156/158 [============================>.] - ETA: 0s - loss: 1.1712 - accuracy: 0.61157/158 [============================>.] - ETA: 0s - loss: 1.1732 - accuracy: 0.61158/158 [==============================] - ETA: 0s - loss: 1.1698 - accuracy: 0.61158/158 [==============================] - 49s 312ms/step - loss: 1.1698 - accuracy: 0.6172 - val_loss: 1.8595 - val_accuracy: 0.5036\n"
    }
   ],
   "source": [
    "history = feedback_model.fit(train_data, validation_data=val_data, epochs=50, callbacks=[\n",
    "        keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "        keras.callbacks.TensorBoard(log_dir)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
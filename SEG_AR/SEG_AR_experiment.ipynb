{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600392894020",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorboard.plugins.hparams import api as hp_api\n",
    "import kerastuner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Dense, \n",
    "    Dropout,\n",
    "    LSTMCell,\n",
    "    RNN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"ex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"SEG_AR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_params = {\n",
    "    'PAST_HISTORY': 16,\n",
    "    'FUTURE_TARGET': 8,\n",
    "    'BATCH_SIZE': 512,\n",
    "    'BUFFER_SIZE': 200000,\n",
    "    'EPOCHS': 500,\n",
    "    'VOCAB_SIZE': 16293\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"HP_LSTM_1_UNITS\" : 64,\n",
    "    \"HP_LSTM_2_UNITS\" : 64,\n",
    "    \"HP_LSTM_1_DROPOUT\" : 0.5,\n",
    "    \"HP_LSTM_2_DROPOUT\" : 0.5,\n",
    "    \"HP_LEARNING_RATE\" : 1e-3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timeseries(dataset, start_index, end_index, history_size, target_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i)\n",
    "        # Reshape data from (history_size,) to (history_size, n_feature)\n",
    "        data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
    "        #data.append(dataset[indices])\n",
    "        labels.append(np.reshape(dataset[i:i+target_size], (target_size, 1)))\n",
    "        #labels.append(dataset[i:i+target_size])\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.genfromtxt(\"data/SEG_train_set.csv\", delimiter=\"\\n\", dtype=np.int32)\n",
    "x_train, y_train = generate_timeseries(train_set, 0, None, static_params[\"PAST_HISTORY\"], static_params[\"FUTURE_TARGET\"])\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.cache().batch(static_params[\"BATCH_SIZE\"]).shuffle(static_params[\"BUFFER_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = np.genfromtxt(\"data/SEG_val_set.csv\", delimiter=\"\\n\", dtype=np.int32)\n",
    "x_val, y_val = generate_timeseries(val_set, 0, None, static_params[\"PAST_HISTORY\"], static_params[\"FUTURE_TARGET\"])\n",
    "val_data = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_data = val_data.cache().batch(static_params[\"BATCH_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEGAutoRegressive(keras.Model):\n",
    "    def __init__(self, units_1, units_2, dropout_1, dropout_2, output_steps, output_size):\n",
    "        super().__init__()\n",
    "        self.output_steps = output_steps\n",
    "        self.units_1 = units_1\n",
    "        self.units_2 = units_2\n",
    "        self.dropout_1 = dropout_1\n",
    "        self.dropout_2 = dropout_2\n",
    "\n",
    "        self.lstm_cell_1 = LSTMCell(units_1, dropout=dropout_1)\n",
    "        self.lstm_cell_2 = LSTMCell(units_2, dropout=dropout_2)\n",
    "\n",
    "        self.lstm_rnn_1 = RNN(self.lstm_cell_1, return_state=True, return_sequences=True)\n",
    "        self.lstm_rnn_2 = RNN(self.lstm_cell_2, return_state=True)\n",
    "        self.dense = Dense(output_size, activation=\"softmax\")\n",
    "\n",
    "    @tf.function#(input_signature=[tf.TensorSpec(shape=[None, None, 1], dtype=tf.int32)])\n",
    "    def warmup(self, inputs):\n",
    "        onehot_inputs = tf.squeeze(tf.one_hot(inputs, static_params[\"VOCAB_SIZE\"]), axis=2)\n",
    "\n",
    "        # inputs.shape => (batch, time, features)\n",
    "        # x.shape => (batch, lstm_units)\n",
    "        x_1, *state_1 = self.lstm_rnn_1(onehot_inputs)\n",
    "        x_2, *state_2 = self.lstm_rnn_2(x_1)\n",
    "\n",
    "        # predictions.shape => (batch, features)\n",
    "        prediction = self.dense(x_2)\n",
    "\n",
    "        return prediction, state_1, state_2\n",
    "\n",
    "    @tf.function#(input_signature=[tf.TensorSpec(shape=[None, None, 1], dtype=tf.int32)])\n",
    "    def call(self, inputs, training=None):\n",
    "        # Use a TensorArray to capture dynamically unrolled outputs.\n",
    "        #predictions = []\n",
    "        predictions = tf.TensorArray(tf.float32, size=self.output_steps, clear_after_read=False)\n",
    "\n",
    "        # Initialize the lstm state\n",
    "        prediction, state_1, state_2 = self.warmup(inputs)\n",
    "\n",
    "        # Insert the first prediction\n",
    "        #predictions.append(prediction)\n",
    "        predictions = predictions.write(0, prediction)\n",
    "\n",
    "        # Run the rest of the prediction steps\n",
    "        for i in tf.range(1, self.output_steps):\n",
    "            # Use the last prediction as input.\n",
    "            x = prediction\n",
    "\n",
    "            # Execute one lstm step.\n",
    "            x_1, state_1 = self.lstm_cell_1(x, states=state_1, training=training)\n",
    "            x_2, state_2 = self.lstm_cell_2(x_1, states=state_2, training=training)\n",
    "\n",
    "            # Convert the lstm output to a prediction.\n",
    "            prediction = self.dense(x_2)\n",
    "\n",
    "            # Add the prediction to the output\n",
    "            #predictions.append(prediction)\n",
    "            predictions = predictions.write(i, prediction)\n",
    "\n",
    "        # predictions.shape => (time, batch, features)\n",
    "        #predictions = tf.stack(predictions)\n",
    "        predictions = predictions.stack()\n",
    "\n",
    "        # predictions.shape => (batch, time, features)\n",
    "        predictions = tf.transpose(predictions, [1, 0, 2])\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SEGAutoRegressive(\n",
    "    units_1=hparams[\"HP_LSTM_1_UNITS\"], units_2=hparams[\"HP_LSTM_2_UNITS\"], dropout_1=hparams[\"HP_LSTM_1_DROPOUT\"], \n",
    "    dropout_2=hparams[\"HP_LSTM_2_DROPOUT\"], output_steps=static_params[\"FUTURE_TARGET\"], output_size=static_params[\"VOCAB_SIZE\"])\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Nadam(hparams[\"HP_LEARNING_RATE\"]),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[[6.1402556e-05, 6.1380131e-05, 6.1333849e-05, ...,\n         6.1377206e-05, 6.1327686e-05, 6.1369428e-05],\n        [6.1399835e-05, 6.1381084e-05, 6.1335770e-05, ...,\n         6.1379462e-05, 6.1327475e-05, 6.1366438e-05],\n        [6.1396109e-05, 6.1382001e-05, 6.1339226e-05, ...,\n         6.1382154e-05, 6.1328763e-05, 6.1363004e-05],\n        ...,\n        [6.1386723e-05, 6.1383231e-05, 6.1351078e-05, ...,\n         6.1388018e-05, 6.1337836e-05, 6.1354665e-05],\n        [6.1384831e-05, 6.1383085e-05, 6.1354403e-05, ...,\n         6.1388768e-05, 6.1341467e-05, 6.1353312e-05],\n        [6.1383471e-05, 6.1382736e-05, 6.1357263e-05, ...,\n         6.1388964e-05, 6.1345039e-05, 6.1352745e-05]]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "model.predict(x_train[2].reshape(1, -1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x, y in train_data.take(1):\n",
    "    x_sample = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#history = model.fit(train_data, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"seg_auto_regressive\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #\n=================================================================\nlstm_cell (LSTMCell)         multiple                  4187648\n_________________________________________________________________\nlstm_cell_1 (LSTMCell)       multiple                  33024\n_________________________________________________________________\nrnn (RNN)                    multiple                  4187648\n_________________________________________________________________\nrnn_1 (RNN)                  multiple                  33024\n_________________________________________________________________\ndense (Dense)                multiple                  1059045\n=================================================================\nTotal params: 5,279,717\nTrainable params: 5,279,717\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nINFO:tensorflow:Assets written to: ex/model_4\\assets\n"
    }
   ],
   "source": [
    "tf.saved_model.save(model, \"ex/model_4\", \n",
    "    signatures=model.call.get_concrete_function(tf.TensorSpec(shape=[None, None, 1], dtype=tf.int32, name=\"input\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model = tf.saved_model.load(\"version/20200918-103208\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "ItemsView(_SignatureMap({'serving_default': <tensorflow.python.saved_model.load._WrapperFunction object at 0x000002B1A7670F88>}))"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "new_model.signatures.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'output_0': <tf.Tensor: shape=(1, 8, 16293), dtype=float32, numpy=\n array([[[2.61560619e-01, 1.05555393e-01, 3.22286412e-02, ...,\n          1.17059717e-05, 8.97260907e-06, 1.40956763e-05],\n         [2.61344552e-01, 1.05482891e-01, 3.22125517e-02, ...,\n          1.17148556e-05, 8.97976952e-06, 1.41057408e-05],\n         [2.61348903e-01, 1.05484381e-01, 3.22129093e-02, ...,\n          1.17146810e-05, 8.97961036e-06, 1.41055179e-05],\n         ...,\n         [2.61362463e-01, 1.05488814e-01, 3.22138779e-02, ...,\n          1.17141390e-05, 8.97916107e-06, 1.41048795e-05],\n         [2.61363626e-01, 1.05489217e-01, 3.22139934e-02, ...,\n          1.17140789e-05, 8.97913105e-06, 1.41048322e-05],\n         [2.61364222e-01, 1.05489418e-01, 3.22140381e-02, ...,\n          1.17140607e-05, 8.97910104e-06, 1.41047849e-05]]], dtype=float32)>}"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "inference = new_model.signatures[\"serving_default\"]\n",
    "inference(tf.constant(x_train[0].reshape(1, -1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
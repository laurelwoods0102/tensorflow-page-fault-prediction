{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597475101358",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'20200815-165215'"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = \"logs/fit/\" + timestamp\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "version_dir = \"version/\" + timestamp \n",
    "\n",
    "os.makedirs(version_dir)\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              t           t+1    delta  tokenized_data\n0  104289271808  104282980352 -6291456        -6291456\n1  104282980352  104282984448     4096            4096\n2  104282984448  104282988544     4096            4096\n3  104282988544  104282992640     4096            4096\n4  104282992640  104282996736     4096            4096",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t</th>\n      <th>t+1</th>\n      <th>delta</th>\n      <th>tokenized_data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>104289271808</td>\n      <td>104282980352</td>\n      <td>-6291456</td>\n      <td>-6291456</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>104282980352</td>\n      <td>104282984448</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>104282984448</td>\n      <td>104282988544</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>104282988544</td>\n      <td>104282992640</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>104282992640</td>\n      <td>104282996736</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"data/NU_train_set.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = dict()\n",
    "\n",
    "param_list[\"PAST_HISTORY\"] = 16\n",
    "param_list[\"FUTURE_TARGET\"] = 8\n",
    "param_list[\"BATCH_SIZE\"] = 1024\n",
    "param_list[\"EPOCHS\"] = 250\n",
    "param_list[\"BUFFER_SIZE\"] = 200000\n",
    "\n",
    "with open(\"version/{}/params.json\".format(timestamp), \"w\") as p:\n",
    "    json.dump(param_list, p, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timeseries(dataset, start_index, end_index, history_size, target_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i)\n",
    "        # Reshape data from (history_size,) to (history_size, n_feature)\n",
    "        data.append(np.reshape(dataset[indices], (history_size, 5)))\n",
    "        labels.append(dataset[i:i+target_size])\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(<1x5 sparse matrix of type '<class 'numpy.float32'>'\n \twith 1 stored elements in Compressed Sparse Row format>,\n [array([-6291456,       -1,        0,     4096,  2097152], dtype=int64)])"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(dtype=np.float32)   #dtype=np.int64\n",
    "encoded_data = encoder.fit_transform(dataset[\"tokenized_data\"].values.reshape(-1, 1))\n",
    "encoded_data[0], encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(encoder, \"data/encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = generate_timeseries(encoded_data.toarray(), 0, None, param_list[\"PAST_HISTORY\"], param_list[\"FUTURE_TARGET\"])\n",
    "\n",
    "#train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "#train_data = train_data.cache().shuffle(param_list[\"BUFFER_SIZE\"]).batch(param_list[\"BATCH_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(47165, 16, 5)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(47165, 8, 5)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(5))  #x_train.shape[-2:] , input_shape=[16, 5] , return_sequences=True\n",
    "#model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.RepeatVector(8))\n",
    "model.add(keras.layers.TimeDistributed(tf.keras.layers.Dense(5, activation=\"softmax\")))\n",
    "#model.add(tf.keras.layers.Flatten())\n",
    "#model.add(tf.keras.layers.Dense(5, activation=\"softmax\"))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(5)))  #x_train.shape[-2:] , input_shape=[16, 5] , return_sequences=True\n",
    "model.add(tf.keras.layers.RepeatVector(8))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(5, return_sequences=True)))\n",
    "model.add(keras.layers.TimeDistributed(tf.keras.layers.Dense(5, activation=\"softmax\")))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "=====================] - 1s 31ms/step - loss: 0.0366 - accuracy: 0.9909 - val_loss: 0.0196 - val_accuracy: 0.9965\nEpoch 113/250\n37/37 [==============================] - 3s 93ms/step - loss: 0.0365 - accuracy: 0.9909 - val_loss: 0.0196 - val_accuracy: 0.9967\nEpoch 114/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0365 - accuracy: 0.9909 - val_loss: 0.0197 - val_accuracy: 0.9967\nEpoch 115/250\n37/37 [==============================] - 3s 79ms/step - loss: 0.0365 - accuracy: 0.9909 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 116/250\n37/37 [==============================] - 1s 26ms/step - loss: 0.0365 - accuracy: 0.9910 - val_loss: 0.0196 - val_accuracy: 0.9967\nEpoch 117/250\n37/37 [==============================] - 1s 25ms/step - loss: 0.0365 - accuracy: 0.9909 - val_loss: 0.0196 - val_accuracy: 0.9966\nEpoch 118/250\n37/37 [==============================] - 2s 68ms/step - loss: 0.0364 - accuracy: 0.9909 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 119/250\n37/37 [==============================] - 1s 25ms/step - loss: 0.0364 - accuracy: 0.9910 - val_loss: 0.0197 - val_accuracy: 0.9966\nEpoch 120/250\n37/37 [==============================] - 1s 29ms/step - loss: 0.0364 - accuracy: 0.9910 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 121/250\n37/37 [==============================] - 1s 30ms/step - loss: 0.0364 - accuracy: 0.9910 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 122/250\n37/37 [==============================] - 4s 99ms/step - loss: 0.0364 - accuracy: 0.9910 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 123/250\n37/37 [==============================] - 1s 25ms/step - loss: 0.0364 - accuracy: 0.9909 - val_loss: 0.0197 - val_accuracy: 0.9966\nEpoch 124/250\n37/37 [==============================] - 1s 38ms/step - loss: 0.0363 - accuracy: 0.9910 - val_loss: 0.0196 - val_accuracy: 0.9966\nEpoch 125/250\n37/37 [==============================] - 3s 79ms/step - loss: 0.0364 - accuracy: 0.9910 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 126/250\n37/37 [==============================] - 1s 25ms/step - loss: 0.0363 - accuracy: 0.9909 - val_loss: 0.0192 - val_accuracy: 0.9968\nEpoch 127/250\n37/37 [==============================] - 4s 110ms/step - loss: 0.0364 - accuracy: 0.9910 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 128/250\n37/37 [==============================] - 1s 26ms/step - loss: 0.0363 - accuracy: 0.9910 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 129/250\n37/37 [==============================] - 1s 27ms/step - loss: 0.0363 - accuracy: 0.9909 - val_loss: 0.0192 - val_accuracy: 0.9968\nEpoch 130/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0363 - accuracy: 0.9909 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 131/250\n37/37 [==============================] - 5s 125ms/step - loss: 0.0362 - accuracy: 0.9910 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 132/250\n37/37 [==============================] - 3s 68ms/step - loss: 0.0363 - accuracy: 0.9911 - val_loss: 0.0192 - val_accuracy: 0.9967\nEpoch 133/250\n37/37 [==============================] - 1s 33ms/step - loss: 0.0363 - accuracy: 0.9910 - val_loss: 0.0193 - val_accuracy: 0.9968\nEpoch 134/250\n37/37 [==============================] - 4s 97ms/step - loss: 0.0362 - accuracy: 0.9910 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 135/250\n37/37 [==============================] - 1s 23ms/step - loss: 0.0362 - accuracy: 0.9910 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 136/250\n37/37 [==============================] - 1s 27ms/step - loss: 0.0362 - accuracy: 0.9910 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 137/250\n37/37 [==============================] - 1s 23ms/step - loss: 0.0362 - accuracy: 0.9910 - val_loss: 0.0194 - val_accuracy: 0.9968\nEpoch 138/250\n37/37 [==============================] - 1s 25ms/step - loss: 0.0362 - accuracy: 0.9910 - val_loss: 0.0196 - val_accuracy: 0.9967\nEpoch 139/250\n37/37 [==============================] - 2s 55ms/step - loss: 0.0362 - accuracy: 0.9909 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 140/250\n37/37 [==============================] - 1s 26ms/step - loss: 0.0362 - accuracy: 0.9911 - val_loss: 0.0192 - val_accuracy: 0.9967\nEpoch 141/250\n37/37 [==============================] - 1s 26ms/step - loss: 0.0362 - accuracy: 0.9910 - val_loss: 0.0200 - val_accuracy: 0.9967\nEpoch 142/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0362 - accuracy: 0.9910 - val_loss: 0.0197 - val_accuracy: 0.9967\nEpoch 143/250\n37/37 [==============================] - 1s 30ms/step - loss: 0.0361 - accuracy: 0.9910 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 144/250\n37/37 [==============================] - 1s 25ms/step - loss: 0.0361 - accuracy: 0.9910 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 145/250\n37/37 [==============================] - 1s 28ms/step - loss: 0.0361 - accuracy: 0.9910 - val_loss: 0.0191 - val_accuracy: 0.9967\nEpoch 146/250\n37/37 [==============================] - 1s 28ms/step - loss: 0.0361 - accuracy: 0.9910 - val_loss: 0.0195 - val_accuracy: 0.9966\nEpoch 147/250\n37/37 [==============================] - 1s 32ms/step - loss: 0.0361 - accuracy: 0.9910 - val_loss: 0.0193 - val_accuracy: 0.9968\nEpoch 148/250\n37/37 [==============================] - 1s 28ms/step - loss: 0.0361 - accuracy: 0.9910 - val_loss: 0.0196 - val_accuracy: 0.9968\nEpoch 149/250\n37/37 [==============================] - 1s 25ms/step - loss: 0.0361 - accuracy: 0.9910 - val_loss: 0.0199 - val_accuracy: 0.9967\nEpoch 150/250\n37/37 [==============================] - 1s 31ms/step - loss: 0.0361 - accuracy: 0.9910 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 151/250\n37/37 [==============================] - 1s 36ms/step - loss: 0.0361 - accuracy: 0.9910 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 152/250\n37/37 [==============================] - 1s 28ms/step - loss: 0.0360 - accuracy: 0.9910 - val_loss: 0.0197 - val_accuracy: 0.9967\nEpoch 153/250\n37/37 [==============================] - 3s 81ms/step - loss: 0.0361 - accuracy: 0.9910 - val_loss: 0.0194 - val_accuracy: 0.9968\nEpoch 154/250\n37/37 [==============================] - 2s 41ms/step - loss: 0.0360 - accuracy: 0.9910 - val_loss: 0.0199 - val_accuracy: 0.9967\nEpoch 155/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0361 - accuracy: 0.9910 - val_loss: 0.0194 - val_accuracy: 0.9966\nEpoch 156/250\n37/37 [==============================] - 2s 48ms/step - loss: 0.0361 - accuracy: 0.9910 - val_loss: 0.0191 - val_accuracy: 0.9967\nEpoch 157/250\n37/37 [==============================] - 8s 214ms/step - loss: 0.0361 - accuracy: 0.9910 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 158/250\n37/37 [==============================] - 2s 57ms/step - loss: 0.0360 - accuracy: 0.9910 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 159/250\n37/37 [==============================] - 1s 40ms/step - loss: 0.0360 - accuracy: 0.9911 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 160/250\n37/37 [==============================] - 1s 31ms/step - loss: 0.0360 - accuracy: 0.9910 - val_loss: 0.0200 - val_accuracy: 0.9967\nEpoch 161/250\n37/37 [==============================] - 1s 34ms/step - loss: 0.0360 - accuracy: 0.9910 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 162/250\n37/37 [==============================] - 1s 35ms/step - loss: 0.0360 - accuracy: 0.9910 - val_loss: 0.0195 - val_accuracy: 0.9968\nEpoch 163/250\n37/37 [==============================] - 2s 50ms/step - loss: 0.0360 - accuracy: 0.9910 - val_loss: 0.0191 - val_accuracy: 0.9968\nEpoch 164/250\n37/37 [==============================] - 3s 68ms/step - loss: 0.0360 - accuracy: 0.9910 - val_loss: 0.0192 - val_accuracy: 0.9968\nEpoch 165/250\n37/37 [==============================] - 1s 35ms/step - loss: 0.0359 - accuracy: 0.9910 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 166/250\n37/37 [==============================] - 1s 26ms/step - loss: 0.0359 - accuracy: 0.9910 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 167/250\n37/37 [==============================] - 1s 28ms/step - loss: 0.0360 - accuracy: 0.9910 - val_loss: 0.0192 - val_accuracy: 0.9967\nEpoch 168/250\n37/37 [==============================] - 1s 29ms/step - loss: 0.0359 - accuracy: 0.9911 - val_loss: 0.0192 - val_accuracy: 0.9967\nEpoch 169/250\n37/37 [==============================] - 3s 85ms/step - loss: 0.0360 - accuracy: 0.9910 - val_loss: 0.0191 - val_accuracy: 0.9967\nEpoch 170/250\n37/37 [==============================] - 1s 33ms/step - loss: 0.0360 - accuracy: 0.9910 - val_loss: 0.0192 - val_accuracy: 0.9968\nEpoch 171/250\n37/37 [==============================] - 2s 53ms/step - loss: 0.0359 - accuracy: 0.9910 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 172/250\n37/37 [==============================] - 1s 27ms/step - loss: 0.0359 - accuracy: 0.9911 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 173/250\n37/37 [==============================] - 1s 27ms/step - loss: 0.0359 - accuracy: 0.9910 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 174/250\n37/37 [==============================] - 3s 72ms/step - loss: 0.0359 - accuracy: 0.9910 - val_loss: 0.0198 - val_accuracy: 0.9968\nEpoch 175/250\n37/37 [==============================] - 1s 29ms/step - loss: 0.0359 - accuracy: 0.9911 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 176/250\n37/37 [==============================] - 1s 26ms/step - loss: 0.0359 - accuracy: 0.9911 - val_loss: 0.0195 - val_accuracy: 0.9966\nEpoch 177/250\n37/37 [==============================] - 3s 71ms/step - loss: 0.0359 - accuracy: 0.9910 - val_loss: 0.0194 - val_accuracy: 0.9968\nEpoch 178/250\n37/37 [==============================] - 3s 85ms/step - loss: 0.0358 - accuracy: 0.9910 - val_loss: 0.0192 - val_accuracy: 0.9968\nEpoch 179/250\n37/37 [==============================] - 2s 47ms/step - loss: 0.0359 - accuracy: 0.9911 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 180/250\n37/37 [==============================] - 3s 92ms/step - loss: 0.0359 - accuracy: 0.9911 - val_loss: 0.0194 - val_accuracy: 0.9968\nEpoch 181/250\n37/37 [==============================] - 2s 45ms/step - loss: 0.0358 - accuracy: 0.9911 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 182/250\n37/37 [==============================] - 1s 23ms/step - loss: 0.0358 - accuracy: 0.9911 - val_loss: 0.0196 - val_accuracy: 0.9965\nEpoch 183/250\n37/37 [==============================] - 1s 23ms/step - loss: 0.0358 - accuracy: 0.9911 - val_loss: 0.0193 - val_accuracy: 0.9968\nEpoch 184/250\n37/37 [==============================] - 4s 112ms/step - loss: 0.0359 - accuracy: 0.9911 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 185/250\n37/37 [==============================] - 1s 27ms/step - loss: 0.0359 - accuracy: 0.9911 - val_loss: 0.0196 - val_accuracy: 0.9966\nEpoch 186/250\n37/37 [==============================] - 3s 76ms/step - loss: 0.0358 - accuracy: 0.9911 - val_loss: 0.0193 - val_accuracy: 0.9968\nEpoch 187/250\n37/37 [==============================] - 1s 25ms/step - loss: 0.0358 - accuracy: 0.9911 - val_loss: 0.0193 - val_accuracy: 0.9968\nEpoch 188/250\n37/37 [==============================] - 6s 155ms/step - loss: 0.0358 - accuracy: 0.9911 - val_loss: 0.0192 - val_accuracy: 0.9968\nEpoch 189/250\n37/37 [==============================] - 1s 25ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 0.0192 - val_accuracy: 0.9967\nEpoch 190/250\n37/37 [==============================] - 4s 99ms/step - loss: 0.0358 - accuracy: 0.9911 - val_loss: 0.0191 - val_accuracy: 0.9967\nEpoch 191/250\n37/37 [==============================] - 1s 23ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 0.0193 - val_accuracy: 0.9966\nEpoch 192/250\n37/37 [==============================] - 1s 26ms/step - loss: 0.0358 - accuracy: 0.9911 - val_loss: 0.0195 - val_accuracy: 0.9966\nEpoch 193/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0358 - accuracy: 0.9911 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 194/250\n37/37 [==============================] - 2s 60ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.0190 - val_accuracy: 0.9968\nEpoch 195/250\n37/37 [==============================] - 3s 70ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.0195 - val_accuracy: 0.9966\nEpoch 196/250\n37/37 [==============================] - 2s 45ms/step - loss: 0.0358 - accuracy: 0.9911 - val_loss: 0.0198 - val_accuracy: 0.9967\nEpoch 197/250\n37/37 [==============================] - 1s 29ms/step - loss: 0.0357 - accuracy: 0.9911 - val_loss: 0.0191 - val_accuracy: 0.9968\nEpoch 198/250\n37/37 [==============================] - 1s 25ms/step - loss: 0.0357 - accuracy: 0.9911 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 199/250\n37/37 [==============================] - 2s 45ms/step - loss: 0.0358 - accuracy: 0.9911 - val_loss: 0.0195 - val_accuracy: 0.9968\nEpoch 200/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.0192 - val_accuracy: 0.9967\nEpoch 201/250\n37/37 [==============================] - 5s 138ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.0193 - val_accuracy: 0.9966\nEpoch 202/250\n37/37 [==============================] - 1s 22ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 203/250\n37/37 [==============================] - 1s 25ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.0196 - val_accuracy: 0.9967\nEpoch 204/250\n37/37 [==============================] - 6s 174ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.0192 - val_accuracy: 0.9967\nEpoch 205/250\n37/37 [==============================] - 1s 28ms/step - loss: 0.0356 - accuracy: 0.9911 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 206/250\n37/37 [==============================] - 1s 36ms/step - loss: 0.0356 - accuracy: 0.9911 - val_loss: 0.0193 - val_accuracy: 0.9968\nEpoch 207/250\n37/37 [==============================] - 3s 83ms/step - loss: 0.0357 - accuracy: 0.9911 - val_loss: 0.0197 - val_accuracy: 0.9966\nEpoch 208/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.0196 - val_accuracy: 0.9967\nEpoch 209/250\n37/37 [==============================] - 1s 25ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.0192 - val_accuracy: 0.9967\nEpoch 210/250\n37/37 [==============================] - 1s 27ms/step - loss: 0.0356 - accuracy: 0.9911 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 211/250\n37/37 [==============================] - 6s 153ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 212/250\n37/37 [==============================] - 1s 27ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 213/250\n37/37 [==============================] - 1s 25ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.0192 - val_accuracy: 0.9967\nEpoch 214/250\n37/37 [==============================] - 5s 143ms/step - loss: 0.0356 - accuracy: 0.9913 - val_loss: 0.0194 - val_accuracy: 0.9966\nEpoch 215/250\n37/37 [==============================] - 2s 46ms/step - loss: 0.0357 - accuracy: 0.9911 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 216/250\n37/37 [==============================] - 2s 58ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.0192 - val_accuracy: 0.9967\nEpoch 217/250\n37/37 [==============================] - 1s 26ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.0195 - val_accuracy: 0.9966\nEpoch 218/250\n37/37 [==============================] - 1s 26ms/step - loss: 0.0355 - accuracy: 0.9912 - val_loss: 0.0195 - val_accuracy: 0.9965\nEpoch 219/250\n37/37 [==============================] - 3s 80ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.0195 - val_accuracy: 0.9965\nEpoch 220/250\n37/37 [==============================] - 1s 25ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.0192 - val_accuracy: 0.9967\nEpoch 221/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.0191 - val_accuracy: 0.9967\nEpoch 222/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0355 - accuracy: 0.9912 - val_loss: 0.0192 - val_accuracy: 0.9967\nEpoch 223/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0355 - accuracy: 0.9912 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 224/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.0192 - val_accuracy: 0.9967\nEpoch 225/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0355 - accuracy: 0.9912 - val_loss: 0.0190 - val_accuracy: 0.9967\nEpoch 226/250\n37/37 [==============================] - 2s 61ms/step - loss: 0.0355 - accuracy: 0.9912 - val_loss: 0.0192 - val_accuracy: 0.9968\nEpoch 227/250\n37/37 [==============================] - 3s 85ms/step - loss: 0.0355 - accuracy: 0.9913 - val_loss: 0.0201 - val_accuracy: 0.9965\nEpoch 228/250\n37/37 [==============================] - 3s 83ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 0.0190 - val_accuracy: 0.9968\nEpoch 229/250\n37/37 [==============================] - 10s 267ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.0191 - val_accuracy: 0.9967\nEpoch 230/250\n37/37 [==============================] - 1s 31ms/step - loss: 0.0355 - accuracy: 0.9912 - val_loss: 0.0191 - val_accuracy: 0.9966\nEpoch 231/250\n37/37 [==============================] - 1s 25ms/step - loss: 0.0355 - accuracy: 0.9912 - val_loss: 0.0190 - val_accuracy: 0.9966\nEpoch 232/250\n37/37 [==============================] - 1s 23ms/step - loss: 0.0354 - accuracy: 0.9913 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 233/250\n37/37 [==============================] - 9s 230ms/step - loss: 0.0355 - accuracy: 0.9912 - val_loss: 0.0192 - val_accuracy: 0.9967\nEpoch 234/250\n37/37 [==============================] - 4s 96ms/step - loss: 0.0355 - accuracy: 0.9913 - val_loss: 0.0194 - val_accuracy: 0.9966\nEpoch 235/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0354 - accuracy: 0.9912 - val_loss: 0.0192 - val_accuracy: 0.9967\nEpoch 236/250\n37/37 [==============================] - 1s 37ms/step - loss: 0.0354 - accuracy: 0.9912 - val_loss: 0.0193 - val_accuracy: 0.9967\nEpoch 237/250\n37/37 [==============================] - 4s 105ms/step - loss: 0.0355 - accuracy: 0.9912 - val_loss: 0.0191 - val_accuracy: 0.9967\nEpoch 238/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0355 - accuracy: 0.9913 - val_loss: 0.0191 - val_accuracy: 0.9966\nEpoch 239/250\n37/37 [==============================] - 6s 171ms/step - loss: 0.0355 - accuracy: 0.9913 - val_loss: 0.0196 - val_accuracy: 0.9967\nEpoch 240/250\n37/37 [==============================] - 2s 47ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.0194 - val_accuracy: 0.9966\nEpoch 241/250\n37/37 [==============================] - 2s 66ms/step - loss: 0.0354 - accuracy: 0.9913 - val_loss: 0.0192 - val_accuracy: 0.9966\nEpoch 242/250\n37/37 [==============================] - 3s 70ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.0192 - val_accuracy: 0.9966\nEpoch 243/250\n37/37 [==============================] - 2s 47ms/step - loss: 0.0355 - accuracy: 0.9912 - val_loss: 0.0194 - val_accuracy: 0.9967\nEpoch 244/250\n37/37 [==============================] - 1s 37ms/step - loss: 0.0354 - accuracy: 0.9913 - val_loss: 0.0198 - val_accuracy: 0.9967\nEpoch 245/250\n37/37 [==============================] - 1s 26ms/step - loss: 0.0355 - accuracy: 0.9913 - val_loss: 0.0193 - val_accuracy: 0.9966\nEpoch 246/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0354 - accuracy: 0.9913 - val_loss: 0.0192 - val_accuracy: 0.9967\nEpoch 247/250\n37/37 [==============================] - 1s 25ms/step - loss: 0.0354 - accuracy: 0.9913 - val_loss: 0.0191 - val_accuracy: 0.9967\nEpoch 248/250\n37/37 [==============================] - 1s 24ms/step - loss: 0.0354 - accuracy: 0.9913 - val_loss: 0.0195 - val_accuracy: 0.9967\nEpoch 249/250\n37/37 [==============================] - 3s 78ms/step - loss: 0.0354 - accuracy: 0.9913 - val_loss: 0.0191 - val_accuracy: 0.9967\nEpoch 250/250\n37/37 [==============================] - 1s 23ms/step - loss: 0.0354 - accuracy: 0.9913 - val_loss: 0.0193 - val_accuracy: 0.9967\n"
    }
   ],
   "source": [
    "model_history = model.fit(x_train, y_train, batch_size=param_list[\"BATCH_SIZE\"], validation_split=0.2, epochs=param_list[\"EPOCHS\"])\n",
    "model.save(\"version/{}/model.h5\".format(timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              t           t+1  delta  tokenized_data\n0  103591821312  103591825408   4096            4096\n1  103591825408  103591829504   4096            4096\n2  103591829504  103591833600   4096            4096\n3  103591833600  103591837696   4096            4096\n4  103591837696  103591841792   4096            4096",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t</th>\n      <th>t+1</th>\n      <th>delta</th>\n      <th>tokenized_data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>103591821312</td>\n      <td>103591825408</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>103591825408</td>\n      <td>103591829504</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>103591829504</td>\n      <td>103591833600</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>103591833600</td>\n      <td>103591837696</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>103591837696</td>\n      <td>103591841792</td>\n      <td>4096</td>\n      <td>4096</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "test_dataset = pd.read_csv(\"data/NU_test_set.csv\")\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(<1x5 sparse matrix of type '<class 'numpy.float32'>'\n \twith 1 stored elements in Compressed Sparse Row format>,\n [array([-6291456,       -1,        0,     4096,  2097152], dtype=int64)])"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "test_encoder = OneHotEncoder(dtype=np.float32)\n",
    "encoded_test_data = test_encoder.fit_transform(test_dataset[\"tokenized_data\"].values.reshape(-1, 1))\n",
    "encoded_test_data[0], test_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = generate_timeseries(encoded_test_data.toarray(), 0, None, 16, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "for i in range(y_test.shape[0]):\n",
    "    y_true.extend(np.argmax(y_test[i], axis=1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in range(x_test.shape[0]):\n",
    "    y_pred.extend(np.argmax(model.predict(x_test[i].reshape(1, 16, 5))[0], axis=1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[[2.9187178e-04, 1.0927758e-03, 3.3078957e-04, 9.9801874e-01,\n         2.6592493e-04],\n        [2.5373511e-04, 8.9197798e-04, 2.7462136e-04, 9.9834847e-01,\n         2.3117388e-04],\n        [3.6898401e-04, 9.1667345e-04, 4.0495221e-04, 9.9796343e-01,\n         3.4592798e-04],\n        [5.6339521e-04, 9.4378972e-04, 6.2860060e-04, 9.9732000e-01,\n         5.4424530e-04],\n        [8.0418430e-04, 9.3528023e-04, 9.0130442e-04, 9.9656588e-01,\n         7.9331436e-04],\n        [1.0053831e-03, 8.7055092e-04, 1.1066241e-03, 9.9602121e-01,\n         9.9636358e-04],\n        [1.0566743e-03, 7.8139035e-04, 1.0919169e-03, 9.9604708e-01,\n         1.0229854e-03],\n        [1.2105748e-03, 1.2207702e-03, 1.0832353e-03, 9.9538875e-01,\n         1.0966696e-03]]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "model.predict(x_test[0].reshape(1, 16, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([3, 3, 3, 3, 3, 3, 3, 3], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "np.argmax(model.predict(x_test[0].reshape(1, 16, 5))[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[4096],\n       [4096],\n       [4096],\n       [4096],\n       [4096],\n       [4096],\n       [4096],\n       [4096]], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "test_encoder.inverse_transform(model.predict(x_test[0].reshape(1, 16, 5))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10502 entries, 0 to 10501\nData columns (total 4 columns):\n #   Column          Non-Null Count  Dtype\n---  ------          --------------  -----\n 0   t               10502 non-null  int64\n 1   t+1             10502 non-null  int64\n 2   delta           10502 non-null  int64\n 3   tokenized_data  10502 non-null  int64\ndtypes: int64(4)\nmemory usage: 328.3 KB\n"
    }
   ],
   "source": [
    "test_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9850520137430807"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "with open(\"version/{}/accuracy.txt\".format(timestamp), \"w\") as t:\n",
    "    t.write(str(accuracy.tolist()))\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'              precision    recall  f1-score   support\\n\\n           0       0.15      0.25      0.19        24\\n           1       0.00      0.00      0.00        80\\n           2       0.40      0.02      0.03      1080\\n           3       0.99      1.00      0.99     82616\\n           4       0.07      0.17      0.10        24\\n\\n    accuracy                           0.99     83824\\n   macro avg       0.32      0.29      0.26     83824\\nweighted avg       0.98      0.99      0.98     83824\\n'"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_true, y_pred)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n           0       0.15      0.25      0.19        24\n           1       0.00      0.00      0.00        80\n           2       0.40      0.02      0.03      1080\n           3       0.99      1.00      0.99     82616\n           4       0.07      0.17      0.10        24\n\n    accuracy                           0.99     83824\n   macro avg       0.32      0.29      0.26     83824\nweighted avg       0.98      0.99      0.98     83824\n\n"
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_recheck = []\n",
    "for i in range(x_test.shape[0]):\n",
    "    y_pred_recheck.extend(np.argmax(model.predict(x_test[i].reshape(1, 16, 5))[0], axis=1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9850520137430807"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "accuracy_recheck = accuracy_score(y_true, y_pred_recheck)\n",
    "accuracy_recheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n           0       0.15      0.25      0.19        24\n           1       0.00      0.00      0.00        80\n           2       0.40      0.02      0.03      1080\n           3       0.99      1.00      0.99     82616\n           4       0.07      0.17      0.10        24\n\n    accuracy                           0.99     83824\n   macro avg       0.32      0.29      0.26     83824\nweighted avg       0.98      0.99      0.98     83824\n\n"
    }
   ],
   "source": [
    "report_recheck = classification_report(y_true, y_pred_recheck)\n",
    "print(report_recheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}